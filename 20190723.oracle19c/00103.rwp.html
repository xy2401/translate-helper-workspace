<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xml:lang="en-us" lang="en-us">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <meta name="abstract" content="When you design applications for real world performance, you should consider how code for bind variables, instrumentation, and set-based processing.">
      <meta name="description" content="When you design applications for real world performance, you should consider how code for bind variables, instrumentation, and set-based processing.">
      <title>Designing Applications for Oracle Real-World Performance</title>
      <meta property="og:site_name" content="Oracle Help Center">
      <meta property="og:title" content="Database Development Guide">
      <meta property="og:description" content="When you design applications for real world performance, you should consider how code for bind variables, instrumentation, and set-based processing.">
      <link rel="stylesheet" href="/sp_common/book-template/ohc-book-template/css/book.css">
      <link rel="shortcut icon" href="/sp_common/book-template/ohc-common/img/favicon.ico">
      <meta name="application-name" content="Database Development Guide">
      <meta name="generator" content="DITA Open Toolkit version 1.8.5 (Mode = doc)">
      <meta name="plugin" content="SP_docbuilder HTML plugin release 18.2.2">
      <link rel="alternate" href="database-development-guide.pdf" title="PDF File" type="application/pdf">
      <meta name="robots" content="all">
      <link rel="schema.dcterms" href="http://purl.org/dc/terms/">
      <meta name="dcterms.created" content="2019-01-31T23:23:15-08:00">
      <meta name="dcterms.title" content="Database Development Guide">
      <meta name="dcterms.dateCopyrighted" content="1996, 2019">
      <meta name="dcterms.category" content="database">
      <meta name="dcterms.identifier" content="E96334-02">
      
      <meta name="dcterms.product" content="en/database/oracle/oracle-database/19">
      
      <link rel="prev" href="performance-and-scalability.html" title="Previous" type="text/html">
      <link rel="next" href="security.html" title="Next" type="text/html">
      <script>
        document.write('<style type="text/css">');
        document.write('body > .noscript, body > .noscript ~ * { visibility: hidden; }');
        document.write('</style>');
     </script>
      <script data-main="/sp_common/book-template/ohc-book-template/js/book-config" src="/sp_common/book-template/requirejs/require.js"></script>
      <script>
            if (window.require === undefined) {
                document.write('<script data-main="sp_common/book-template/ohc-book-template/js/book-config" src="sp_common/book-template/requirejs/require.js"><\/script>');
                document.write('<link href="sp_common/book-template/ohc-book-template/css/book.css" rel="stylesheet"/>');
            }
        </script>
      <script type="application/json" id="ssot-metadata">{"primary":{"category":{"short_name":"database","element_name":"Database","display_in_url":true},"suite":{"short_name":"oracle","element_name":"Oracle","display_in_url":true},"product_group":{"short_name":"not-applicable","element_name":"Not applicable","display_in_url":false},"product":{"short_name":"oracle-database","element_name":"Oracle Database","display_in_url":true},"release":{"short_name":"19","element_name":"Release 19","display_in_url":true}}}</script>
      
    <meta name="dcterms.isVersionOf" content="ADFNS">
    <meta name="dcterms.release" content="Release 19">
  </head>
   <body>
      <div class="noscript alert alert-danger text-center" role="alert">
         <a href="performance-and-scalability.html" class="pull-left"><span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span>Previous</a>
         <a href="security.html" class="pull-right">Next<span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span></a>
         <span class="fa fa-exclamation-triangle" aria-hidden="true"></span> JavaScript must be enabled to correctly display this content
        
      </div>
      <article>
         <header>
            <ol class="breadcrumb" vocab="http://schema.org/" typeof="BreadcrumbList">
               <li property="itemListElement" typeof="ListItem"><a href="index.html" property="item" typeof="WebPage"><span property="name">Database Development Guide</span></a></li>
               <li property="itemListElement" typeof="ListItem"><a href="fundamentals.html" property="item" typeof="WebPage"><span property="name">Database Development Fundamentals</span></a></li>
               <li class="active" property="itemListElement" typeof="ListItem">Designing Applications for Oracle Real-World Performance</li>
            </ol>
            <a id="GUID-754328E1-2203-4B03-A21B-A91C3E548233" name="GUID-754328E1-2203-4B03-A21B-A91C3E548233"></a>
            
            <h2 id="ADFNS-GUID-754328E1-2203-4B03-A21B-A91C3E548233" class="sect2"><span class="enumeration_chapter">4 </span>Designing Applications for Oracle Real-World Performance
            </h2>
         </header>
         <div class="ind">
            <div>
               <p>When you design applications for real world performance, you should consider how code for bind variables, instrumentation, and set-based processing.</p>
               <p>Topics:</p>
               <ul style="list-style-type: disc;">
                  <li>
                     <p><a href="rwp.html#GUID-D95280DE-969D-4B83-825E-ECC872C111EA" title="A bind variable placeholder in a SQL statement or PL/SQL block indicates where data must be supplied at runtime.">Using Bind Variables</a></p>
                  </li>
                  <li>
                     <p><a href="rwp.html#GUID-20D3F573-B043-42A7-867D-0C1C0A0067AD">Using Instrumentation</a></p>
                  </li>
                  <li>
                     <p><a href="rwp.html#GUID-83C28F26-45AE-492C-B42A-8F4F20770C33" title="A common task in database applications in a data warehouse environment is querying or modifying a huge data set.">Using Set-Based Processing</a></p>
                  </li>
               </ul>
            </div><a id="ADFNS179"></a><div class="props_rev_3"><a id="GUID-D95280DE-969D-4B83-825E-ECC872C111EA" name="GUID-D95280DE-969D-4B83-825E-ECC872C111EA"></a><h3 id="ADFNS-GUID-D95280DE-969D-4B83-825E-ECC872C111EA" class="sect3">Using Bind Variables</h3>
               <div>
                  <p>A bind variable placeholder in a SQL statement or PL/SQL block indicates where data must be supplied at runtime.</p>
                  <div class="section">
                     <p>Suppose that you want your application to insert data into the table created with this statement:</p><pre class="oac_no_warn" dir="ltr">CREATE TABLE test (x VARCHAR2(30), y VARCHAR2(30));
</pre><p>Because the data is not known until runtime, you must use dynamic SQL.</p>
                     <p>The following statement inserts a row into table <code class="codeph">test</code>, concatenating string literals for columns x and y:
                     </p><pre class="oac_no_warn" dir="ltr">INSERT INTO test (x,y) VALUES ( ''' || REPLACE (x, '''', '''''') || '''),
                                ''' || REPLACE (y, '''', '''''') || ''');
</pre><p>The following statement inserts a row into table <code class="codeph">test</code> using bind variables <code class="codeph">:x</code> and <code class="codeph">:y</code> for columns x and y:
                     </p><pre class="oac_no_warn" dir="ltr">INSERT INTO test (x,y) VALUES (:x, :y);
</pre><p>The statement that uses bind variable placeholders is easier to code.</p>
                     <p>Now consider a dynamic bulk load operation that inserts 1,000 rows into table <code class="codeph">test</code> using each of the preceding methods.
                     </p>
                     <p>The method that concatenates string literals uses 1,000 <code class="codeph">INSERT</code> statements, each of which must be hard-parsed, qualified, checked for security, optimized, and compiled. Because each statement is hard-parsed, the number of latches greatly increases. Latches are mutual-exclusion locking mechanisms—serialization devices, which inhibit concurrency.
                     </p>
                     <p>A method that uses bind variable placeholders uses only one <code class="codeph">INSERT</code> statement. The statement is soft-parsed, qualified, checked for security, optimized, compiled, and cached in a shared pool. The compiled statement from the shared pool is used for each of the 1000 inserts. This statement caching is a very important benefit of using bind variables.
                     </p>
                     <p>An application that uses bind variable placeholders is more scalable, supports more users, requires fewer resources, and runs faster than an application that uses string concatenation—and it is less vulnerable to SQL injection attacks. If a SQL statement uses string concatenation, an end user can modify the statement and use the application to do something harmful.</p>
                     <p>You can use bind variable placeholders for input variables in <code class="codeph">DELETE</code>, <code class="codeph">INSERT</code>, <code class="codeph">SELECT</code>, and <code class="codeph">UPDATE</code> statements, and anywhere in a PL/SQL block that you can use an expression or literal. In PL/SQL, you can also use bind variable placeholders for output variables. Binding is used for both input and output variables in nonquery operations.
                     </p>
                     <div class="infoboxnotealso" id="GUID-D95280DE-969D-4B83-825E-ECC872C111EA__GUID-2E87E1B6-B4F4-420C-B711-6D32260F78E3">
                        <p class="notep1">See Also:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><a href="https://www.oracle.com/pls/topic/lookup?ctx=en/database/oracle/oracle-database/19/adfns&amp;id=LNPLS646" target="_blank"><span class="italic">Oracle Database PL/SQL Language Reference</span></a> for more information about using bind variables to protect your application from SQL injection
                              </p>
                           </li>
                           <li>
                              <p><a href="https://www.oracle.com/pls/topic/lookup?ctx=en/database/oracle/oracle-database/19/adfns&amp;id=LNOCI16342" target="_blank"><span class="italic">Oracle Call Interface Programmer's Guide</span></a> for more information about using bind variable placeholders in OCI
                              </p>
                           </li>
                        </ul>
                     </div>
                  </div>
                  <!-- class="section" -->
               </div>
            </div><a id="ADFNS162"></a><div class="props_rev_3"><a id="GUID-20D3F573-B043-42A7-867D-0C1C0A0067AD" name="GUID-20D3F573-B043-42A7-867D-0C1C0A0067AD"></a><h3 id="ADFNS-GUID-20D3F573-B043-42A7-867D-0C1C0A0067AD" class="sect3">Using Instrumentation</h3>
               <div>
                  <p>To use instrumentation means adding debug code throughout your application. When enabled, this code generates trace files, which contain information that helps you identify and locate problems. Trace files are especially helpful when debugging multitier applications; they help you identify the problematic tier.</p>
                  <div class="infoboxnotealso" id="GUID-20D3F573-B043-42A7-867D-0C1C0A0067AD__GUID-BDBC727F-773A-4F07-9405-F8EF4CB3946C">
                     <p class="notep1">See Also:</p>
                     <p><a href="performance-and-scalability.html#GUID-C1AD0758-6D69-4D2F-80BB-30BA6DA2DCF2">SQL Trace Facility (SQL_TRACE)</a> for more information
                     </p>
                  </div>
               </div>
            </div>
            <div class="sect2"><a id="GUID-83C28F26-45AE-492C-B42A-8F4F20770C33" name="GUID-83C28F26-45AE-492C-B42A-8F4F20770C33"></a><h3 id="ADFNS-GUID-83C28F26-45AE-492C-B42A-8F4F20770C33" class="sect3">Using Set-Based Processing</h3>
               <div>
                  <p>A common task in database applications in a data warehouse environment is querying or modifying a huge data set. </p>
                  <p>For example, an application might join data sets numbering in the tens of millions of rows, filter on a set of criteria, perform aggregations, and then display the result to the user. Alternatively, an application might filter out rows from one billion-row table based on specified criteria, and then insert matching rows into another table.</p>
                  <p>The problem for application developers is how to achieve high performance when processing these large data sets. Processing techniques fall into two categories: iterative, and set-based. Over years of testing, the Oracle Real-World Performance group has discovered that set-based processing techniques perform orders of magnitude better for database applications that process large data sets.</p>
                  <p>Topics:</p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p><a href="rwp.html#GUID-16CD8271-4959-41C2-9332-4FE21F54BA83" title="Iterative data processing processes data row by row, using arrays, or using manual parallelism.">Iterative Data Processing</a></p>
                     </li>
                     <li>
                        <p><a href="rwp.html#GUID-83C28F26-45AE-492C-B42A-8F4F20770C33" title="A common task in database applications in a data warehouse environment is querying or modifying a huge data set.">Using Set-Based Processing</a></p>
                     </li>
                  </ul>
               </div>
               <div class="sect3"><a id="GUID-16CD8271-4959-41C2-9332-4FE21F54BA83" name="GUID-16CD8271-4959-41C2-9332-4FE21F54BA83"></a><h4 id="ADFNS-GUID-16CD8271-4959-41C2-9332-4FE21F54BA83" class="sect4">Iterative Data Processing</h4>
                  <div>
                     <p>Iterative data processing processes data row by row, using arrays, or using manual parallelism.</p>
                     <p>Topics:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><a href="rwp.html#GUID-587B101A-CA9D-4F9F-AC67-E128D67DEB59" title="In this type of processing, applications use conditional logic to iterate through a set of rows.">About Iterative Data Processing</a></p>
                        </li>
                        <li>
                           <p><a href="rwp.html#GUID-014A1091-206B-4455-B6BF-2E010C5E4655" title="Of the iterative techniques, row-by-row processing is the most common.">Iterative Data Processing: Row-By-Row</a></p>
                        </li>
                        <li>
                           <p><a href="rwp.html#GUID-5B427623-E329-4BD5-9D60-B58B0C61A7C9" title="Array processing is identical to row-by-row processing, except that it processes a group of rows in each iteration rather than a single row.">Iterative Data Processing: Arrays</a></p>
                        </li>
                        <li>
                           <p><a href="rwp.html#GUID-413B3E68-5590-4337-956B-B6CFC11FC2DD" title="Manual parallelism uses the same iterative algorithm as row-by-row and array processing, but enables multiple server processes to work on the job concurrently.">Iterative Data Processing: Manual Parallelism</a></p>
                        </li>
                     </ul>
                  </div>
                  <div class="sect4"><a id="GUID-587B101A-CA9D-4F9F-AC67-E128D67DEB59" name="GUID-587B101A-CA9D-4F9F-AC67-E128D67DEB59"></a><h5 id="ADFNS-GUID-587B101A-CA9D-4F9F-AC67-E128D67DEB59" class="sect5">About Iterative Data Processing</h5>
                     <div>
                        <p>In this type of processing, applications use conditional logic to iterate through a set of rows.</p>
                        <p>You can write iterative applications in PL/SQL, Java, or any other procedural or object-oriented language. The technique is "iterative" because it breaks the row source into subgroups containing one or more rows, and then processes each subgroup. A single process can iterate through all subgroups, or multiple processes can iterate through the subgroups in parallel.</p>
                        <p>Typically, although not necessarily, iterative processing uses a client/server model as follows:</p>
                        <ol>
                           <li>
                              <p>Transfer a group of rows from the database server to the client application.</p>
                           </li>
                           <li>
                              <p>Process the group within the client application.</p>
                           </li>
                           <li>
                              <p>Transfer the processed group back to the database server.</p>
                           </li>
                        </ol>
                        <p>You can implement iterative algorithms using three main techniques: row-by-row processing, array processing, and manual parallelism. Each technique obtains the same result, but from a performance perspective, each has its benefits and drawbacks.</p>
                     </div>
                  </div>
                  <div class="sect4"><a id="GUID-014A1091-206B-4455-B6BF-2E010C5E4655" name="GUID-014A1091-206B-4455-B6BF-2E010C5E4655"></a><h5 id="ADFNS-GUID-014A1091-206B-4455-B6BF-2E010C5E4655" class="sect5">Iterative Data Processing: Row-By-Row</h5>
                     <div>
                        <p>Of the iterative techniques, row-by-row processing is the most common.</p>
                        <p>A single process loops through a data set and operates on a single row a time. In a typical implementation, the application retrieves each row from the database, processes it in the middle tier, and then sends the row back to the database, which executes DML and commits.</p>
                        <p>Assume that your functional requirement is to query an external table named <code class="codeph">ext_scan_events</code>, and then insert its rows into a heap-organized staging table named <code class="codeph">stage1_scan_events</code>. The following PL/SQL block uses a row-by-row technique to meet this requirement:
                        </p><pre class="oac_no_warn" dir="ltr">declare
  cursor c is select s.* from ext_scan_events s;
  r c%rowtype;
begin
  open c;
  loop
    fetch c into r;
    exit when c%notfound;
    insert into stage1_scan_events d values r;
    commit;
  end loop;
  close c;
end;</pre><p>The row-by-row code uses a cursor loop to perform the following actions:</p>
                        <ol>
                           <li>
                              <p>Fetch a single row from <code class="codeph">ext_scan_events</code> to the application running in the client host, or exit the program if no more rows exist.
                              </p>
                           </li>
                           <li>
                              <p>Insert the row into <code class="codeph">stage1_scan_events</code>.
                              </p>
                           </li>
                           <li>
                              <p>Commit the preceding insert.</p>
                           </li>
                           <li>
                              <p>Return to Step 1.</p>
                           </li>
                        </ol>
                        <p>The row-by-row technique has the following advantages:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>It performs well on small data sets. Assume that <code class="codeph">ext_scan_events</code> contains 10,000 records. If the application processes each row in 1 millisecond, then the total processing time is 10 seconds.
                              </p>
                           </li>
                           <li>
                              <p>The looping algorithm is familiar to all professional developers, easy to write quickly, and easy to understand.</p>
                           </li>
                        </ul>
                        <p>The row-by-row technique has the following disadvantages: </p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Processing time can be unacceptably long for large data sets. If <code class="codeph">ext_scan_events</code> contains 1 billion rows, and if the application processes each row in an average of 1 miliseconds, then the total processing time is 12 days. Processing a trillion-row table requires <span class="italic">32 years</span>.
                              </p>
                           </li>
                           <li>
                              <p>The application executes serially, and thus cannot exploit the native parallel processing features of Oracle Database running on modern hardware. For example, the row-by-row technique cannot benefit from a multi-core computer, Oracle RAC, or Oracle Exadata Machine. For example, if the database host contains 16 CPUs and 32 cores, then 31 cores will be idle when the sole database server process reads or write each row. If multiple instances exist in an Oracle RAC deployment, then only one instance can process the data.</p>
                           </li>
                        </ul>
                     </div>
                  </div>
                  <div class="sect4"><a id="GUID-5B427623-E329-4BD5-9D60-B58B0C61A7C9" name="GUID-5B427623-E329-4BD5-9D60-B58B0C61A7C9"></a><h5 id="ADFNS-GUID-5B427623-E329-4BD5-9D60-B58B0C61A7C9" class="sect5">Iterative Data Processing: Arrays</h5>
                     <div>
                        <p>Array processing is identical to row-by-row processing, except that it processes a group of rows in each iteration rather than a single row.</p>
                        <p>Like the row-by-row technique, array processing is serial, which means that only one database server process operates on a group of rows at one time. In a typical array implementation, the application retrieves each group of rows from the database, processes it in the middle tier, and then sends the group back to the database, which performs DML for the group of rows, and then commits.</p>
                        <p>Assume that your functional requirement is the same as in the example in <span> Iterative Data Processing: Row-By-Row</span>: query an external table named <code class="codeph">ext_scan_events</code>, and then insert its rows into a heap-organized staging table named <code class="codeph">stage1_scan_events</code>. The following PL/SQL block, which you execute in SQL*Plus on a separate host from the database server, uses an array technique to meet this requirement:
                        </p><pre class="oac_no_warn" dir="ltr">declare
  cursor c is select s.* from ext_scan_events s;
  type t is table of c%rowtype index by binary_integer;
  a t;
  rows binary_integer := 0;
begin
  open c;
  loop
    fetch c bulk collect into a limit array_size;
    exit when a.count = 0;
    forall i in 1..a.count
      insert into stage1_scan_events d values a(i);
    commit;
  end loop;
  close c;
end;
</pre><p>The preceding code differs from the equivalent row-by-row code in using a <code class="codeph">BULK COLLECT</code> operator in the <code class="codeph">FETCH</code> statement, which is limited by the array_size value of type <code class="codeph">PLS_INTEGER</code>. For example, if array_size is set to 100, then the application fetches rows in groups of 100.
                        </p>
                        <p>The cursor loop performs the following sequence of actions:</p>
                        <ol>
                           <li>
                              <p>Fetch an array of rows from ext_scan_events to the application running in the client host, or exit the program when the loop counter equals 0.</p>
                           </li>
                           <li>
                              <p>Loop through the array of rows, and insert each row into the <code class="codeph">stage1_scan_events</code> table.
                              </p>
                           </li>
                           <li>
                              <p>Commit the preceding inserts.</p>
                           </li>
                           <li>
                              <p>Return to Step 1.</p>
                           </li>
                        </ol>
                        <p>In PL/SQL, the array code differs from the row-by-row code in using a counter rather than the cursor attribute <code class="codeph">c%notfound</code> to test the exit condition. The reason is that if the fetch collects the last group of rows in the table, then <code class="codeph">c%notfound</code> forces the loop to exit, which is undesired behavior. When using a counter, each fetch collects the specified number of rows, and when the collection is empty, the program exits.
                        </p>
                        <p>The array technique has the following advantages over the row-by-row technique:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>The array enables the application to process a group of rows at the same time, which means that it reduces network round trips, <code class="codeph">COMMIT</code> time, and the code path in the client and server. When combined, these factors can potentially reduce the total processing time by an order of magnitude
                              </p>
                           </li>
                           <li>
                              <p>The database is more efficient because the server process batches the inserts, and commits after every group of inserts rather than after every insert. Reducing the number of commits reduces the I/O load and lessens the probability of log sync wait events.</p>
                           </li>
                        </ul>
                        <p>The disadvantages of this technique are the same as for row-by-row processing. Processing time can be unacceptable for large data sets. For a trillion-row table, reducing processing time from 32 years to 3.2 years is still unacceptable. Also, the application must run serially on a single CPU core, and thus cannot exploit the native parallelism of Oracle Database. </p>
                        <div class="infoboxnotealso" id="GUID-5B427623-E329-4BD5-9D60-B58B0C61A7C9__NOTE-1412-CBE0106F">
                           <p class="notep1">See Also:</p>
                           <p><a href="rwp.html#GUID-014A1091-206B-4455-B6BF-2E010C5E4655" title="Of the iterative techniques, row-by-row processing is the most common.">Iterative Data Processing: Row-By-Row</a></p>
                        </div>
                     </div>
                  </div>
                  <div class="sect4"><a id="GUID-413B3E68-5590-4337-956B-B6CFC11FC2DD" name="GUID-413B3E68-5590-4337-956B-B6CFC11FC2DD"></a><h5 id="ADFNS-GUID-413B3E68-5590-4337-956B-B6CFC11FC2DD" class="sect5">Iterative Data Processing: Manual Parallelism</h5>
                     <div>
                        <p>Manual parallelism uses the same iterative algorithm as row-by-row and array processing, but enables multiple server processes to work on the job concurrently.</p>
                        <p>In a typical implementation, the application scans the source data multiple times, and then uses the <code class="codeph">ORA_HASH</code> function to divide the data among the parallel insert processes. 
                        </p>
                        <p>The <code class="codeph">ORA_HASH</code> function computes a hash value for a given expression. The function accepts three arguments: 
                        </p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><code class="codeph"><span class="codeinlineitalic">expr</span></code>, which is typically a column name
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph"><span class="codeinlineitalic">max_bucket</span></code>, which specifies the number of hash buckets
                              </p>
                           </li>
                           <li>
                              <p><code class="codeph"><span class="codeinlineitalic">seed_value</span></code>, which enables multiple results from the same data (the default is 0)
                              </p>
                           </li>
                        </ul>
                        <p>For example, the following statement divides the sales table into 10 buckets of rows, numbered 0 to 9, and returns the rows from bucket 1:</p><pre class="oac_no_warn" dir="ltr">SELECT * FROM sales WHERE ORA_HASH(cust_id, 9) = 1;</pre><p>If an application uses <code class="codeph">ORA_HASH</code> in this way, and if n hash buckets exists, then each server process operates on 1/<span class="italic">n</span> of the data.
                        </p>
                        <p>Assume the functional requirement is the same as in the row-by-row and array examples: to read scan events from source tables, and then insert them into the <code class="codeph">stage1_scan_events</code> table. The primary differences are as follows:
                        </p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>The scan events are stored in a mass of flat files. The <code class="codeph">ext_scan_events_dets</code> table describes these flat files. The <code class="codeph">ext_scan_events_dets.file_seq_nbr</code> column stores the numerical primary key, and the <code class="codeph">ext_file_name</code> column stores the file name.
                              </p>
                           </li>
                           <li>
                              <p>32 server processes must run in parallel, with each server process querying a different external table. The 32 external tables are named <code class="codeph">ext_scan_events_0</code> through ext_scan_events_31. However, each server process inserts into the same <code class="codeph">stage1_scan_events</code> table. 
                              </p>
                           </li>
                           <li>
                              <p>You use PL/SQL to achieve the parallelism by executing 32 threads of the same PL/SQL program, with each thread running simultaneously as a separate job managed by Oracle Scheduler. A job is the combination of a schedule and a program.</p>
                           </li>
                        </ul>
                        <p>The following PL/SQL code, which you execute in SQL*Plus on a separate host from the database server, uses manual parallellism:</p><pre class="oac_no_warn" dir="ltr">declare
  sqlstmt varchar2(1024) := q'[
-- BEGIN embedded anonymous block
  cursor c is select s.* from ext_scan_events_${thr} s;
  type t is table of c%rowtype index by binary_integer;
  a t;
  rows binary_integer := 0;
begin
  for r in (select ext_file_name from ext_scan_events_dets where ora_hash(file_seq_nbr,${thrs}) = ${thr})
  loop
    execute immediate
      'alter table ext_scan_events_${thr} location' || '(' || r.ext_file_name || ')';
    open c;
    loop
      fetch c bulk collect into a limit ${array_size};
      exit when a.count = 0;
      forall i in 1..a.count
        insert into stage1_scan_events d values a(i);
      commit;
--  demo instrumentation
      rows := rows + a.count; if rows &gt; 1e3 then exit when not sd_control.p_progress('loading','userdefined',rows); rows := 0; end if;
    end loop;
    close c;
  end loop;
end;
-- END   embedded anonymous block
]';

begin
  sqlstmt := replace(sqlstmt, '${array_size}', to_char(array_size));
  sqlstmt := replace(sqlstmt, '${thr}', thr);
  sqlstmt := replace(sqlstmt, '${thrs}', thrs);
  execute immediate sqlstmt;
end;
</pre><p>This program has three iterative constructs, from outer to inner:</p>
                        <ol>
                           <li>
                              <p>An outer <code class="codeph">FOR LOOP</code> that retrieves names of flat files, and uses DDL to specify the flat file name as the location of an external table
                              </p>
                           </li>
                           <li>
                              <p>A middle <code class="codeph">LOOP</code> statement that fetches groups of rows from a query of the external table.
                              </p>
                           </li>
                           <li>
                              <p>An innermost <code class="codeph">FORALL</code> statement that iterates through each group and inserts the rows
                              </p>
                           </li>
                        </ol>
                        <p>In this sample program, you set <code class="codeph">$thrs</code> to 31 in every job, and set <code class="codeph">$thr</code> to a different value between 0 and 31 in every job. For example, job 1 might have <code class="codeph">$thr</code> set to 0, job 2 might have <code class="codeph">$thr</code> set to 1, and so on.
                        </p>
                        <p>In the program executed by the first job, with $thr set to 0, the outer <code class="codeph">FOR LOOP</code> iterates through the results of the following query:
                        </p><pre class="oac_no_warn" dir="ltr">select ext_file_name 
from   ext_scan_events_dets 
where  ora_hash(file_seq_nbr,31) = 0</pre><p>The <code class="codeph">ORA_HASH</code> function divides the <code class="codeph">ext_scan_events_dets</code> table into 32 evenly distributed buckets, and then the <code class="codeph">SELECT</code> statement retrieves the file names for bucket 0. For example, the query result set might contain the following file names:
                        </p><pre class="oac_no_warn" dir="ltr">/disk1/scan_ev_101
/disk2/scan_ev_003
/disk1/scan_ev_077
...
/disk4/scan_ev_314</pre><p>The middle <code class="codeph">LOOP</code> iterates through the list of file names. For example, the first file name in the result set might be <code class="codeph">/disk1/scan_ev_101</code>. For job 1 the external table is named <code class="codeph">ext_scan_events_0</code>, so the first iteration of the <code class="codeph">LOOP</code> changes the location of this table as follows:
                        </p><pre class="oac_no_warn" dir="ltr">alter table ext_scan_events_0 location(/disk1/scan_ev_101);</pre><p>In the innermost <code class="codeph">FORALL</code> statement, the <code class="codeph">BULK COLLECT</code> operator retrieves rows from the <code class="codeph">ext_scan_events_0</code> table into an array, inserts the rows into the <code class="codeph">stage1_scan_events</code> table, and then commits the bulk insert. When the program exits the <code class="codeph">FORALL</code> statement, the program proceeds to the next item in the loop, changes the file location of the external table to <code class="codeph">/disk2/scan_ev_003</code>, and then queries, inserts, and commits rows as in the previous iteration. Job 1 continues processing in this way until all records contained in the flat files corresponding to hash bucket 0 have been inserted in the <code class="codeph">stage1_scan_events</code> table.
                        </p>
                        <p>While job 1 is executing, the other 31 Oracle Scheduler jobs execute in parallel. For example, job 2 sets <code class="codeph">$thr</code> to 1, which defines the cursor as a query of table <code class="codeph">ext_scan_events_1</code>, and so on through job 32, which sets <code class="codeph">$thr</code> to 31 and defines the cursor as a query of table <code class="codeph">ext_scan_events_31</code>. In this way, each job simultaneously reads a different subset of the scan event files, and inserts the records from its subset into the same <code class="codeph">stage1_scan_events</code> table.
                        </p>
                        <p>The manual parallelism technique has the following advantages over the alternative iterative techniques:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>It performs far better on large data sets because server processes are working in parallel. For example, if 32 processes are dividing the work, and if the database has sufficient CPU and memory resources and experiences no contention, then the database might perform 32 insert jobs in the time that the array technique took to perform a single job. The performance gain for a large data set is often an order of magnitude greater than serial techniques.</p>
                           </li>
                           <li>
                              <p>When the application uses <code class="codeph">ORA_HASH</code> to distribute the workload, each thread of execution can access the same amount of data. If each thread reads and writes the same amount of data, then the parallel processes can finish at the same time, which means that the database utilizes the hardware for as long as the application takes to run.
                              </p>
                           </li>
                        </ul>
                        <p>The manual parallelism technique has the following disadvantages:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>The code is relatively lengthy, complicated, and difficult to understand. The algorithm is complicated because the work of distributing the workload over many threads falls to the developer rather than the database. Effectively, the application runs serial algorithms in parallel rather than running a parallel algorithm.</p>
                           </li>
                           <li>
                              <p>Typically, the startup costs of dividing the data have a fixed overhead. The application must perform a certain amount of preparatory work before the database can begin the main work, which is processing the rows in parallel. This startup limitation does not apply to the competing techniques, which do not divide the data.</p>
                           </li>
                           <li>
                              <p>If multiple threads perform the same operations on a common set of database objects, then lock and latch contention is possible. For example, if 32 different server processes are attempting to update the same set of buffers, then buffer busy waits are probable. Also, if multiple server processes are issuing <code class="codeph">COMMIT</code> statements at roughly the same time, then log file sync waits are probable.
                              </p>
                           </li>
                           <li>
                              <p>Parallel processing consumes significant CPU resources compared to the competing iterative techniques. If the database host does not have sufficient cores available to process the threads simultaneously, then performance suffers. For example, if only 4 cores are available to 32 threads, then the probability of a thread having CPU available at a given time is 1/8.</p>
                           </li>
                        </ul>
                     </div>
                  </div>
               </div>
               <div class="sect3"><a id="GUID-49AA324B-A060-4284-9841-A6E27DB9E45C" name="GUID-49AA324B-A060-4284-9841-A6E27DB9E45C"></a><h4 id="ADFNS-GUID-49AA324B-A060-4284-9841-A6E27DB9E45C" class="sect4">Set-Based Processing</h4>
                  <div>
                     <p>Set-based processing is a SQL technique that processes a data set inside the database.</p>
                     <p>In a set-based model, the SQL statement defines the result, and allows the database to determine the most efficient way to obtain it. In contrast, iterative algorithms use conditional logic to pull each row or group of rows from the database to the client application, process the data on the client, and then send the data back to the database. Set-based processing eliminates the network round-trip and database API overhead because the data never leaves the database. It reduces the number of COMMITs.</p>
                     <p>Assume the same functional requirement as in the previous examples. The following SQL statements meet this requirement using a set-based algorithm:</p><pre class="oac_no_warn" dir="ltr">alter session enable parallel dml;
insert /*+ APPEND */ into stage1_scan_events d
  select s.* from ext_scan_events s;
commit;
</pre><p>Because the <code class="codeph">INSERT</code> statement contains a subquery of the <code class="codeph">ext_scan_events</code> table, a <span class="italic">single</span> SQL statement reads and writes all rows. Also, the application executes a <span class="italic">single</span> <code class="codeph">COMMIT</code> after the database has inserted all rows. In contrast, iterative applications execute a <code class="codeph">COMMIT</code> after the insert of each row or each group of rows.
                     </p>
                     <p>The set-based technique has significant advantages over iterative techniques:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>As demonstrated in Oracle Real-World  Performance demonstrations and classes, the performance on large data sets is orders of magnitude faster. It is not unusual for the run time of a program to drop from several hours to several seconds. The improvement in performance for large data sets is so profound that iterative techniques become extremely difficult to justify.</p>
                        </li>
                        <li>
                           <p>A side-effect of the dramatic increase in processing speed is that DBAs can eliminate long-running and error-prone batch jobs, and innovate business processes in real time. For example, instead of running a 6-hour batch job every night, a business can run a 12-seconds job as needed during the day.</p>
                        </li>
                        <li>
                           <p>The length of the code is significantly shorter, a short as two or three lines of code, because SQL defines the result and not the access method. This means that the database, rather than the application, decides the best way to divide, retrieve, and manipulate the rows.</p>
                        </li>
                        <li>
                           <p>In contrast to manual parallelism, parallel DML is optimized for performance because the database, rather than the application, manages the processes. Thus, it is not necessary to divide the workload manually in the client application, and hope that each process finishes at the same time.</p>
                        </li>
                        <li>
                           <p>When joining data sets, the database automatically uses highly efficient hash joins instead of relatively inefficient application-level loops.</p>
                        </li>
                        <li>
                           <p>The <code class="codeph">APPEND</code> hint forces a direct-path load, which means that the database creates no redo and undo, thereby avoiding the waste of I/O and CPU. In typical ETL workloads, the buffer cache poses a problem. Modifying data inside the buffer cache, and then writing back the data and its associated undo and redo, consumes significant resources. Because the buffer cache cannot manage blocks fast enough, and because the CPU costs of manipulating blocks into the buffer cache and back out again (usually one 8 K block at a time) are high, both the database writer and server processes must work extremely hard to keep up with the volume of buffers.
                           </p>
                        </li>
                     </ul>
                     <p>The disadvantages of set-based processing:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>The techniques are unfamiliar to many database developers, so they are more difficult. The <code class="codeph">INSERT</code> example is relatively simple. However, more complicated algorithms required more complicated statements that may require multiple outer joins. Developers who are not familiar with pipelining outer joins and using <code class="codeph">WITH</code> clauses and <code class="codeph">CASE</code> statements may be daunted by the prospect of both writing and understanding set-based code.
                           </p>
                        </li>
                        <li>
                           <p>Because a set-based model is completely different from an iterative model, changing it requires completely rewriting the source code. In contrast, changing row-by-row code to array-based code is relatively trivial.</p>
                        </li>
                     </ul>
                     <p>Despite the disadvantages of set-based processing, the Oracle Real-World  Performance group believes that the enormous performance gains for large data sets justify the effort.</p>
                     <div class="infoboxnote" id="GUID-49AA324B-A060-4284-9841-A6E27DB9E45C__NOTE-1410-77B77BA1">
                        <p class="notep1">Videos:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><a href="https://www.oracle.com/pls/topic/lookup?ctx=en/database/oracle/oracle-database/19/adfns&amp;id=vid_oll_rwp_set_based" target="_blank">RWP #7 Set-Based Processing</a></p>
                           </li>
                           <li>
                              <p><a href="https://www.oracle.com/pls/topic/lookup?ctx=en/database/oracle/oracle-database/19/adfns&amp;id=vid_oll_rwp_set_parallel" target="_blank">RWP #8: Set-Based Parallel Processing</a></p>
                           </li>
                           <li>
                              <p><a href="https://www.oracle.com/pls/topic/lookup?ctx=en/database/oracle/oracle-database/19/adfns&amp;id=vid_oll_rwp_dedup" target="_blank">RWP #9: Set-Based Processing--Data Deduplication</a></p>
                           </li>
                           <li>
                              <p><a href="https://www.oracle.com/pls/topic/lookup?ctx=en/database/oracle/oracle-database/19/adfns&amp;id=vid_oll_rwp_transform" target="_blank">RWP #10: Set-Based Processing--Data Transformations</a></p>
                           </li>
                           <li>
                              <p><a href="https://www.oracle.com/pls/topic/lookup?ctx=en/database/oracle/oracle-database/19/adfns&amp;id=vid_oll_rwp_agg" target="_blank">RWP #11: Set-Based Processing--Data Aggregation</a></p>
                           </li>
                        </ul>
                     </div>
                  </div>
               </div>
            </div>
         </div>
      </article>
   </body>
</html>