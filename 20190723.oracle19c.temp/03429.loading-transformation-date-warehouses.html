<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xml:lang="en-us" lang="en-us">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <title>Loading and Transformation in Data Warehouses</title>
      <meta property="og:site_name" content="Oracle Help Center">
      <meta property="og:title" content="Data Warehousing Guide">
      <meta property="og:description" content="">
      <link rel="stylesheet" href="/sp_common/book-template/ohc-book-template/css/book.css">
      <link rel="shortcut icon" href="/sp_common/book-template/ohc-common/img/favicon.ico">
      <meta name="application-name" content="Data Warehousing Guide">
      <meta name="generator" content="DITA Open Toolkit version 1.8.5 (Mode = doc)">
      <meta name="plugin" content="SP_docbuilder HTML plugin release 18.2.2">
      <link rel="alternate" href="database-data-warehousing-guide.pdf" title="PDF File" type="application/pdf">
      <meta name="robots" content="all">
      <link rel="schema.dcterms" href="http://purl.org/dc/terms/">
      <meta name="dcterms.created" content="2019-01-09T00:20:13-08:00">
      
      <meta name="dcterms.dateCopyrighted" content="2001, 2019">
      <meta name="dcterms.category" content="database">
      <meta name="dcterms.identifier" content="E96243-01">
      
      <meta name="dcterms.product" content="en/database/oracle/oracle-database/19">
      
      <link rel="prev" href="transportation-data-warehouses.html" title="Previous" type="text/html">
      <link rel="next" href="part-relational-analytics.html" title="Next" type="text/html">
      <script>
        document.write('<style type="text/css">');
        document.write('body > .noscript, body > .noscript ~ * { visibility: hidden; }');
        document.write('</style>');
     </script>
      <script data-main="/sp_common/book-template/ohc-book-template/js/book-config" src="/sp_common/book-template/requirejs/require.js"></script>
      <script>
            if (window.require === undefined) {
                document.write('<script data-main="sp_common/book-template/ohc-book-template/js/book-config" src="sp_common/book-template/requirejs/require.js"><\/script>');
                document.write('<link href="sp_common/book-template/ohc-book-template/css/book.css" rel="stylesheet"/>');
            }
        </script>
      <script type="application/json" id="ssot-metadata">{"primary":{"category":{"short_name":"database","element_name":"Database","display_in_url":true},"suite":{"short_name":"oracle","element_name":"Oracle","display_in_url":true},"product_group":{"short_name":"not-applicable","element_name":"Not applicable","display_in_url":false},"product":{"short_name":"oracle-database","element_name":"Oracle Database","display_in_url":true},"release":{"short_name":"19","element_name":"Release 19","display_in_url":true}}}</script>
      
    <meta name="dcterms.title" content="Database Data Warehousing Guide">
    <meta name="dcterms.isVersionOf" content="DWHSG">
    <meta name="dcterms.release" content="Release 19">
  </head>
   <body>
      <div class="noscript alert alert-danger text-center" role="alert">
         <a href="transportation-data-warehouses.html" class="pull-left"><span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span>Previous</a>
         <a href="part-relational-analytics.html" class="pull-right">Next<span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span></a>
         <span class="fa fa-exclamation-triangle" aria-hidden="true"></span> JavaScript must be enabled to correctly display this content
        
      </div>
      <article>
         <header>
            <ol class="breadcrumb" vocab="http://schema.org/" typeof="BreadcrumbList">
               <li property="itemListElement" typeof="ListItem"><a href="index.html" property="item" typeof="WebPage"><span property="name">Data Warehousing Guide</span></a></li>
               <li property="itemListElement" typeof="ListItem"><a href="part-etl.html" property="item" typeof="WebPage"><span property="name">Data Movement/ETL </span></a></li>
               <li class="active" property="itemListElement" typeof="ListItem">Loading and Transformation in Data Warehouses</li>
            </ol>
            <a id="GUID-5B2CC8B6-8503-4B41-A75E-79A4925FCE4B" name="GUID-5B2CC8B6-8503-4B41-A75E-79A4925FCE4B"></a>
            
            <h2 id="DWHSG-GUID-5B2CC8B6-8503-4B41-A75E-79A4925FCE4B" class="sect2"><span class="enumeration_chapter">18 </span>Loading and Transformation in Data Warehouses
            </h2>
         </header>
         <div class="ind">
            <div>
               <p>This chapter helps you create and manage a data warehouse, and discusses:</p>
               <ul style="list-style-type: disc;">
                  <li>
                     <p><a href="loading-transformation-date-warehouses.html#GUID-D3F12AE4-CF2B-4F67-B027-C3CD7B86E9F1" title="You can optimize bulk updates to the table by using the EXECUTE_UPDATE procedure. Because the updates are not logged in the redo log, performance is optimized.Because ETL can become complex and suffer from poor performance, Oracle Database provides a user interface that enables you to monitor and report on database operations that are part of an ETL plan.">Overview of Loading and Transformation in Data Warehouses</a></p>
                  </li>
                  <li>
                     <p><a href="loading-transformation-date-warehouses.html#GUID-6DECC3F7-758E-45E3-88EE-F2B740AB7C13">Loading Mechanisms for Data Warehouses</a></p>
                  </li>
                  <li>
                     <p><a href="loading-transformation-date-warehouses.html#GUID-D8DA5FB4-7F4C-42C5-828D-9150A5699186">Transformation Mechanisms in Data Warehouses</a></p>
                  </li>
                  <li>
                     <p><a href="loading-transformation-date-warehouses.html#GUID-DAD3F208-A1CB-4491-8D61-D4640B51286A" title="External data that is used during the data transformation process may sometimes be inaccurate thereby causing data conversion errors. Certain SQL functions can be used to handle data conversion errors.">Error Logging and Handling Mechanisms</a></p>
                  </li>
                  <li>
                     <p><a href="loading-transformation-date-warehouses.html#GUID-DD11528E-EE2A-4640-B8F1-75E6D3EB08F6">Loading and Transformation Scenarios</a></p>
                  </li>
               </ul>
            </div><a id="DWHSG8304"></a><div class="props_rev_3"><a id="GUID-D3F12AE4-CF2B-4F67-B027-C3CD7B86E9F1" name="GUID-D3F12AE4-CF2B-4F67-B027-C3CD7B86E9F1"></a><h3 id="DWHSG-GUID-D3F12AE4-CF2B-4F67-B027-C3CD7B86E9F1" class="sect3"><span class="enumeration_section">18.1 </span>Overview of Loading and Transformation in Data Warehouses
               </h3>
               <div>
                  <p><a id="d63021e75" class="indexterm-anchor"></a>Data transformations are often the most complex and, in terms of processing time, the most costly part of the extraction, transformation, and loading (ETL) process. They can range from simple data conversions to extremely complex data scrubbing techniques. Many, if not all, data transformations can occur within an Oracle database, although transformations are often implemented outside of the database (for example, on flat files) as well.
                  </p>
                  <p>This chapter introduces techniques for implementing scalable and efficient data transformations within the Oracle Database. The examples in this chapter are relatively simple. Real-world data transformations are often considerably more complex. However, the transformation techniques introduced in this chapter meet the majority of real-world data transformation requirements, often with more scalability and less programming than alternative approaches.</p>
                  <p>This chapter does not seek to illustrate all of the typical transformations that would be encountered in a data warehouse, but to demonstrate the types of fundamental technology that can be applied to implement these transformations and to provide guidance in how to choose the best techniques.</p>
               </div><a id="DWHSG8305"></a><div class="props_rev_3"><a id="GUID-1B38D45D-1860-44D6-98A4-9B089C4759A5" name="GUID-1B38D45D-1860-44D6-98A4-9B089C4759A5"></a><h4 id="DWHSG-GUID-1B38D45D-1860-44D6-98A4-9B089C4759A5" class="sect4"><span class="enumeration_section">18.1.1 </span>Data Warehouses: Transformation Flow
                  </h4>
                  <div>
                     <p>From an architectural perspective, you can transform your data in the following ways:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><a href="loading-transformation-date-warehouses.html#GUID-AF6D2F31-0BAE-421E-A812-62D38C3645B8">Multistage Data Transformation in Data Warehouses</a></p>
                        </li>
                        <li>
                           <p><a href="loading-transformation-date-warehouses.html#GUID-FA110310-B713-4165-8F48-EC5E869E1F8F">Pipelined Data Transformation in Data Warehouses</a></p>
                        </li>
                        <li>
                           <p><a href="loading-transformation-date-warehouses.html#GUID-48A039BC-D1EC-4E6A-9552-E3DFDA33D4E4">Staging Area in Data Warehouses</a></p>
                        </li>
                     </ul>
                  </div><a id="DWHSG8307"></a><a id="DWHSG8306"></a><div class="props_rev_3"><a id="GUID-AF6D2F31-0BAE-421E-A812-62D38C3645B8" name="GUID-AF6D2F31-0BAE-421E-A812-62D38C3645B8"></a><h5 id="DWHSG-GUID-AF6D2F31-0BAE-421E-A812-62D38C3645B8" class="sect5"><span class="enumeration_section">18.1.1.1 </span>Multistage Data Transformation in Data Warehouses
                     </h5>
                     <div>
                        <p>The data<a id="d63021e143" class="indexterm-anchor"></a> transformation logic for most data warehouses consists of multiple steps. For example, in transforming new records to be inserted into a sales table, there may be separate logical transformation steps to validate each dimension key.
                        </p>
                        <p><a href="loading-transformation-date-warehouses.html#GUID-AF6D2F31-0BAE-421E-A812-62D38C3645B8__BABCAHAJ">Figure 18-1</a> offers a graphical way of looking at the transformation logic.
                        </p>
                        <div class="figure" id="GUID-AF6D2F31-0BAE-421E-A812-62D38C3645B8__BABCAHAJ">
                           <p class="titleinfigure">Figure 18-1 Multistage Data Transformation</p><img src="img/dwhsg025.gif" alt="Description of Figure 18-1 follows" title="Description of Figure 18-1 follows" longdesc="img_text/dwhsg025.html"><br><a href="img_text/dwhsg025.html">Description of "Figure 18-1 Multistage Data Transformation"</a></div>
                        <!-- class="figure" -->
                        <p>When using Oracle Database as a transformation engine, a common strategy is to implement each transformation as a separate SQL operation and to create a separate, temporary staging table (such as the tables <code class="codeph">new_sales_step1</code> and <code class="codeph">new_sales_step2</code> in <a href="loading-transformation-date-warehouses.html#GUID-AF6D2F31-0BAE-421E-A812-62D38C3645B8__BABCAHAJ">Figure 18-1</a>) to store the incremental results for each step. This load-then-transform strategy also provides a natural checkpointing scheme to the entire transformation process, which enables the process to be more easily monitored and restarted. However, a disadvantage to multistaging is that the space and time requirements increase.
                        </p>
                        <p>It may also be possible to combine many simple logical transformations into a single SQL statement or single PL/SQL procedure. Doing so may provide better performance than performing each step independently, but it may also introduce difficulties in modifying, adding, or dropping individual transformations, as well as recovering from failed transformations.</p>
                     </div>
                  </div><a id="DWHSG8309"></a><a id="DWHSG8308"></a><div class="props_rev_3"><a id="GUID-FA110310-B713-4165-8F48-EC5E869E1F8F" name="GUID-FA110310-B713-4165-8F48-EC5E869E1F8F"></a><h5 id="DWHSG-GUID-FA110310-B713-4165-8F48-EC5E869E1F8F" class="sect5"><span class="enumeration_section">18.1.1.2 </span>Pipelined Data Transformation in Data Warehouses
                     </h5>
                     <div>
                        <p>The ETL process flow can be changed dramatically and the database becomes an integral part of the ETL solution<a id="d63021e191" class="indexterm-anchor"></a>.
                        </p>
                        <p>The new functionality renders some of the former necessary process steps obsolete while some others can be remodeled to enhance the data flow and the data transformation to become more scalable and non-interruptive. The task shifts from serial transform-then-load process (with most of the tasks done outside the database) or load-then-transform process, to an enhanced transform-while-loading. </p>
                        <p>Oracle offers a wide variety of new capabilities to address all the issues and tasks relevant in an ETL scenario. It is important to understand that the database offers toolkit functionality rather than trying to address a one-size-fits-all solution. The underlying database has to enable the most appropriate ETL process flow for a specific customer need, and not dictate or constrain it from a technical perspective. <a href="loading-transformation-date-warehouses.html#GUID-FA110310-B713-4165-8F48-EC5E869E1F8F__I1007647">Figure 18-2</a> illustrates the new functionality, which is discussed throughout later sections.
                        </p>
                        <div class="figure" id="GUID-FA110310-B713-4165-8F48-EC5E869E1F8F__I1007647">
                           <p class="titleinfigure">Figure 18-2 Pipelined Data Transformation</p><img src="img/dwhsg107.gif" alt="Description of Figure 18-2 follows" title="Description of Figure 18-2 follows" longdesc="img_text/dwhsg107.html"><br><a href="img_text/dwhsg107.html">Description of "Figure 18-2 Pipelined Data Transformation"</a></div>
                        <!-- class="figure" -->
                     </div>
                  </div><a id="DWHSG8953"></a><div class="props_rev_3"><a id="GUID-48A039BC-D1EC-4E6A-9552-E3DFDA33D4E4" name="GUID-48A039BC-D1EC-4E6A-9552-E3DFDA33D4E4"></a><h5 id="DWHSG-GUID-48A039BC-D1EC-4E6A-9552-E3DFDA33D4E4" class="sect5"><span class="enumeration_section">18.1.1.3 </span>Staging Area in Data Warehouses
                     </h5>
                     <div>
                        <p>The overall speed of your load is determined by how quickly the raw data can be read from the staging area and written to the target table in the database. It is highly recommended that you stage your raw data across as many physical disks as possible to ensure the reading of the raw data is not a bottleneck during the load.</p>
                        <p>An excellent place to stage the data is in an Oracle Database File System (DBFS). DBFS creates a mountable file system which can be used to access files stored in the database as SecureFiles LOBs. DBFS is similar to NFS in that it provides a shared network file system that looks like a local file system. Oracle recommends that you create the DBFS in a separate database from the data warehouse, and that the file system be mounted using the <code class="codeph">DIRECT_IO</code> option to avoid contention on the system page cache while moving the raw data files in and out of the file system. More information on setting up DBFS can be found in <a href="../adlob/introducing-database-file-system.html#ADLOB-GUID-B7A83817-F0D6-4A09-AE98-DFC966783109" target="_blank"><span><cite>Oracle Database SecureFiles and Large Objects Developer's Guide</cite></span></a>.
                        </p>
                     </div>
                  </div>
               </div>
               <div class="sect3"><a id="GUID-44B2D063-DAC4-4CFC-A776-FF501AAEDEE7" name="GUID-44B2D063-DAC4-4CFC-A776-FF501AAEDEE7"></a><h4 id="DWHSG-GUID-44B2D063-DAC4-4CFC-A776-FF501AAEDEE7" class="sect4"><span class="enumeration_section">18.1.2 </span>About Batch Updates and Online Table Redefinition
                  </h4>
                  <div>
                     <p>You can optimize bulk updates to the table by using the <code class="codeph">EXECUTE_UPDATE</code> procedure. Because the updates are not logged in the redo log, performance is optimized.
                     </p>
                     <p></p>
                     <p>The <code class="codeph">DBMS_REDEFINITION.EXECUTE_UPDATE</code> procedure allows you to run <code class="codeph">UPDATE</code> statements in direct insert mode. Because redo is not logged during this operation, you cannot recover the redefinition and data updates using media recovery.  To maintain recoverability, it is recommended that a database or tablespace backup be performed before the redefinition begins.
                     </p>
                     <div class="infoboxnotealso" id="GUID-44B2D063-DAC4-4CFC-A776-FF501AAEDEE7__GUID-70324A39-FCDF-4E13-BECE-682BCC0A7421">
                        <p class="notep1">See Also:</p>
                        <p><a href="../admin/managing-tables.html#ADMIN-GUID-43794F5A-1B13-4E97-B4DD-31AEB9633E9A" target="_blank"><span><cite>Oracle Database Administrator’s Guide</cite></span></a></p>
                     </div>
                  </div>
               </div>
               <div class="sect3"><a id="GUID-D66210E5-9F35-45C8-B310-FC4D764B4FEC" name="GUID-D66210E5-9F35-45C8-B310-FC4D764B4FEC"></a><h4 id="DWHSG-GUID-D66210E5-9F35-45C8-B310-FC4D764B4FEC" class="sect4"><span class="enumeration_section">18.1.3 </span>Overview of Monitoring ETL Operations
                  </h4>
                  <div>
                     <p>Because ETL can become complex and suffer from poor performance, Oracle Database provides a user interface that enables you to monitor and report on database operations that are part of an ETL plan.</p>
                     <p></p>
                     <p>A database operation is a user-defined logical object that contains a set of related database tasks, for example an ETL processing job, defined by end users or application code. Each database operation is uniquely identified by its name and execution ID and can be executed multiple times. </p>
                     <p>Database operation monitoring is extremely useful for troubleshooting a suboptimally performing job and helps to identify where and how much resources are being consumed at any given step. It enables you to track related information, identify performance bottlenecks, and reduce the time to tune database performance problems. Starting with Oracle Database 12<span class="italic">c</span> Release 2 (12.2), you can begin a database operation on an arbitrary session by specifying its session ID and serial number in the <code class="codeph">DBMS_SQL_MONITOR.BEGIN_OPERATION</code> function.
                     </p>
                     <div class="infoboxnotealso" id="GUID-D66210E5-9F35-45C8-B310-FC4D764B4FEC__GUID-B74F4813-535B-4F44-BD16-88C9C9499433">
                        <p class="notep1">See Also:</p>
                        <p><a href="../tgsql/monitoring-database-operations.html#TGSQL-GUID-007E5BAE-B07D-4BD1-9485-DE8D260BF862" target="_blank"><span><cite>Oracle Database SQL Tuning Guide</cite></span></a></p>
                     </div>
                  </div>
               </div>
            </div><a id="DWHSG8310"></a><div class="props_rev_3"><a id="GUID-6DECC3F7-758E-45E3-88EE-F2B740AB7C13" name="GUID-6DECC3F7-758E-45E3-88EE-F2B740AB7C13"></a><h3 id="DWHSG-GUID-6DECC3F7-758E-45E3-88EE-F2B740AB7C13" class="sect3"><span class="enumeration_section">18.2 </span>Loading Mechanisms for Data Warehouses
               </h3>
               <div>
                  <p>You can use the following mechanisms for loading a data warehouse:</p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p><a href="loading-transformation-date-warehouses.html#GUID-075B9E66-3C42-4164-BF70-B144C0BEC4F0">Loading a Data Warehouse with SQL*Loader</a></p>
                     </li>
                     <li>
                        <p><a href="loading-transformation-date-warehouses.html#GUID-0C48B004-54C8-48A3-BBF8-6C69BB19F15E">Loading a Data Warehouse with External Tables</a></p>
                     </li>
                     <li>
                        <p><a href="loading-transformation-date-warehouses.html#GUID-16CA33C9-77A1-494A-8170-F4703D2C0447">Loading a Data Warehouse with OCI and Direct-Path APIs</a></p>
                     </li>
                     <li>
                        <p><a href="loading-transformation-date-warehouses.html#GUID-5904B997-7D60-4553-82CA-91709E040F5A">Loading a Data Warehouse with Export/Import</a></p>
                     </li>
                  </ul>
               </div><a id="DWHSG8311"></a><div class="props_rev_3"><a id="GUID-075B9E66-3C42-4164-BF70-B144C0BEC4F0" name="GUID-075B9E66-3C42-4164-BF70-B144C0BEC4F0"></a><h4 id="DWHSG-GUID-075B9E66-3C42-4164-BF70-B144C0BEC4F0" class="sect4"><span class="enumeration_section">18.2.1 </span>Loading a Data Warehouse with SQL*Loader
                  </h4>
                  <div>
                     <div class="section">
                        <p><a id="d63021e396" class="indexterm-anchor"></a>Before any data transformations can occur within the database, the raw data must become accessible for the database. One approach is to load it into the database. <a href="transportation-data-warehouses.html#GUID-3CC5E89C-A354-4F58-BC2A-D9DF439357E5">Transportation in Data Warehouses</a>, discusses several techniques for transporting data to an Oracle data warehouse. Perhaps the most common technique for transporting data is by way of flat files.
                        </p>
                        <p>SQL*Loader is used to move data from flat files into an Oracle data warehouse. During this data load, SQL*Loader can also be used to implement basic data transformations. When using direct-path SQL*Loader, basic data manipulation, such as data type conversion and simple <code class="codeph">NULL</code> handling, can be automatically resolved during the data load. Most data warehouses use direct-path loading for performance reasons. 
                        </p>
                        <p>The conventional-path loader provides broader capabilities for data transformation than a direct-path loader: SQL functions can be applied to any column as those values are being loaded. This provides a rich capability for transformations during the data load. However, the conventional-path loader is slower than direct-path loader. For these reasons, the conventional-path loader should be considered primarily for loading and transforming smaller amounts of data.</p>
                        <p>Data warehouses can use direct path mode to run batch updates to avoid the overhead of maintaining redo data. You can run batch updates on a table during online table redefinition. </p>
                        <p>The following is a simple example of a SQL*Loader control file to load data into the <code class="codeph">sales</code> table of the <code class="codeph">sh</code> sample schema from an external file <code class="codeph">sh_sales.dat</code>. The external flat file <code class="codeph">sh_sales.dat</code> consists of sales transaction data, aggregated on a daily level. Not all columns of this external file are loaded into <code class="codeph">sales</code>. This external file is also used as a source for loading the second fact table of the <code class="codeph">sh</code> sample schema, which is done using an external table:
                        </p>
                        <p>The following shows the control file (<code class="codeph">sh_sales.ctl</code>) loading the <code class="codeph">sales</code> table:
                        </p><pre class="oac_no_warn" dir="ltr">LOAD DATA INFILE sh_sales.dat APPEND INTO TABLE sales
FIELDS TERMINATED BY "|"
(PROD_ID, CUST_ID, TIME_ID, CHANNEL_ID, PROMO_ID, QUANTITY_SOLD, AMOUNT_SOLD)
 </pre><p>It can be loaded with the following command:</p><pre class="oac_no_warn" dir="ltr">$  sqlldr control=sh_sales.ctl direct=true
Username:
Password:
</pre><p>In the case of SQL*Loader Express mode, you do not use a control file. Instead, it uses table column definitions to determine input data types.</p>
                        <div class="infoboxnotealso" id="GUID-075B9E66-3C42-4164-BF70-B144C0BEC4F0__GUID-9803962C-26EA-41CC-B137-F26225C73761">
                           <p class="notep1">See Also:</p>
                           <ul style="list-style-type: disc;">
                              <li>
                                 <p><a href="../sutil/oracle-sql-loader-commands.html#SUTIL-GUID-CD662CD8-DAA7-4A30-BC84-546E4C40DB31" target="_blank"><span><cite>Oracle Database Utilities</cite></span></a> for more information
                                 </p>
                              </li>
                              <li>
                                 <p><a href="../admin/managing-tables.html#ADMIN-GUID-43794F5A-1B13-4E97-B4DD-31AEB9633E9A" target="_blank"><span><cite>Oracle Database Administrator’s Guide</cite></span></a> for information about bulk updates using the <code class="codeph">DBMS_REDEFINITION</code> package
                                 </p>
                              </li>
                           </ul>
                        </div>
                     </div>
                     <!-- class="section" -->
                  </div>
               </div><a id="DWHSG8312"></a><div class="props_rev_3"><a id="GUID-0C48B004-54C8-48A3-BBF8-6C69BB19F15E" name="GUID-0C48B004-54C8-48A3-BBF8-6C69BB19F15E"></a><h4 id="DWHSG-GUID-0C48B004-54C8-48A3-BBF8-6C69BB19F15E" class="sect4"><span class="enumeration_section">18.2.2 </span>Loading a Data Warehouse with External Tables
                  </h4>
                  <div>
                     <div class="section">
                        <p>Another appr<a id="d63021e495" class="indexterm-anchor"></a><a id="d63021e497" class="indexterm-anchor"></a>oach for handling external data sources is using external tables. Oracle's external table feature enables you to use external data as a virtual table that can be queried and joined directly and in parallel without requiring the external data to be first loaded in the database. You can then use SQL, PL/SQL, and Java to access the external data.
                        </p>
                        <p></p>
                        <p>External tables enable the pipelining of the loading phase with the transformation phase. The transformation process can be merged with the loading process without any interruption of the data streaming. It is no longer necessary to stage the data inside the database for further processing inside the database, such as comparison or transformation. For example, the conversion functionality of a conventional load can be used for a direct-path <code class="codeph">INSERT</code> <code class="codeph">AS</code> <code class="codeph">SELECT</code> statement in conjunction with the <code class="codeph">SELECT</code> from an external table. Starting in Oracle Database 12<span class="italic">c</span>, the database automatically gathers table statistics as part of a bulk-load operation (CTAS and IAS) similar to how statistics are gathered when an index is created. By gathering statistics during the data load, you avoid additional scan operations and provide the necessary statistics as soon as the data becomes available to the users. 
                        </p>
                        <p>The main difference between external tables and regular tables is that externally organized tables are read-only. No DML operations (<code class="codeph">UPDATE</code>/<code class="codeph">INSERT</code>/<code class="codeph">DELETE</code>) are possible and no indexes can be created on them.
                        </p>
                        <p>External tables are mostly compliant with the existing SQL*Loader functionality and provide superior functionality in most cases. External tables are especially useful for environments where the complete external source has to be joined with existing database objects or when the data has to be transformed in a complex manner. For example, unlike SQL*Loader, you can apply any arbitrary SQL transformation and use the direct-path insert method. In addition, you can specify a program to be executed (such as <code class="codeph">zcat</code>) that processes files (such as compressed data files) and enables Oracle Database to use the output (such as uncompressed data files), which means you can load large amounts of compressed data without first uncompressing it on a disk.
                        </p>
                        <p>You can create an external table named <code class="codeph">sales_transactions_ext</code>, representing the structure of the complete sales transaction data, represented in the external file <code class="codeph">sh_sales.gz</code>. The product department is especially interested in a cost analysis on product and time. You thus create a fact table named <code class="codeph">cost</code> in the <code class="codeph">sh</code> schema. The operational source data is the same as for the <code class="codeph">sales</code> fact table. However, because you are not investigating every dimensional information that is provided, the data in the <code class="codeph">cost</code> fact table has a coarser granularity than in the <code class="codeph">sales</code> fact table, for example, all different distribution channels are aggregated.
                        </p>
                        <p>You cannot load the data into the <code class="codeph">cost</code> fact table without applying the previously mentioned aggregation of the detailed information, due to the suppression of some of the dimensions.
                        </p>
                        <p>The external table framework offers a solution to solve this. Unlike SQL*Loader, where you would have to load the data before applying the aggregation, you can combine the loading and transformation within a single SQL DML statement, as shown in the following. You do not have to stage the data temporarily before inserting into the target table.</p>
                        <p>The object directories must already exist, and point to the directory containing the <code class="codeph">sh_sales.gz</code> file as well as the directory containing the bad and log files.
                        </p><pre class="oac_no_warn" dir="ltr">CREATE TABLE sales_transactions_ext
(PROD_ID NUMBER, CUST_ID NUMBER,
 TIME_ID DATE, CHANNEL_ID NUMBER,
 PROMO_ID NUMBER, QUANTITY_SOLD NUMBER,
 AMOUNT_SOLD NUMBER(10,2), UNIT_COST NUMBER(10,2),
 UNIT_PRICE NUMBER(10,2))
ORGANIZATION external (TYPE oracle_loader
  DEFAULT DIRECTORY data_file_dir ACCESS PARAMETERS
  (RECORDS DELIMITED BY NEWLINE CHARACTERSET US7ASCII
    PREPROCESSOR EXECDIR:'zcat' 
    BADFILE log_file_dir:'sh_sales.bad_xt'
    LOGFILE log_file_dir:'sh_sales.log_xt'
    FIELDS TERMINATED BY "|" LDRTRIM
    ( PROD_ID, CUST_ID,
      TIME_ID         DATE(10) "YYYY-MM-DD", 
      CHANNEL_ID, PROMO_ID, QUANTITY_SOLD, AMOUNT_SOLD,
      UNIT_COST, UNIT_PRICE))
  location ('sh_sales.gz') 
)REJECT LIMIT UNLIMITED;
</pre><p>The external table can now be used from within the database, accessing some columns of the external data only, grouping the data, and inserting it into the <code class="codeph">costs</code> fact table:
                        </p><pre class="oac_no_warn" dir="ltr">INSERT /*+ APPEND */ INTO COSTS
(TIME_ID, PROD_ID, UNIT_COST, UNIT_PRICE)
SELECT TIME_ID, PROD_ID, AVG(UNIT_COST), AVG(amount_sold/quantity_sold)
FROM sales_transactions_ext GROUP BY time_id, prod_id;
</pre><div class="infoboxnotealso" id="GUID-0C48B004-54C8-48A3-BBF8-6C69BB19F15E__GUID-0B77661A-7303-4873-B184-AAB8294FC45E">
                           <p class="notep1">See Also:</p>
                           <ul style="list-style-type: disc;">
                              <li>
                                 <p><a href="../sqlrf/ALTER-TABLE.html#SQLRF53428" target="_blank"><span class="italic">Oracle Database SQL Language Reference</span></a> for a complete description of external table syntax
                                 </p>
                              </li>
                              <li>
                                 <p><a href="../sutil/oracle-sql-loader-concepts.html#SUTIL995" target="_blank"><span class="italic">Oracle Database Utilities</span></a> for usage examples
                                 </p>
                              </li>
                           </ul>
                        </div>
                     </div>
                     <!-- class="section" -->
                  </div>
               </div><a id="DWHSG8313"></a><div class="props_rev_3"><a id="GUID-16CA33C9-77A1-494A-8170-F4703D2C0447" name="GUID-16CA33C9-77A1-494A-8170-F4703D2C0447"></a><h4 id="DWHSG-GUID-16CA33C9-77A1-494A-8170-F4703D2C0447" class="sect4"><span class="enumeration_section">18.2.3 </span>Loading a Data Warehouse with OCI and Direct-Path APIs
                  </h4>
                  <div>
                     <p>OCI and direct-path APIs are frequently used when the transformation and computation are done outside the database and there is no need for flat file staging.</p>
                  </div>
               </div><a id="DWHSG8314"></a><div class="props_rev_3"><a id="GUID-5904B997-7D60-4553-82CA-91709E040F5A" name="GUID-5904B997-7D60-4553-82CA-91709E040F5A"></a><h4 id="DWHSG-GUID-5904B997-7D60-4553-82CA-91709E040F5A" class="sect4"><span class="enumeration_section">18.2.4 </span>Loading a Data Warehouse with Export/Import
                  </h4>
                  <div>
                     <p>Export and import are used when the data is inserted as is into the target system. No complex extractions are possible. See <a href="extraction-data-warehouses.html#GUID-7C9793D3-10E7-40BB-80FF-627C7160D044">Extraction in Data Warehouses</a> for further information.
                     </p>
                  </div>
               </div>
            </div><a id="DWHSG8315"></a><div class="props_rev_3"><a id="GUID-D8DA5FB4-7F4C-42C5-828D-9150A5699186" name="GUID-D8DA5FB4-7F4C-42C5-828D-9150A5699186"></a><h3 id="DWHSG-GUID-D8DA5FB4-7F4C-42C5-828D-9150A5699186" class="sect3"><span class="enumeration_section">18.3 </span>Transformation Mechanisms in Data Warehouses
               </h3>
               <div>
                  <p>You have the following cho<a id="d63021e670" class="indexterm-anchor"></a>ices for transforming data inside the database:
                  </p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p><a href="loading-transformation-date-warehouses.html#GUID-E1BA12C1-5CE7-405C-8BC7-745ADE615E90">Transforming Data Using SQL</a></p>
                     </li>
                     <li>
                        <p><a href="loading-transformation-date-warehouses.html#GUID-11660715-44A7-4687-8E4B-2C18B8339A1D">Transforming Data Using PL/SQL</a></p>
                     </li>
                     <li>
                        <p><a href="loading-transformation-date-warehouses.html#GUID-98157B1C-86EC-4888-9760-DB0164D2A832">Transforming Data Using Table Functions</a></p>
                     </li>
                  </ul>
               </div><a id="DWHSG8316"></a><div class="props_rev_3"><a id="GUID-E1BA12C1-5CE7-405C-8BC7-745ADE615E90" name="GUID-E1BA12C1-5CE7-405C-8BC7-745ADE615E90"></a><h4 id="DWHSG-GUID-E1BA12C1-5CE7-405C-8BC7-745ADE615E90" class="sect4"><span class="enumeration_section">18.3.1 </span>Transforming Data Using SQL
                  </h4>
                  <div>
                     <div class="section">
                        <p><a id="d63021e713" class="indexterm-anchor"></a>Once data is loaded into the database, data transformations can be executed using SQL operations. There are four basic techniques for implementing SQL data transformations:
                        </p>
                     </div>
                     <!-- class="section" -->
                     <div class="section">
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><a href="loading-transformation-date-warehouses.html#GUID-DB1E72E7-5ED6-4BA6-A133-DAD16932E5A0">CREATE TABLE ... AS SELECT And INSERT /*+APPEND*/ AS SELECT</a></p>
                           </li>
                           <li>
                              <p><a href="loading-transformation-date-warehouses.html#GUID-7463003E-2689-4469-8ED9-77BBA5BC2A00">Transforming Data Using UPDATE</a></p>
                           </li>
                           <li>
                              <p><a href="loading-transformation-date-warehouses.html#GUID-033C3049-7936-46C2-881C-14BA409D294B">Transforming Data Using MERGE</a></p>
                           </li>
                           <li>
                              <p><a href="loading-transformation-date-warehouses.html#GUID-573C71FA-9CC7-41F1-B27A-AC5668A02854">Transforming Data Using Multitable INSERT</a></p>
                           </li>
                        </ul>
                     </div>
                     <!-- class="section" -->
                  </div><a id="DWHSG8317"></a><div class="props_rev_3"><a id="GUID-DB1E72E7-5ED6-4BA6-A133-DAD16932E5A0" name="GUID-DB1E72E7-5ED6-4BA6-A133-DAD16932E5A0"></a><h5 id="DWHSG-GUID-DB1E72E7-5ED6-4BA6-A133-DAD16932E5A0" class="sect5"><span class="enumeration_section">18.3.1.1 </span>CREATE TABLE ... AS SELECT And INSERT /*+APPEND*/ AS SELECT
                     </h5>
                     <div>
                        <div class="section">
                           <p>The <code class="codeph">CREATE</code> <code class="codeph">TABLE</code> ... <code class="codeph">AS</code> <code class="codeph">SELECT</code> statement (CTAS) is a powerful tool for manipulating large sets of data. As shown in the following example, many data transformations can be expressed in standard SQL, and CTAS provides a mechanism for efficiently executing a SQL query and storing the results of that query in a new database table. The <code class="codeph">INSERT</code> /*+<code class="codeph">APPEND</code>*/ ... <code class="codeph">AS</code> <code class="codeph">SELECT</code> statement offers the same capabilities with existing database tables.
                           </p>
                           <p>In a data warehouse environment, CTAS is typically run in parallel using <code class="codeph">NOLOGGING</code> mode for best performance.
                           </p>
                           <p>A simple and common type of data transformation is data substitution. In a data substitution transformation, some or all of the values of a single column are modified. For example, our <code class="codeph">sales</code> table has a <code class="codeph">channel_id</code> column. This column indicates whether a given sales transaction was made by a company's own sales force (a direct sale) or by a distributor (an indirect sale).
                           </p>
                           <p>You may receive data from multiple source systems for your data warehouse. Suppose that one of those source systems processes only direct sales, and thus the source system does not know indirect sales channels. When the data warehouse initially receives sales data from this system, all sales records have a <code class="codeph">NULL</code> value for the <code class="codeph">sales.channel_id</code> field. These <code class="codeph">NULL</code> values must be set to the proper key value. For example, you can do this efficiently using a SQL function as part of the insertion into the target sales table statement. The structure of source table <code class="codeph">sales_activity_direct</code> is as follows:
                           </p><pre class="oac_no_warn" dir="ltr">DESC sales_activity_direct
Name           Null?    Type
------------   -----    ----------------
SALES_DATE              DATE
PRODUCT_ID              NUMBER
CUSTOMER_ID             NUMBER
PROMOTION_ID            NUMBER
AMOUNT                  NUMBER
QUANTITY                NUMBER
</pre><p>The following SQL statement inserts data from <code class="codeph">sales_activity_direct</code> into the <code class="codeph">sales</code> table of the sample schema, using a SQL function to truncate the sales date values to the midnight time and assigning a fixed channel ID of 3.
                           </p><pre class="oac_no_warn" dir="ltr">INSERT /*+ APPEND NOLOGGING PARALLEL */
INTO sales SELECT product_id, customer_id, TRUNC(sales_date), 3,
       promotion_id, quantity, amount
FROM sales_activity_direct;</pre></div>
                        <!-- class="section" -->
                     </div>
                  </div><a id="DWHSG8318"></a><div class="props_rev_3"><a id="GUID-7463003E-2689-4469-8ED9-77BBA5BC2A00" name="GUID-7463003E-2689-4469-8ED9-77BBA5BC2A00"></a><h5 id="DWHSG-GUID-7463003E-2689-4469-8ED9-77BBA5BC2A00" class="sect5"><span class="enumeration_section">18.3.1.2 </span>Transforming Data Using UPDATE
                     </h5>
                     <div>
                        <div class="section">
                           <p>Another technique for implementing a data substitution is to use an <code class="codeph">UPDATE</code> statement to modify the <code class="codeph">sales.channel_id</code> column. An <code class="codeph">UPDATE</code> provides the correct result. However, if the data substitution transformations require that a very large percentage of the rows (or all of the rows) be modified, then, it may be more efficient to use a CTAS statement than an <code class="codeph">UPDATE</code>.
                           </p>
                        </div>
                        <!-- class="section" -->
                     </div>
                  </div><a id="DWHSG8321"></a><a id="DWHSG8319"></a><div class="props_rev_3"><a id="GUID-033C3049-7936-46C2-881C-14BA409D294B" name="GUID-033C3049-7936-46C2-881C-14BA409D294B"></a><h5 id="DWHSG-GUID-033C3049-7936-46C2-881C-14BA409D294B" class="sect5"><span class="enumeration_section">18.3.1.3 </span>Transforming Data Using MERGE
                     </h5>
                     <div>
                        <div class="section">
                           <p>Oracle Database's merge functionality extends SQL, by introducing the SQL keyword <code class="codeph">MERGE</code>, in order to provide the ability to update or insert a row conditionally into a table or out of line single table views. Conditions are specified in the <code class="codeph">ON</code> clause. This is, besides pure bulk loading, one of the most common operations in data warehouse synchronization.
                           </p>
                        </div>
                        <!-- class="section" -->
                        <div class="example" id="GUID-033C3049-7936-46C2-881C-14BA409D294B__i1006454">
                           <p class="titleinexample">Example 18-1 Merge Operation Using SQL</p>
                           <p>The following example discusses various implementations of a merge. It assumes that new data for the dimension table products is propagated to the data warehouse and has to be either inserted or updated. The table <code class="codeph">products_delta</code> has the same structure as <code class="codeph">products</code>.
                           </p><pre class="oac_no_warn" dir="ltr">MERGE INTO products t USING products_delta s
ON (t.prod_id=s.prod_id)
WHEN MATCHED THEN UPDATE SET
  t.prod_list_price=s.prod_list_price, t.prod_min_price=s.prod_min_price
WHEN NOT MATCHED THEN INSERT (prod_id, prod_name, prod_desc, prod_subcategory,
  prod_subcategory_desc, prod_category, prod_category_desc, prod_status, 
  prod_list_price, prod_min_price)
VALUES (s.prod_id, s.prod_name, s.prod_desc, s.prod_subcategory, 
  s.prod_subcategory_desc, s.prod_category, s.prod_category_desc, 
  s.prod_status, s.prod_list_price, s.prod_min_price);</pre></div>
                        <!-- class="example" -->
                     </div>
                  </div><a id="DWHSG8323"></a><a id="DWHSG8324"></a><a id="DWHSG8325"></a><a id="DWHSG8326"></a><a id="DWHSG8322"></a><div class="props_rev_3"><a id="GUID-573C71FA-9CC7-41F1-B27A-AC5668A02854" name="GUID-573C71FA-9CC7-41F1-B27A-AC5668A02854"></a><h5 id="DWHSG-GUID-573C71FA-9CC7-41F1-B27A-AC5668A02854" class="sect5"><span class="enumeration_section">18.3.1.4 </span>Transforming Data Using Multitable INSERT
                     </h5>
                     <div>
                        <div class="section">
                           <p>Many times, external data sources have to be segregated based on logical attributes for insertion into different target objects. It is also frequent in data warehouse environments to fan out the same source data into several target objects. Multitable inserts provide a new SQL statement for these kinds of transformations, where data can either end up in several or exactly one target, depending on the business transformation rules. This insertion can be done conditionally based on business rules or unconditionally.</p>
                           <p>It offers the benefits of the <code class="codeph">INSERT</code> ... <code class="codeph">SELECT</code> statement when multiple tables are involved as targets. In doing so, it avoids the drawbacks of the two obvious alternatives. You either had to deal with <span class="italic">n</span> independent <code class="codeph">INSERT</code> … <code class="codeph">SELECT</code> statements, thus processing the same source data <span class="italic">n</span> times and increasing the transformation workload <span class="italic">n</span> times. Alternatively, you had to choose a procedural approach with a per-row determination how to handle the insertion. This solution lacked direct access to high-speed access paths available in SQL.
                           </p>
                           <p>As with the existing <code class="codeph">INSERT</code> ... <code class="codeph">SELECT</code> statement, the new statement can be parallelized and used with the direct-load mechanism for faster performance.
                           </p>
                        </div>
                        <!-- class="section" -->
                        <div class="example" id="GUID-573C71FA-9CC7-41F1-B27A-AC5668A02854__GUID-35298AB6-DA03-4C43-9C91-F786FDB70E61">
                           <p class="titleinexample">Example 18-2 Unconditional Insert</p>
                           <p>The following statement aggregates the transactional sales information, stored in <code class="codeph">sales_activity_direct</code>, on a daily basis and inserts into both the <code class="codeph">sales</code> and the <code class="codeph">costs</code> fact table for the current day.
                           </p><pre class="oac_no_warn" dir="ltr">INSERT ALL
   INTO sales VALUES (product_id, customer_id, today, 3, promotion_id,
                      quantity_per_day, amount_per_day)
   INTO costs VALUES (product_id, today, promotion_id, 3,
                      product_cost, product_price)
SELECT TRUNC(s.sales_date) AS today, s.product_id, s.customer_id,
  s.promotion_id, SUM(s.amount) AS amount_per_day, SUM(s.quantity)
  quantity_per_day, p.prod_min_price*0.8 AS product_cost, p.prod_list_price 
  AS product_price
FROM sales_activity_direct s, products p
WHERE s.product_id = p.prod_id AND TRUNC(sales_date) = TRUNC(SYSDATE)
GROUP BY TRUNC(sales_date), s.product_id, s.customer_id, s.promotion_id, 
  p.prod_min_price*0.8, p.prod_list_price;</pre></div>
                        <!-- class="example" -->
                        <div class="example" id="GUID-573C71FA-9CC7-41F1-B27A-AC5668A02854__GUID-83B9F592-5612-4A97-B8AC-5B6FB5DE0D17">
                           <p class="titleinexample">Example 18-3 Conditional ALL Insert</p>
                           <p>The following statement inserts a row into the <code class="codeph">sales</code> and <code class="codeph">costs</code> tables for all sales transactions with a valid promotion and stores the information about multiple identical orders of a customer in a separate table <code class="codeph">cum_sales_activity</code>. It is possible two rows will be inserted for some sales transactions, and none for others.
                           </p><pre class="oac_no_warn" dir="ltr">INSERT ALL
WHEN promotion_id IN (SELECT promo_id FROM promotions) THEN
   INTO sales VALUES (product_id, customer_id, today, 3, promotion_id,
                       quantity_per_day, amount_per_day)
   INTO costs VALUES (product_id, today, promotion_id, 3,
                      product_cost, product_price)
WHEN num_of_orders &gt; 1 THEN
   INTO cum_sales_activity VALUES (today, product_id, customer_id,
     promotion_id, quantity_per_day, amount_per_day, num_of_orders)
SELECT TRUNC(s.sales_date) AS today, s.product_id, s.customer_id,
   s.promotion_id, SUM(s.amount) AS amount_per_day, SUM(s.quantity)
   quantity_per_day, COUNT(*) num_of_orders, p.prod_min_price*0.8
   AS product_cost, p.prod_list_price AS product_price
FROM sales_activity_direct s, products p
WHERE s.product_id = p.prod_id
AND TRUNC(sales_date) = TRUNC(SYSDATE)
GROUP BY TRUNC(sales_date), s.product_id, s.customer_id,
 s.promotion_id, p.prod_min_price*0.8, p.prod_list_price;</pre></div>
                        <!-- class="example" -->
                        <div class="example" id="GUID-573C71FA-9CC7-41F1-B27A-AC5668A02854__GUID-348DCBDD-BB6A-4F54-893D-ECE3E180D1E5">
                           <p class="titleinexample">Example 18-4 Conditional FIRST Insert</p>
                           <p>The following statement inserts into an appropriate shipping manifest according to the total quantity and the weight of a product order. An exception is made for high value orders, which are also sent by express, unless their weight classification is too high. All incorrect orders, in this simple example represented as orders without a quantity, are stored in a separate table. It assumes the existence of appropriate tables <code class="codeph">large_freight_shipping</code>, <code class="codeph">express_shipping</code>, <code class="codeph">default_shipping</code>, and <code class="codeph">incorrect_sales_order</code>.
                           </p><pre class="oac_no_warn" dir="ltr">INSERT FIRST WHEN (sum_quantity_sold &gt; 10 AND prod_weight_class &lt; 5) AND
sum_quantity_sold &gt;=1) OR (sum_quantity_sold &gt; 5 AND prod_weight_class &gt; 5) THEN
  INTO large_freight_shipping VALUES
      (time_id, cust_id, prod_id, prod_weight_class, sum_quantity_sold)
  WHEN sum_amount_sold &gt; 1000 AND sum_quantity_sold &gt;=1 THEN
  INTO express_shipping VALUES
      (time_id, cust_id, prod_id, prod_weight_class,
       sum_amount_sold, sum_quantity_sold)
WHEN (sum_quantity_sold &gt;=1) THEN INTO default_shipping VALUES
      (time_id, cust_id, prod_id, sum_quantity_sold)
ELSE INTO incorrect_sales_order VALUES (time_id, cust_id, prod_id)
SELECT s.time_id, s.cust_id, s.prod_id, p.prod_weight_class,
       SUM(amount_sold) AS sum_amount_sold,
       SUM(quantity_sold) AS sum_quantity_sold
FROM sales s, products p
WHERE s.prod_id = p.prod_id AND s.time_id = TRUNC(SYSDATE)
GROUP BY s.time_id, s.cust_id, s.prod_id, p.prod_weight_class;</pre></div>
                        <!-- class="example" -->
                        <div class="example" id="GUID-573C71FA-9CC7-41F1-B27A-AC5668A02854__GUID-6B1707BA-287E-4409-B935-CCBE18BB8EE9">
                           <p class="titleinexample">Example 18-5 Mixed Conditional and Unconditional Insert</p>
                           <p>The following example inserts new customers into the <code class="codeph">customers</code> table and stores all new customers with <code class="codeph">cust_credit_limit</code> higher then 4500 in an additional, separate table for further promotions.
                           </p><pre class="oac_no_warn" dir="ltr">INSERT FIRST WHEN cust_credit_limit &gt;= 4500 THEN INTO customers
  INTO customers_special VALUES (cust_id, cust_credit_limit)
  ELSE INTO customers
SELECT * FROM customers_new;
</pre><div class="infoboxnotealso" id="GUID-573C71FA-9CC7-41F1-B27A-AC5668A02854__GUID-EC09222A-5C7B-42BC-BBF5-8479F656F857">
                              <p class="notep1">See Also:</p>
                              <p><a href="refreshing-materialized-views.html#GUID-64068234-BDB0-4C12-AE70-75571046A586" title="A materialized view that uses the ON STATEMENT refresh mode is automatically refreshed every time a DML operation is performed on any of the materialized view’s base tables. Oracle Database performs fast refresh for materialized views that are defined using approximate queries.While redefining a table online using the DBMS_REDEFINITION package, you can perform incremental refresh of fast refreshable materialized views that are dependent on the table being redefined.You can use the complete, fast, or PCT refresh methods to refresh a materialized view that is based on a hybrid partitioned table.">Refreshing Materialized Views</a> for more information regarding <code class="codeph">MERGE</code> operations
                              </p>
                           </div>
                        </div>
                        <!-- class="example" -->
                     </div>
                  </div>
               </div><a id="DWHSG8327"></a><div class="props_rev_3"><a id="GUID-11660715-44A7-4687-8E4B-2C18B8339A1D" name="GUID-11660715-44A7-4687-8E4B-2C18B8339A1D"></a><h4 id="DWHSG-GUID-11660715-44A7-4687-8E4B-2C18B8339A1D" class="sect4"><span class="enumeration_section">18.3.2 </span>Transforming Data Using PL/SQL
                  </h4>
                  <div>
                     <p>In a data warehouse environment, you can use procedural languages such as PL/SQL to implement complex transformations in the Oracle Database. Whereas CTAS operates on entire tables and emphasizes parallelism, PL/SQL provides a row-based approached and can accommodate very sophisticated transformation rules. For example, a PL/SQL procedure could open multiple cursors and read data from multiple source tables, combine this data using complex business rules, and finally insert the transformed data into one or more target table. It would be difficult or impossible to express the same sequence of operations using standard SQL statements.</p>
                     <p>Using a procedural language, a specific transformation (or number of transformation steps) within a complex ETL processing can be encapsulated, reading data from an intermediate staging area and generating a new table object as output. A previously generated transformation input table and a subsequent transformation will consume the table generated by this specific transformation. Alternatively, these encapsulated transformation steps within the complete ETL process can be integrated seamlessly, thus streaming sets of rows between each other without the necessity of intermediate staging. You can use table functions to implement such behavior.</p>
                  </div>
               </div><a id="DWHSG8328"></a><div class="props_rev_3"><a id="GUID-98157B1C-86EC-4888-9760-DB0164D2A832" name="GUID-98157B1C-86EC-4888-9760-DB0164D2A832"></a><h4 id="DWHSG-GUID-98157B1C-86EC-4888-9760-DB0164D2A832" class="sect4"><span class="enumeration_section">18.3.3 </span>Transforming Data Using Table Functions
                  </h4>
                  <div>
                     <p>Table functions provide the support for pipelined and parallel execution of transformations implemented in PL/SQL, C, or Java.<span class="bold"> </span>Scenarios as mentioned earlier can be done without requiring the use of intermediate staging tables, which interrupt the data flow through various transformations steps. Detailed information about table functions is provided in <span class="q">"<a href="loading-transformation-date-warehouses.html#GUID-53CA1DE7-F323-46AA-8803-C76E1642486B">What is a Table Function?</a>"</span>.
                     </p>
                  </div><a id="DWHSG8330"></a><a id="DWHSG8331"></a><a id="DWHSG8332"></a><a id="DWHSG8329"></a><div class="props_rev_3"><a id="GUID-53CA1DE7-F323-46AA-8803-C76E1642486B" name="GUID-53CA1DE7-F323-46AA-8803-C76E1642486B"></a><h5 id="DWHSG-GUID-53CA1DE7-F323-46AA-8803-C76E1642486B" class="sect5"><span class="enumeration_section">18.3.3.1 </span>What is a Table Function?
                     </h5>
                     <div>
                        <p>A table function is defined as a function that can produce a set of rows as output. Additionally, table functions can take a set of rows as input. Prior to Oracle9<span class="italic">i</span>, PL/SQL functions:
                        </p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Could not take cursors as input.</p>
                           </li>
                           <li>
                              <p>Could not be parallelized or pipelined.</p>
                           </li>
                        </ul>
                        <p>Now, functions are not limited in these ways. Table functions extend database functionality by allowing:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Multiple rows to be returned from a function.</p>
                           </li>
                           <li>
                              <p>Results of SQL subqueries (that select multiple rows) to be passed directly to functions.</p>
                           </li>
                           <li>
                              <p>Functions take cursors as input.</p>
                           </li>
                           <li>
                              <p>Functions can be parallelized.</p>
                           </li>
                           <li>
                              <p>Returning result sets incrementally for further processing as soon as they are created. This is called incremental pipelining</p>
                           </li>
                        </ul>
                        <p>Table functions can be defined in PL/SQL using a native PL/SQL interface, or in Java or C using the Oracle Data Cartridge Interface (ODCI).</p>
                        <div class="infoboxnotealso" id="GUID-53CA1DE7-F323-46AA-8803-C76E1642486B__GUID-012AFC1F-DF1D-428F-8B0A-D5C4EAFDFCD1">
                           <p class="notep1">See Also:</p>
                           <ul style="list-style-type: disc;">
                              <li>
                                 <p><a href="../lnpls/plsql-optimization-and-tuning.html#LNPLS01210" target="_blank"><span class="italic">Oracle Database PL/SQL Language Reference</span></a> for further information
                                 </p>
                              </li>
                              <li>
                                 <p><a href="../addci/using-pipelined-and-parallel-table-functions.html#ADDCI2140" target="_blank"><span class="italic">Oracle Database Data Cartridge Developer's Guide</span></a> for further information
                                 </p>
                              </li>
                           </ul>
                        </div>
                        <p><a href="loading-transformation-date-warehouses.html#GUID-53CA1DE7-F323-46AA-8803-C76E1642486B__I1006638">Figure 18-3</a> illustrates a typical aggregation where you input a set of rows and output a set of rows, in that case, after performing a <code class="codeph">SUM</code> operation.
                        </p>
                        <div class="figure" id="GUID-53CA1DE7-F323-46AA-8803-C76E1642486B__I1006638">
                           <p class="titleinfigure">Figure 18-3 Table Function Example</p><img src="img/dwhsg084.gif" alt="Description of Figure 18-3 follows" title="Description of Figure 18-3 follows" longdesc="img_text/dwhsg084.html"><br><a href="img_text/dwhsg084.html">Description of "Figure 18-3 Table Function Example"</a></div>
                        <!-- class="figure" -->
                        <p>The pseudocode for this operation would be similar to:</p><pre class="oac_no_warn" dir="ltr">INSERT INTO Out SELECT * FROM ("Table Function"(SELECT * FROM In));
</pre><p>The table function takes the result of the <code class="codeph">SELECT</code> on <code class="codeph">In</code> as input and delivers a set of records in a different format as output for a direct insertion into <code class="codeph">Out</code>.
                        </p>
                        <p>Additionally, a table function can fan out data within the scope of an atomic transaction. This can be used for many occasions like an efficient logging mechanism or a fan out for other independent transformations. In such a scenario, a single staging table is needed.</p>
                        <div class="figure" id="GUID-53CA1DE7-F323-46AA-8803-C76E1642486B__GUID-999253ED-2787-4948-B9B0-40D96C6CD5A8">
                           <p class="titleinfigure">Figure 18-4 Pipelined Parallel Transformation with Fanout</p><img src="img/dwhsg079.gif" alt="Description of Figure 18-4 follows" title="Description of Figure 18-4 follows" longdesc="img_text/dwhsg079.html"><br><a href="img_text/dwhsg079.html">Description of "Figure 18-4 Pipelined Parallel Transformation with Fanout"</a></div>
                        <!-- class="figure" -->
                        <p>The pseudocode for this would be similar to:</p><pre class="oac_no_warn" dir="ltr">INSERT INTO target SELECT * FROM (tf2(SELECT * 
FROM (tf1(SELECT * FROM source))));
</pre><p>This inserts into <code class="codeph">target</code> and, as part of <code class="codeph">tf1</code>, into <code class="codeph">Stage</code> <code class="codeph">Table</code> <code class="codeph">1</code> within the scope of an atomic transaction.
                        </p><pre class="oac_no_warn" dir="ltr">INSERT INTO target SELECT * FROM tf3(SELT * FROM stage_table1);</pre><div class="infoboxnotealso" id="GUID-53CA1DE7-F323-46AA-8803-C76E1642486B__GUID-926150FA-ADB1-46D0-94A5-0EA5D04FA3B6">
                           <p class="notep1">See Also:</p>
                           <ul style="list-style-type: disc;">
                              <li>
                                 <p><a href="../lnpls/plsql-optimization-and-tuning.html#LNPLS01210" target="_blank"><span class="italic">Oracle Database PL/SQL Language Reference</span></a> for details about table functions
                                 </p>
                              </li>
                              <li>
                                 <p><a href="../addci/using-pipelined-and-parallel-table-functions.html#ADDCI2140" target="_blank"><span class="italic">Oracle Database Data Cartridge Developer's Guide</span></a> for details about tables functions implemented in languages other than PL/SQL
                                 </p>
                              </li>
                           </ul>
                        </div>
                        <div class="section">
                           <p class="subhead3" id="GUID-53CA1DE7-F323-46AA-8803-C76E1642486B__GUID-0C215ACE-E2B1-4B2D-9B06-98365261B1CD">Objects to Create Before Running Table Function Examples</p>
                           <p>The following examples demonstrate the fundamentals of table functions, without the usage of complex business rules implemented inside those functions. They are chosen for demonstration purposes only, and are all implemented in PL/SQL.</p>
                           <p>Table functions return sets of records and can take cursors as input. Besides the <code class="codeph">sh</code> sample schema, you have to set up the following database objects before using the examples:
                           </p><pre class="oac_no_warn" dir="ltr">CREATE TYPE product_t AS OBJECT (
      prod_id                  NUMBER(6)
    , prod_name                VARCHAR2(50)
    , prod_desc                VARCHAR2(4000)
    , prod_subcategory         VARCHAR2(50)
    , prod_subcategory_desc    VARCHAR2(2000)
    , prod_category            VARCHAR2(50)
    , prod_category_desc       VARCHAR2(2000)
    , prod_weight_class        NUMBER(2)
    , prod_unit_of_measure     VARCHAR2(20)
    , prod_pack_size           VARCHAR2(30)
    , supplier_id              NUMBER(6)
    , prod_status              VARCHAR2(20)
    , prod_list_price          NUMBER(8,2)
    , prod_min_price           NUMBER(8,2)
);
/
CREATE TYPE product_t_table AS TABLE OF product_t;
/
COMMIT;

CREATE OR REPLACE PACKAGE cursor_PKG AS
  TYPE product_t_rec IS RECORD (
      prod_id                   NUMBER(6)
    , prod_name                 VARCHAR2(50)
    , prod_desc                 VARCHAR2(4000)
    , prod_subcategory          VARCHAR2(50)
    , prod_subcategory_desc     VARCHAR2(2000)
    , prod_category             VARCHAR2(50)
    , prod_category_desc        VARCHAR2(2000)
    , prod_weight_class         NUMBER(2)
    , prod_unit_of_measure      VARCHAR2(20)
    , prod_pack_size            VARCHAR2(30)
    , supplier_id               NUMBER(6)
    , prod_status               VARCHAR2(20)
    , prod_list_price           NUMBER(8,2)
    , prod_min_price            NUMBER(8,2));
  TYPE product_t_rectab IS TABLE OF product_t_rec;
  TYPE strong_refcur_t IS REF CURSOR RETURN product_t_rec;
  TYPE refcur_t IS REF CURSOR;
END;
/

REM artificial help table, used later
CREATE TABLE obsolete_products_errors (prod_id NUMBER, msg VARCHAR2(2000));
</pre></div>
                        <!-- class="section" -->
                        <div class="example" id="GUID-53CA1DE7-F323-46AA-8803-C76E1642486B__CACFHAGG">
                           <p class="titleinexample">Example 18-6 Table Functions Example: Basic Example</p>
                           <p>This example demonstrates a simple filtering; it shows all obsolete products except the <code class="codeph">prod_category</code> Electronics. The table function returns the result set as a set of records and uses a weakly typed <code class="codeph">REF</code> <code class="codeph">CURSOR</code> as input.
                           </p><pre class="oac_no_warn" dir="ltr">CREATE OR REPLACE FUNCTION obsolete_products(cur cursor_pkg.refcur_t)
RETURN product_t_table
IS
    prod_id                   NUMBER(6); 
    prod_name                 VARCHAR2(50);
    prod_desc                 VARCHAR2(4000);
    prod_subcategory          VARCHAR2(50);
    prod_subcategory_desc     VARCHAR2(2000);
    prod_category             VARCHAR2(50);
    prod_category_desc        VARCHAR2(2000);
    prod_weight_class         NUMBER(2);
    prod_unit_of_measure      VARCHAR2(20);
    prod_pack_size            VARCHAR2(30);
    supplier_id               NUMBER(6);
    prod_status               VARCHAR2(20);
    prod_list_price           NUMBER(8,2);
    prod_min_price            NUMBER(8,2);
    sales NUMBER:=0;
    objset product_t_table := product_t_table();
    i NUMBER := 0;
BEGIN
   LOOP
     -- Fetch from cursor variable
     FETCH cur INTO prod_id, prod_name, prod_desc, prod_subcategory, 
    prod_subcategory_desc, prod_category, prod_category_desc, prod_weight_class,
    prod_unit_of_measure, prod_pack_size, supplier_id, prod_status, 
    prod_list_price, prod_min_price;
     EXIT WHEN cur%NOTFOUND; -- exit when last row is fetched
     -- Category Electronics is not meant to be obsolete and will be suppressed
     IF prod_status='obsolete' AND prod_category != 'Electronics' THEN
     -- append to collection
     i:=i+1;
     objset.extend;
     objset(i):=product_t( prod_id, prod_name, prod_desc, prod_subcategory,
     prod_subcategory_desc, prod_category, prod_category_desc, 
     prod_weight_class, prod_unit_of_measure, prod_pack_size, supplier_id, 
     prod_status, prod_list_price, prod_min_price);
     END IF;
   END LOOP;
   CLOSE cur;
   RETURN objset;
END;
/
</pre><p>You can use the table function in a SQL statement to show the results. Here you use additional SQL functionality for the output:</p><pre class="oac_no_warn" dir="ltr">SELECT DISTINCT UPPER(prod_category), prod_status
FROM TABLE(obsolete_products(
   CURSOR(SELECT prod_id, prod_name, prod_desc, prod_subcategory,
   prod_subcategory_desc, prod_category, prod_category_desc, prod_weight_class,
   prod_unit_of_measure, prod_pack_size,
   supplier_id, prod_status, prod_list_price, prod_min_price
          FROM products)));
</pre></div>
                        <!-- class="example" -->
                        <div class="example" id="GUID-53CA1DE7-F323-46AA-8803-C76E1642486B__GUID-32FB1B25-A469-4EF9-8A7F-6529447A8379">
                           <p class="titleinexample">Example 18-7 Table Functions Example: Filtering Using REF CURSOR</p>
                           <p>This example implements the same filtering as <a href="loading-transformation-date-warehouses.html#GUID-53CA1DE7-F323-46AA-8803-C76E1642486B__CACFHAGG">Example 18-6</a>. The main differences between the two are:
                           </p>
                           <ul style="list-style-type: disc;">
                              <li>
                                 <p>This example uses a strong typed <code class="codeph">REF</code> <code class="codeph">CURSOR</code> as input and can be parallelized based on the objects of the strong typed cursor, as shown in one of the following examples.
                                 </p>
                              </li>
                              <li>
                                 <p>The table function returns the result set incrementally as soon as records are created.</p>
                              </li>
                           </ul><pre class="oac_no_warn" dir="ltr">CREATE OR REPLACE FUNCTION 
  obsolete_products_pipe(cur cursor_pkg.strong_refcur_t) RETURN product_t_table
PIPELINED
PARALLEL_ENABLE (PARTITION cur BY ANY) IS
    prod_id                 NUMBER(6);
    prod_name               VARCHAR2(50);
    prod_desc               VARCHAR2(4000);
    prod_subcategory        VARCHAR2(50);
    prod_subcategory_desc   VARCHAR2(2000);
    prod_category           VARCHAR2(50);
    prod_category_desc      VARCHAR2(2000);
    prod_weight_class       NUMBER(2);
    prod_unit_of_measure   VARCHAR2(20);
    prod_pack_size         VARCHAR2(30);
    supplier_id            NUMBER(6);
    prod_status            VARCHAR2(20);
    prod_list_price        NUMBER(8,2);
    prod_min_price         NUMBER(8,2);
    sales NUMBER:=0;
BEGIN
 LOOP
     -- Fetch from cursor variable
     FETCH cur INTO prod_id, prod_name, prod_desc, prod_subcategory,
     prod_subcategory_desc, prod_category, prod_category_desc, 
     prod_weight_class, prod_unit_of_measure, prod_pack_size, supplier_id, 
     prod_status, prod_list_price, prod_min_price;
     EXIT WHEN cur%NOTFOUND; -- exit when last row is fetched
     IF prod_status='obsolete' AND prod_category !='Electronics' THEN
       PIPE ROW (product_t( prod_id, prod_name, prod_desc, prod_subcategory,
 prod_subcategory_desc, prod_category, prod_category_desc, prod_weight_class,
 prod_unit_of_measure, prod_pack_size, supplier_id, prod_status, 
 prod_list_price, prod_min_price));
     END IF;
   END LOOP;
   CLOSE cur;
   RETURN;
END;
/
</pre><p>You can use the table function as follows:</p><pre class="oac_no_warn" dir="ltr">SELECT DISTINCT prod_category,
                DECODE(prod_status,'obsolete','NO LONGER AVAILABLE','N/A')
FROM TABLE(obsolete_products_pipe(
  CURSOR(SELECT prod_id, prod_name, prod_desc, prod_subcategory,
         prod_subcategory_desc, prod_category, prod_category_desc,
         prod_weight_class, prod_unit_of_measure, prod_pack_size,
         supplier_id, prod_status, prod_list_price, prod_min_price
         FROM products)));
</pre><p>You now change the degree of parallelism for the input table products and issue the same statement again:</p><pre class="oac_no_warn" dir="ltr">ALTER TABLE products PARALLEL 4;
</pre><p>The session statistics show that the statement has been parallelized:</p><pre class="oac_no_warn" dir="ltr">SELECT * FROM V$PQ_SESSTAT WHERE statistic='Queries Parallelized';

STATISTIC              LAST_QUERY  SESSION_TOTAL
--------------------   ----------  -------------
Queries Parallelized            1              3

1 row selected.
</pre></div>
                        <!-- class="example" -->
                        <div class="example" id="GUID-53CA1DE7-F323-46AA-8803-C76E1642486B__GUID-F06815AD-5A85-4D00-9517-623F1DE58B40">
                           <p class="titleinexample">Example 18-8 Table Functions Example: Fanning Out Results into Persistent Tables</p>
                           <p>Table functions are also capable to fanout results into persistent table structures. In this example, the function filters all obsolete products except those of a specific <code class="codeph">prod_category</code> (default Electronics), which was set to status <code class="codeph">obsolete</code> by error. The result set of the table function consists of all other obsolete product categories. The detected wrong <code class="codeph">prod_id</code> IDs are stored in a separate table structure <code class="codeph">obsolete_products_error</code>. Note that if a table function is part of an autonomous transaction, it must <code class="codeph">COMMIT</code> or <code class="codeph">ROLLBACK</code> before each <code class="codeph">PIPE</code> <code class="codeph">ROW</code> statement to avoid an error in the callings subprogram. Its result set consists of all other obsolete product categories. It furthermore demonstrates how normal variables can be used in conjunction with table functions:
                           </p><pre class="oac_no_warn" dir="ltr">CREATE OR REPLACE FUNCTION obsolete_products_dml(cur cursor_pkg.strong_refcur_t,
 prod_cat varchar2 DEFAULT 'Electronics') RETURN product_t_table
PIPELINED
PARALLEL_ENABLE (PARTITION cur BY ANY) IS
    PRAGMA AUTONOMOUS_TRANSACTION;
    prod_id                   NUMBER(6);
    prod_name                 VARCHAR2(50);
    prod_desc                 VARCHAR2(4000);
    prod_subcategory          VARCHAR2(50);
    prod_subcategory_desc     VARCHAR2(2000);
    prod_category             VARCHAR2(50);
    prod_category_desc        VARCHAR2(2000);
    prod_weight_class         NUMBER(2);
    prod_unit_of_measure      VARCHAR2(20);
    prod_pack_size            VARCHAR2(30);
    supplier_id               NUMBER(6);
    prod_status               VARCHAR2(20);
    prod_list_price           NUMBER(8,2);
    prod_min_price            NUMBER(8,2);
    sales                     NUMBER:=0;
BEGIN
   LOOP
     -- Fetch from cursor variable
     FETCH cur INTO prod_id, prod_name, prod_desc, prod_subcategory, 
  prod_subcategory_desc, prod_category, prod_category_desc, prod_weight_class,
  prod_unit_of_measure, prod_pack_size, supplier_id, prod_status,
     prod_list_price, prod_min_price;
     EXIT WHEN cur%NOTFOUND; -- exit when last row is fetched
     IF prod_status='obsolete' THEN
       IF prod_category=prod_cat THEN
          INSERT INTO obsolete_products_errors VALUES
          (prod_id, 'correction: category '||UPPER(prod_cat)||' still
   available');
          COMMIT;
       ELSE
       PIPE ROW (product_t( prod_id, prod_name, prod_desc, prod_subcategory,
 prod_subcategory_desc, prod_category, prod_category_desc, prod_weight_class,
 prod_unit_of_measure, prod_pack_size, supplier_id, prod_status, 
 prod_list_price, prod_min_price));
       END IF;
     END IF;
   END LOOP;
   CLOSE cur;
   RETURN;
END;
/
</pre><p>The following query shows all obsolete product groups except the <code class="codeph">prod_category</code> Electronics, which was wrongly set to status <code class="codeph">obsolete</code>:
                           </p><pre class="oac_no_warn" dir="ltr">SELECT DISTINCT prod_category, prod_status FROM TABLE(obsolete_products_dml(
CURSOR(SELECT prod_id, prod_name, prod_desc, prod_subcategory, 
  prod_subcategory_desc, prod_category, prod_category_desc, prod_weight_class,
  prod_unit_of_measure, prod_pack_size, supplier_id, prod_status, 
  prod_list_price, prod_min_price
FROM products)));
</pre><p>As you can see, there are some products of the <code class="codeph">prod_category</code> Electronics that were obsoleted by accident:
                           </p><pre class="oac_no_warn" dir="ltr">SELECT DISTINCT msg FROM obsolete_products_errors;
</pre><p>Taking advantage of the second input variable, you can specify a different product group than Electronics to be considered:</p><pre class="oac_no_warn" dir="ltr">SELECT DISTINCT prod_category, prod_status
FROM TABLE(obsolete_products_dml(
CURSOR(SELECT prod_id, prod_name, prod_desc, prod_subcategory,
  prod_subcategory_desc, prod_category, prod_category_desc, prod_weight_class,
  prod_unit_of_measure, prod_pack_size, supplier_id, prod_status,
  prod_list_price, prod_min_price
FROM products),'Photo'));
</pre><p>Because table functions can be used like a normal table, they can be nested, as shown in the following:</p><pre class="oac_no_warn" dir="ltr">SELECT DISTINCT prod_category, prod_status
FROM TABLE(obsolete_products_dml(CURSOR(SELECT * 
FROM TABLE(obsolete_products_pipe(CURSOR(SELECT prod_id, prod_name, prod_desc,
 prod_subcategory, prod_subcategory_desc, prod_category, prod_category_desc,
 prod_weight_class, prod_unit_of_measure, prod_pack_size, supplier_id, 
 prod_status, prod_list_price, prod_min_price
FROM products))))));
</pre><p>The biggest advantage of Oracle Database's ETL is its toolkit functionality, where you can combine any of the latter discussed functionality to improve and speed up your ETL processing. For example, you can take an external table as input, join it with an existing table and use it as input for a parallelized table function to process complex business logic. This table function can be used as input source for a <code class="codeph">MERGE</code> operation, thus streaming the new information for the data warehouse, provided in a flat file within one single statement through the complete ETL process.
                           </p>
                        </div>
                        <!-- class="example" -->
                     </div>
                  </div>
               </div>
            </div><a id="DWHSG8333"></a><div class="props_rev_3"><a id="GUID-DAD3F208-A1CB-4491-8D61-D4640B51286A" name="GUID-DAD3F208-A1CB-4491-8D61-D4640B51286A"></a><h3 id="DWHSG-GUID-DAD3F208-A1CB-4491-8D61-D4640B51286A" class="sect3"><span class="enumeration_section">18.4 </span>Error Logging and Handling Mechanisms
               </h3>
               <div>
                  <p>Ha<a id="d63021e1397" class="indexterm-anchor"></a><a id="d63021e1399" class="indexterm-anchor"></a><a id="d63021e1403" class="indexterm-anchor"></a>ving data that is not clean is very common when loading and transforming data, especially when dealing with data coming from a variety of sources, including external ones. If this dirty data causes you to abort a long-running load or transformation operation, a lot of time and resources is wasted.
                  </p>
                  <p>The following topics discuss the two main causes of errors and how to address them:</p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p><a href="loading-transformation-date-warehouses.html#GUID-3AAAC9DA-2009-474A-B85A-7C7999C80F89">Business Rule Violations</a></p>
                     </li>
                     <li>
                        <p><a href="loading-transformation-date-warehouses.html#GUID-92563272-9748-4A5F-882E-7A645BF69859" title="External data that is used during the data transformation process may sometimes be inaccurate thereby causing data conversion errors. Certain SQL functions can be used to handle data conversion errors.">Data Rule Violations (Data Errors)</a></p>
                     </li>
                  </ul>
               </div><a id="DWHSG8334"></a><div class="props_rev_3"><a id="GUID-3AAAC9DA-2009-474A-B85A-7C7999C80F89" name="GUID-3AAAC9DA-2009-474A-B85A-7C7999C80F89"></a><h4 id="DWHSG-GUID-3AAAC9DA-2009-474A-B85A-7C7999C80F89" class="sect4"><span class="enumeration_section">18.4.1 </span>Business Rule Violations
                  </h4>
                  <div>
                     <p>Data that is logically not clean violates business rules that are known prior to any data consumption. Most of the time, handling these kind of errors will be incorporated into the loading or transformation process. However, in situations where the error identification for all records would become too expensive and the business rule can be enforced as a data rule violation, for example, testing hundreds of columns to see if they are <code class="codeph">NOT</code> <code class="codeph">NULL</code>, programmers often choose to handle even known possible logical error cases more generically. An example of this is shown in <span class="q">"<a href="loading-transformation-date-warehouses.html#GUID-E99E3CAC-83BC-448E-9CF3-D45432BE34A0">Data Error Scenarios</a>"</span>.
                     </p>
                     <p>Incorporating logical rules can be as easy as applying filter conditions on the data input stream or as complex as feeding the dirty data into a different transformation workflow. Some examples are as follows:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Filtering of logical data errors using SQL. Data that does not adhere to certain conditions is filtered out prior to being processed.</p>
                        </li>
                        <li>
                           <p>Identifying and separating logical data errors. In simple cases, this can be accomplished using SQL, as shown in <a href="loading-transformation-date-warehouses.html#GUID-033C3049-7936-46C2-881C-14BA409D294B__i1006454">Example 18-1</a>, or in more complex cases in a procedural approach, as shown in <a href="loading-transformation-date-warehouses.html#GUID-53CA1DE7-F323-46AA-8803-C76E1642486B__CACFHAGG">Example 18-6</a>.
                           </p>
                        </li>
                     </ul>
                  </div>
               </div><a id="DWHSG8335"></a><div class="props_rev_3"><a id="GUID-92563272-9748-4A5F-882E-7A645BF69859" name="GUID-92563272-9748-4A5F-882E-7A645BF69859"></a><h4 id="DWHSG-GUID-92563272-9748-4A5F-882E-7A645BF69859" class="sect4"><span class="enumeration_section">18.4.2 </span>Data Rule Violations (Data Errors)
                  </h4>
                  <div>
                     <p>Unlike logical errors, data rule violations are not usually anticipated by the load or transformation process. Such unexpected data rule violations (also known as data errors) that are not handled from an operation cause the operation to fail. Data rule violations are error conditions that happen inside the database and cause a statement to fail. Examples of this are data type conversion errors or constraint violations.</p>
                     <p></p>
                     <p>In the past, SQL did not offer a way to handle data errors on a row level as part of its bulk processing. The only way to handle data errors inside the database was to use PL/SQL. Now, however, you can log data errors into a special error table while the DML operation continues. You can also handle data conversion errors using SQL functions.</p>
                     <p>The following sections briefly discuss the various exception handling strategies:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><a href="loading-transformation-date-warehouses.html#GUID-F26DFED8-0A21-4546-8E74-CD3741DFFFC0" title="External data that is used during the data transformation process may sometimes be inaccurate thereby causing data conversion errors. Certain SQL functions can be used to handle data conversion errors.">Handling Data Errors with SQL</a></p>
                        </li>
                        <li>
                           <p><a href="loading-transformation-date-warehouses.html#GUID-9AC08819-AA89-4FCE-8F87-0DA0E6932C29">Handling Data Errors in PL/SQL</a></p>
                        </li>
                        <li>
                           <p><a href="loading-transformation-date-warehouses.html#GUID-F8F527F2-A7D7-4262-A1F0-D1E84FC3DD54">Handling Data Errors with an Error Logging Table</a></p>
                        </li>
                     </ul>
                  </div>
                  <div class="sect4"><a id="GUID-F26DFED8-0A21-4546-8E74-CD3741DFFFC0" name="GUID-F26DFED8-0A21-4546-8E74-CD3741DFFFC0"></a><h5 id="DWHSG-GUID-F26DFED8-0A21-4546-8E74-CD3741DFFFC0" class="sect5"><span class="enumeration_section">18.4.2.1 </span>Handling Data Errors with SQL
                     </h5>
                     <div>
                        <p>External data that is used during the data transformation process may sometimes be inaccurate thereby causing data conversion errors. Certain SQL functions can be used to handle data conversion errors.</p>
                        <div class="p">
                           <p></p>
                           <p>The <code class="codeph">COMPATIBLE</code> parameter must be set to 12.2 to use SQL functions that handle data conversion errors.
                           </p>
                           <p>The following strategies are available to handle data conversion errors with SQL functions:</p>
                        </div>
                        <!-- class="section" -->
                        <ul>
                           <li class="stepexpand"><span>Explicit filtering of either valid or invalid data</span><div>
                                 <p>The <code class="codeph">VALIDATE_CONVERSION</code> function identifies problem data that cannot be converted to the required data type. It returns 1 if a given expression can be converted to the specified data type, else it returns 0.
                                 </p>
                              </div>
                           </li>
                           <li class="stepexpand"><span>Error handling within SQL data type conversion functions</span><div>
                                 <p>The <code class="codeph">CAST</code>, <code class="codeph">TO_NUMBER</code>, <code class="codeph">TO_BINARY_FLOAT</code>, <code class="codeph">TO_BINARY_DOUBLE</code>, <code class="codeph">TO_DATE</code>, <code class="codeph">TO_TIMESTAMP</code>, <code class="codeph">TO_TIMESTAMP_TZ</code>, <code class="codeph">TO_DSINTERVAL</code>, and <code class="codeph">TO_YMINTERVAL</code> functions can return a user-specified value, instead of an error, when data type conversion errors occur. This reduces failures during an ETL process.
                                 </p>
                                 <p>The user-specified value is returned only if an error occurs while converting the expression, not when evaluating the expression. The <code class="codeph">CAST</code> function also allows format strings and NLS parameter strings as arguments for certain data types.
                                 </p>
                              </div>
                           </li>
                        </ul>
                        <div class="example" id="GUID-F26DFED8-0A21-4546-8E74-CD3741DFFFC0__GUID-C01B88B1-1D36-42E1-9488-C49C89888DE9">
                           <p class="titleinexample">Example 18-9 Using VALIDATE_CONVERSION and CAST to Handle Data Conversion Errors</p>
                           <p>Assume that data is loaded into the <code class="codeph">PRODUCTS</code> table from the <code class="codeph">TMP_PRODUCTS</code> table. The number and names of columns in both tables are the same, but the data type of the <code class="codeph">prod_id</code> column is different. The <code class="codeph">prod_id</code> column in the <code class="codeph">PRODUCTS</code> table is of data type <code class="codeph">NUMBER</code>. Although the data in the <code class="codeph">prod_id</code> column in the <code class="codeph">TMP_PRODUCTS</code> table is numeric, its data type is <code class="codeph">VARCHAR2</code>. While loading data into the <code class="codeph">PRODUCTS</code> table, you can handle data type conversion errors on the <code class="codeph">prod_id</code> column by either filtering out the rows containing incorrect <code class="codeph">prod_id</code> values or assigning a default value for <code class="codeph">prod_id</code> values that cannot be converted to <code class="codeph">NUMBER</code>.
                           </p>
                           <p>The following command loads data from the <code class="codeph">TMP_PRODUCTS</code> table into <code class="codeph">PRODUCTS</code> table. Only rows where <code class="codeph">tmp_products.prod_id</code> can be successfully converted into a numeric value are inserted.
                           </p><pre class="pre codeblock"><code>INSERT INTO PRODUCTS 
   (SELECT prod_id, prod_name, prod_desc, prod_category_id, prod_category_name, 
       prod_category_desc, prod_list_price 
    FROM tmp_products
    WHERE VALIDATE_CONVERSION(prod_id AS NUMBER)=1);</code></pre><p>You can use the <code class="codeph">CAST</code> function to handle <code class="codeph">prod_id</code> values that cause data type conversion errors. The following <code class="codeph">INSERT</code> command loads data from the <code class="codeph">TMP_PRODUCTS</code> table into the <code class="codeph">PRODUCTS</code> table. The <code class="codeph">CAST</code> function used with <code class="codeph">prod_id</code> ensures that the default value of 0 is assigned to <code class="codeph">prod_id</code> when a data type conversion error occurs. This ensures that the load operation does not fail because of data type conversion errors.
                           </p><pre class="pre codeblock"><code>INSERT INTO PRODUCTS 
   (SELECT CAST(prod_id AS NUMBER DEFAULT 0 ON CONVERSION ERROR), prod_name, 
       prod_desc, prod_category_id, prod_category_name, prod_category_desc, 
       prod_list_price 
    FROM tmp_products);</code></pre><div class="infoboxnotealso" id="GUID-F26DFED8-0A21-4546-8E74-CD3741DFFFC0__GUID-DA74FAC3-7E9C-486C-B23C-CB395515DAC7">
                              <p class="notep1">See Also:</p>
                              <p><a href="../sqlrf/Functions.html#SQLRF-GUID-D079EFD3-C683-441F-977E-2C9503089982" target="_blank"><span><cite>Oracle Database SQL Language Reference</cite></span></a> for more information about the <code class="codeph">CAST</code> and <code class="codeph">VALIDATE_CONVERSION</code> functions and their supported data types
                              </p>
                           </div>
                        </div>
                        <!-- class="example" -->
                     </div>
                  </div><a id="DWHSG8336"></a><div class="props_rev_3"><a id="GUID-9AC08819-AA89-4FCE-8F87-0DA0E6932C29" name="GUID-9AC08819-AA89-4FCE-8F87-0DA0E6932C29"></a><h5 id="DWHSG-GUID-9AC08819-AA89-4FCE-8F87-0DA0E6932C29" class="sect5"><span class="enumeration_section">18.4.2.2 </span>Handling Data Errors in PL/SQL
                     </h5>
                     <div>
                        <div class="section">
                           <p>The following statement is an example of how error handling can be done using PL/SQL. Note that you have to use procedural record-level processing to catch any errors. This statement is a rough equivalent of the statement discussed in <span class="q">"<a href="loading-transformation-date-warehouses.html#GUID-F8F527F2-A7D7-4262-A1F0-D1E84FC3DD54">Handling Data Errors with an Error Logging Table</a>"</span>.
                           </p><pre class="oac_no_warn" dir="ltr">DECLARE
errm number default 0;
BEGIN
FOR crec IN (SELECT product_id, customer_id, TRUNC(sales_date) sd,
                   promotion_id, quantity, amount
             FROM sales_activity_direct) loop
 
BEGIN
 INSERT INTO sales VALUES (crec.product_id, crec.customer_id,
                           crec.sd, 3, crec.promotion_id,
                           crec.quantity, crec.amount);
exception
WHEN others then
 errm := sqlerrm;
 INSERT INTO sales_activity_error
        VALUES (errm, crec.product_id, crec.customer_id, crec.sd,
                crec.promotion_id, crec.quantity, crec.amount);
END;
END loop;
END;
/</pre></div>
                        <!-- class="section" -->
                     </div>
                  </div><a id="DWHSG8337"></a><div class="props_rev_3"><a id="GUID-F8F527F2-A7D7-4262-A1F0-D1E84FC3DD54" name="GUID-F8F527F2-A7D7-4262-A1F0-D1E84FC3DD54"></a><h5 id="DWHSG-GUID-F8F527F2-A7D7-4262-A1F0-D1E84FC3DD54" class="sect5"><span class="enumeration_section">18.4.2.3 </span>Handling Data Errors with an Error Logging Table
                     </h5>
                     <div>
                        <div class="section">
                           <p>DML error<a id="d63021e1771" class="indexterm-anchor"></a> logging extends existing DML functionality by enabling you to specify the name of an error logging table into which Oracle Database should record errors encountered during DML operations. This enables you to complete the DML operation in spite of any errors, and to take corrective action on the erroneous rows at a later time.
                           </p>
                           <p>This DML error logging table consists of several mandatory control columns and a set of user-defined columns that represent either all or a subset of the columns of the target table of the DML operation using a data type that is capable of storing potential errors for the target column. For example, you need a <code class="codeph">VARCHAR2</code> data type in the error logging table to store <code class="codeph">TO_NUM</code> data type conversion errors for a <code class="codeph">NUMBER</code> column in the target table. You<a id="d63021e1787" class="indexterm-anchor"></a> should use the <code class="codeph">DBMS_ERRLOG</code> package to create the DML error logging tables. See the <a href="../arpls/DBMS_ERRLOG.html#ARPLS680" target="_blank"><span class="italic">Oracle Database PL/SQL Packages and Types Reference</span></a> for more information about this package and the structure of the logging table.
                           </p>
                           <p>The column name mapping between the DML target table and an error logging table determines which columns besides the control columns is logged for a DML operation.</p>
                           <p>The following statement illustrates how to enhance the example in <span class="q">"<a href="loading-transformation-date-warehouses.html#GUID-E1BA12C1-5CE7-405C-8BC7-745ADE615E90">Transforming Data Using SQL</a>"</span> with DML error logging:
                           </p><pre class="oac_no_warn" dir="ltr">INSERT /*+ APPEND PARALLEL */
INTO sales SELECT product_id, customer_id, TRUNC(sales_date), 3,
   promotion_id, quantity, amount
FROM sales_activity_direct
LOG ERRORS INTO sales_activity_errors('load_20040802')
REJECT LIMIT UNLIMITED
</pre><p>All data errors are logged into table <code class="codeph">sales_activity_errors</code>, identified by the optional tag <code class="codeph">load_20040802</code>. The <code class="codeph">INSERT</code> statement succeeds even in the presence of data errors. Note that you have to create the DML error logging table prior to using this statement.
                           </p>
                           <p>If <code class="codeph">REJECT</code> <code class="codeph">LIMIT</code> <code class="codeph">X</code> had been specified, the statement would have failed with the error message of <code class="codeph">error X=1</code>. The error message can be different for different reject limits. In the case of a failing statement, only the DML statement is rolled back, not the insertion into the DML error logging table. The error logging table will contain X+1 rows.
                           </p>
                           <p>A DML error logging table can be in a different schema than the executing user, but you must fully specify the table name in that case. Optionally, the name of the DML error logging table can be omitted; Oracle then assumes a default name for the table as generated by <a id="d63021e1839" class="indexterm-anchor"></a><a id="d63021e1841" class="indexterm-anchor"></a>the <code class="codeph">DBMS_ERRLOG</code> package.
                           </p>
                           <p>Oracle Database logs the following errors during DML operations:</p>
                        </div>
                        <!-- class="section" -->
                        <div class="section">
                           <ul style="list-style-type: disc;">
                              <li>
                                 <p>Column values that are too large.</p>
                              </li>
                              <li>
                                 <p>Constraint violations (<code class="codeph">NOT</code> <code class="codeph">NULL</code>, unique, referential, and check constraints).
                                 </p>
                              </li>
                              <li>
                                 <p>Errors raised during trigger execution.</p>
                              </li>
                              <li>
                                 <p>Errors resulting from type conversion between a column in a subquery and the corresponding column of the table.</p>
                              </li>
                              <li>
                                 <p>Partition mapping errors.</p>
                              </li>
                           </ul>
                           <p>The following conditions cause the statement to fail and roll back without invoking the error logging capability:</p>
                           <ul style="list-style-type: disc;">
                              <li>
                                 <p>Violated deferred constraints.</p>
                              </li>
                              <li>
                                 <p>Out of space errors.</p>
                              </li>
                              <li>
                                 <p>Any direct-path <code class="codeph">INSERT</code> operation (<code class="codeph">INSERT</code> or <code class="codeph">MERGE</code>) that raises a unique constraint or index violation.
                                 </p>
                              </li>
                              <li>
                                 <p>Any <code class="codeph">UPDATE</code> operation (<code class="codeph">UPDATE</code> or <code class="codeph">MERGE</code>) that raises a unique constraint or index violation.
                                 </p>
                              </li>
                           </ul>
                           <p>In addition, you cannot track errors in the error logging table for <code class="codeph">LONG</code>, <code class="codeph">LOB</code>, or object type columns. See <a href="../sqlrf/INSERT.html#SQLRF55101" target="_blank"><span class="italic">Oracle Database SQL Language Reference</span></a> for more information on restrictions when using error logging.
                           </p>
                           <p>DML error logging can be applied to any kind of DML operation. Several examples are discussed in the following section.</p>
                           <p>Note that SQL*Loader as an external load utility offers the functionality of logging data errors as well, but lacks the advantage of the integrated ETL processing inside the database.</p>
                        </div>
                        <!-- class="section" -->
                     </div>
                  </div>
               </div>
            </div><a id="DWHSG8338"></a><div class="props_rev_3"><a id="GUID-DD11528E-EE2A-4640-B8F1-75E6D3EB08F6" name="GUID-DD11528E-EE2A-4640-B8F1-75E6D3EB08F6"></a><h3 id="DWHSG-GUID-DD11528E-EE2A-4640-B8F1-75E6D3EB08F6" class="sect3"><span class="enumeration_section">18.5 </span>Loading and Transformation Scenarios
               </h3>
               <div>
                  <p>The following sections offer examp<a id="d63021e1946" class="indexterm-anchor"></a>les of typical loading and transformation tasks:
                  </p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p><a href="loading-transformation-date-warehouses.html#GUID-8AFBA8C7-D42C-4860-942D-BF5DB229B378">Key Lookup Scenario</a></p>
                     </li>
                     <li>
                        <p><a href="loading-transformation-date-warehouses.html#GUID-F03860DA-EE32-46EF-A670-D6E7DE037669">Business Rule Violation Scenario</a></p>
                     </li>
                     <li>
                        <p><a href="loading-transformation-date-warehouses.html#GUID-E99E3CAC-83BC-448E-9CF3-D45432BE34A0">Data Error Scenarios</a></p>
                     </li>
                     <li>
                        <p><a href="loading-transformation-date-warehouses.html#GUID-BE3DFCBF-6BDF-421D-BA6D-F37EB98D6ECD">Pivoting Scenarios</a></p>
                     </li>
                  </ul>
               </div><a id="DWHSG8339"></a><div class="props_rev_3"><a id="GUID-8AFBA8C7-D42C-4860-942D-BF5DB229B378" name="GUID-8AFBA8C7-D42C-4860-942D-BF5DB229B378"></a><h4 id="DWHSG-GUID-8AFBA8C7-D42C-4860-942D-BF5DB229B378" class="sect4"><span class="enumeration_section">18.5.1 </span>Key Lookup Scenario
                  </h4>
                  <div>
                     <p><a id="d63021e1993" class="indexterm-anchor"></a>A typical transformation is the key lookup. For example, suppose that sales transaction data has been loaded into a retail data warehouse. Although the data warehouse's <code class="codeph">sales</code> table contains a <code class="codeph">product_id</code> column, the sales transaction data extracted from the source system contains Uniform Price Codes (UPC) instead of product IDs. Therefore, it is necessary to transform the UPC codes into product IDs before the new sales transaction data can be inserted into the <code class="codeph">sales</code> table.
                     </p>
                     <p>In order to execute this transformation, a lookup table must relate the <code class="codeph">product_id</code> values to the UPC codes. This table might be the <code class="codeph">product</code> dimension table, or perhaps another table in the data warehouse that has been created specifically to support this transformation. For this example, you assume that there is a table named <code class="codeph">product</code>, which has a <code class="codeph">product_id</code> and an <code class="codeph">upc_code</code> column.
                     </p>
                     <p>This data substitution transformation can be implemented using the following CTAS statement:</p><pre class="oac_no_warn" dir="ltr">CREATE TABLE temp_sales_step2 NOLOGGING PARALLEL AS SELECT sales_transaction_id,
  product.product_id sales_product_id, sales_customer_id, sales_time_id,
  sales_channel_id, sales_quantity_sold, sales_dollar_amount
FROM  temp_sales_step1, product
WHERE temp_sales_step1.upc_code = product.upc_code;
</pre><p>This CTAS statement converts each valid UPC code to a valid <code class="codeph">product_id</code> value. If the ETL process has guaranteed that each UPC code is valid, then this statement alone may be sufficient to implement the entire transformation.
                     </p>
                  </div>
               </div><a id="DWHSG8340"></a><div class="props_rev_3"><a id="GUID-F03860DA-EE32-46EF-A670-D6E7DE037669" name="GUID-F03860DA-EE32-46EF-A670-D6E7DE037669"></a><h4 id="DWHSG-GUID-F03860DA-EE32-46EF-A670-D6E7DE037669" class="sect4"><span class="enumeration_section">18.5.2 </span>Business Rule Violation Scenario
                  </h4>
                  <div>
                     <p>In the preceding example, if you must also handle new sales data that does not have valid UPC codes (a logical data error), you can use an additional CTAS statement to identify the invalid rows:</p><pre class="oac_no_warn" dir="ltr">CREATE TABLE temp_sales_step1_invalid NOLOGGING PARALLEL AS
SELECT * FROM temp_sales_step1 s
WHERE NOT EXISTS (SELECT 1 FROM product p WHERE p.upc_code=s.upc_code);
</pre><p>This invalid data is now stored in a separate table, <code class="codeph">temp_sales_step1_invalid</code>, and can be handled separately by the ETL process.
                     </p>
                     <p>Another way to handle invalid data is to modify the original CTAS to use an outer join, as in the following statement:</p><pre class="oac_no_warn" dir="ltr">CREATE TABLE temp_sales_step2 NOLOGGING PARALLEL AS
SELECT sales_transaction_id, product.product_id sales_product_id,
   sales_customer_id, sales_time_id, sales_channel_id, sales_quantity_sold,
   sales_dollar_amount
FROM  temp_sales_step1, product
WHERE temp_sales_step1.upc_code = product.upc_code (+);
</pre><p>Using this outer join, the sales transactions that originally contained invalidated UPC codes are assigned a <code class="codeph">product_id</code> of <code class="codeph">NULL</code>. These transactions can be handled later. Alternatively, you could use a multi-table insert, separating the values with a <code class="codeph">product_id</code> of <code class="codeph">NULL</code> into a separate table; this might be a beneficial approach when the expected error count is relatively small compared to the total data volume. You do not have to touch the large target table but only a small one for a subsequent processing.
                     </p><pre class="oac_no_warn" dir="ltr">INSERT /*+ APPEND PARALLEL */ FIRST
WHEN sales_product_id IS NOT NULL THEN
   INTO temp_sales_step2
   VALUES (sales_transaction_id, sales_product_id,
   sales_customer_id, sales_time_id, sales_channel_id,
   sales_quantity_sold, sales_dollar_amount)
ELSE
   INTO temp_sales_step1_invalid
   VALUES (sales_transaction_id, sales_product_id,
   sales_customer_id, sales_time_id, sales_channel_id,
   sales_quantity_sold, sales_dollar_amount)
SELECT sales_transaction_id, product.product_id sales_product_id,
   sales_customer_id, sales_time_id, sales_channel_id,
   sales_quantity_sold, sales_dollar_amount
FROM temp_sales_step1, product
WHERE temp_sales_step1.upc_code = product.upc_code (+);
</pre><p>Note that for this solution, the empty tables <code class="codeph">temp_sales_step2</code> and <code class="codeph">temp_sales_step1_invalid</code> must already exist.
                     </p>
                     <p>Additional approaches to handling invalid UPC codes exist. Some data warehouses may choose to insert null-valued <code class="codeph">product_id</code> values into their <code class="codeph">sales</code> table, while others may not allow any new data from the entire batch to be inserted into the <code class="codeph">sales</code> table until all invalid UPC codes have been addressed. The correct approach is determined by the business requirements of the data warehouse. Irrespective of the specific requirements, exception handling can be addressed by the same basic SQL techniques as transformations.
                     </p>
                  </div>
               </div><a id="DWHSG8341"></a><div class="props_rev_3"><a id="GUID-E99E3CAC-83BC-448E-9CF3-D45432BE34A0" name="GUID-E99E3CAC-83BC-448E-9CF3-D45432BE34A0"></a><h4 id="DWHSG-GUID-E99E3CAC-83BC-448E-9CF3-D45432BE34A0" class="sect4"><span class="enumeration_section">18.5.3 </span>Data Error Scenarios
                  </h4>
                  <div>
                     <p>If the quality of the data is unknown, the example discussed in <a href="loading-transformation-date-warehouses.html#GUID-F03860DA-EE32-46EF-A670-D6E7DE037669">Business Rule Violation Scenario</a> could be enhanced to handle unexpected data errors, for example, data type conversion errors, as shown in the following:
                     </p><pre class="oac_no_warn" dir="ltr">INSERT /*+ APPEND PARALLEL */ FIRST
WHEN sales_product_id IS NOT NULL THEN
INTO temp_sales_step2
VALUES (sales_transaction_id, sales_product_id,
   sales_customer_id, sales_time_id, sales_channel_id,
   sales_quantity_sold, sales_dollar_amount)
LOG ERRORS INTO sales_step2_errors('load_20040804')
REJECT LIMIT UNLIMITED
ELSE
INTO temp_sales_step1_invalid
VALUES (sales_transaction_id, sales_product_id,
   sales_customer_id, sales_time_id, sales_channel_id,
   sales_quantity_sold, sales_dollar_amount)
LOG ERRORS INTO sales_step2_errors('load_20040804')
REJECT LIMIT UNLIMITED
SELECT sales_transaction_id, product.product_id sales_product_id,
   sales_customer_id, sales_time_id, sales_channel_id,
   sales_quantity_sold, sales_dollar_amount
FROM temp_sales_step1, product
WHERE temp_sales_step1.upc_code = product.upc_code (+);
</pre><p>This statement tracks the logical data error of not having a valid product UPC code in table <code class="codeph">temp_sales_step1_invalid</code> and all other possible errors in a DML error logging table called <code class="codeph">sales_step2_errors</code>. Note that an error logging table can be used for several DML operations.
                     </p>
                     <p>An alternative to this approach would be to enforce the business rule of having a valid UPC code on the database level with a <code class="codeph">NOT</code> <code class="codeph">NULL</code> constraint. Using an outer join, all orders not having a valid UPC code would be mapped to a <code class="codeph">NULL</code> value and then treated as data errors. This DML error logging capability is used to track these errors in the following statement:
                     </p><pre class="oac_no_warn" dir="ltr">INSERT /*+ APPEND PARALLEL */
INTO temp_sales_step2
VALUES (sales_transaction_id, sales_product_id,
   sales_customer_id, sales_time_id, sales_channel_id,
   sales_quantity_sold, sales_dollar_amount)
SELECT sales_transaction_id, product.product_id sales_product_id,
   sales_customer_id, sales_time_id, sales_channel_id,
   sales_quantity_sold, sales_dollar_amount
FROM temp_sales_step1, product
WHERE temp_sales_step1.upc_code = product.upc_code (+)
LOG ERRORS INTO sales_step2_errors('load_20040804')
REJECT LIMIT UNLIMITED;
</pre><p>The error logging table contains all records that would have caused the DML operation to fail. You can use its content to analyze and correct any error. The content in the error logging table is preserved for any DML operation, irrespective of the success of the DML operation itself. Let us assume the following SQL statement failed because the reject limit was reached:</p><pre class="oac_no_warn" dir="ltr">SQL&gt; INSERT /*+ APPEND NOLOGGING PARALLEL */ INTO sales_overall
2 SELECT * FROM sales_activity_direct
3 LOG ERRORS INTO err$_sales_overall ('load_test2')
4 REJECT LIMIT 10;
SELECT * FROM sales_activity_direct
*
ERROR at line 2:
ORA-01722: invalid number
</pre><p>The <a id="d63021e2155" class="indexterm-anchor"></a>name of the error logging table, <code class="codeph">err$_sales_overall</code>, is the default derived by using the <code class="codeph">DBMS_ERRLOG</code> package. See <a href="../arpls/DBMS_ERRLOG.html#ARPLS680" target="_blank"><span class="italic">Oracle Database PL/SQL Packages and Types Reference</span></a> for more information.
                     </p>
                     <p>The error message raised by Oracle occurs where the first after the error limit is reached. The next error (number 11) is the one that raised an error. The error message that is displayed is based on the error that exceeded the limit, so, for example, the ninth error could be different from the eleventh error.</p>
                     <p>The target table <code class="codeph">sales_overall</code> will not show any records being entered (assumed that the table was empty before), but the error logging table will contain 11 rows (<code class="codeph">REJECT</code> <code class="codeph">LIMIT</code> <code class="codeph">+</code> <code class="codeph">1</code>)
                     </p><pre class="oac_no_warn" dir="ltr">SQL&gt; SELECT COUNT(*) FROM sales_overall;
COUNT(*)
----------
0

SQL&gt; SELECT COUNT(*) FROM err$_sales_overall;
COUNT(*)
----------
11
</pre><p>A DML error logging table consists of several fixed control columns that are mandatory for every error logging table. Besides the Oracle error number, Oracle enforces storing the error message as well. In many cases, the error message provides additional information to analyze and resolve the root cause for the data error. The following SQL output of a DML error logging table shows this difference. Note that the second output contains the additional information for rows that were rejected due to <code class="codeph">NOT</code> <code class="codeph">NULL</code> violations.
                     </p><pre class="oac_no_warn" dir="ltr">SQL&gt; SELECT DISTINCT ora_err_number$ FROM err$_sales_overall;

ORA_ERR_NUMBER$
---------------
           1400
           1722
           1830
           1847

SQL&gt; SELECT DISTINCT ora_err_number$, ora_err_mesg$ FROM err$_sales_overall;

ORA_ERR_NUMBER$       ORA_ERR_MESG$
           1400       ORA-01400: cannot insert NULL into
                      ("SH"."SALES_OVERALL"."CUST_ID")
           1400       ORA-01400: cannot insert NULL into
                      ("SH"."SALES_OVERALL"."PROD_ID")
           1722       ORA-01722: invalid number
           1830       ORA-01830: date format picture ends before
                      converting entire input string
           1847       ORA-01847: day of month must be between 1 and last
                      day of month
</pre><div class="infoboxnotealso" id="GUID-E99E3CAC-83BC-448E-9CF3-D45432BE34A0__GUID-061305F1-B55F-4522-9BF0-72BE286359F1">
                        <p class="notep1">See Also:</p>
                        <p><a href="../admin/managing-tables.html#ADMIN10261" target="_blank"><span class="italic">Oracle Database Administrator's Guide</span></a> for a detailed description of control columns.
                        </p>
                     </div>
                  </div>
               </div><a id="DWHSG8343"></a><a id="DWHSG8342"></a><div class="props_rev_3"><a id="GUID-BE3DFCBF-6BDF-421D-BA6D-F37EB98D6ECD" name="GUID-BE3DFCBF-6BDF-421D-BA6D-F37EB98D6ECD"></a><h4 id="DWHSG-GUID-BE3DFCBF-6BDF-421D-BA6D-F37EB98D6ECD" class="sect4"><span class="enumeration_section">18.5.4 </span>Pivoting Scenarios
                  </h4>
                  <div>
                     <p><a id="d63021e2232" class="indexterm-anchor"></a>A data warehouse can<a id="d63021e2235" class="indexterm-anchor"></a> receive data from many different sources. Some of these source systems may not be relational databases and may store data in very different formats from the data warehouse. For example, suppose that you receive a set of sales records from a nonrelational database having the form:
                     </p><pre class="oac_no_warn" dir="ltr">product_id, customer_id, weekly_start_date, sales_sun, sales_mon, sales_tue,
  sales_wed, sales_thu, sales_fri, sales_sat
</pre><p>The input table looks like the following:</p><pre class="oac_no_warn" dir="ltr">SELECT * FROM sales_input_table;
</pre><pre class="oac_no_warn" dir="ltr">PRODUCT_ID CUSTOMER_ID WEEKLY_ST  SALES_SUN  SALES_MON  SALES_TUE  SALES_WED SALES_THU  SALES_FRI  SALES_SAT
---------- ----------- --------- ---------- ---------- ---------- -------------------- ---------- ----------
       111         222 01-OCT-00        100        200        300        400       500        600        700
       222         333 08-OCT-00        200        300        400        500       600        700        800
       333         444 15-OCT-00        300        400        500        600       700        800        900</pre><p>In your data warehouse, you would want to store the records in a more typical relational form in a fact table <code class="codeph">sales</code> of the <code class="codeph">sh</code> sample schema: 
                     </p><pre class="oac_no_warn" dir="ltr">prod_id, cust_id, time_id, amount_sold</pre><div class="infoboxnote" id="GUID-BE3DFCBF-6BDF-421D-BA6D-F37EB98D6ECD__GUID-C310F522-8844-48A7-83E8-A1EB97C34BD3">
                        <p class="notep1">Note:</p>
                        <p>A number of constraints on the <code class="codeph">sales</code> table have been disabled for purposes of this example, because the example ignores a number of table columns for the sake of brevity.
                        </p>
                     </div>
                     <p>Thus, you need to build a transformation such that each record in the input stream must be converted into seven records for the data warehouse's <code class="codeph">sales</code> table. This operation is commonly referred to as <a href="glossary.html#GUID-CE6745C6-610E-4EEA-BD47-534C9CBF44A9"><span class="xrefglossterm">pivoting</span></a>, and Oracle Database offers several ways to do this.
                     </p>
                     <p>The result of the previous example will resemble the following:</p><pre class="oac_no_warn" dir="ltr">SELECT prod_id, cust_id, time_id, amount_sold FROM sales;

   PROD_ID    CUST_ID   TIME_ID   AMOUNT_SOLD
---------- ----------   --------- -----------
       111        222   01-OCT-00         100
       111        222   02-OCT-00         200
       111        222   03-OCT-00         300
       111        222   04-OCT-00         400
       111        222   05-OCT-00         500
       111        222   06-OCT-00         600
       111        222   07-OCT-00         700
       222        333   08-OCT-00         200
       222        333   09-OCT-00         300
       222        333   10-OCT-00         400
       222        333   11-OCT-00         500
       222        333   12-OCT-00         600
       222        333   13-OCT-00         700
       222        333   14-OCT-00         800
       333        444   15-OCT-00         300
       333        444   16-OCT-00         400
       333        444   17-OCT-00         500
       333        444   18-OCT-00         600
       333        444   19-OCT-00         700
       333        444   20-OCT-00         800
       333        444   21-OCT-00         900</pre><div class="example" id="GUID-BE3DFCBF-6BDF-421D-BA6D-F37EB98D6ECD__GUID-82E18458-E50D-4335-AD42-F5E03B458225">
                        <p class="titleinexample">Example 18-10 Pivoting Example</p>
                        <p>The following example uses the multitable insert syntax to insert into the demo table <code class="codeph">sh.sales</code> some data from an input table with a different structure. The multitable <code class="codeph">INSERT</code> statement looks like the following:
                        </p><pre class="oac_no_warn" dir="ltr">INSERT ALL INTO sales (prod_id, cust_id, time_id, amount_sold)
      VALUES (product_id, customer_id, weekly_start_date, sales_sun)
      INTO sales (prod_id, cust_id, time_id, amount_sold)
      VALUES (product_id, customer_id, weekly_start_date+1, sales_mon)
      INTO sales (prod_id, cust_id, time_id, amount_sold)
      VALUES (product_id, customer_id, weekly_start_date+2, sales_tue)
      INTO sales (prod_id, cust_id, time_id, amount_sold)
      VALUES (product_id, customer_id, weekly_start_date+3, sales_wed)
      INTO sales (prod_id, cust_id, time_id, amount_sold)
      VALUES (product_id, customer_id, weekly_start_date+4, sales_thu)
      INTO sales (prod_id, cust_id, time_id, amount_sold)
      VALUES (product_id, customer_id, weekly_start_date+5, sales_fri)
      INTO sales (prod_id, cust_id, time_id, amount_sold)
      VALUES (product_id, customer_id, weekly_start_date+6, sales_sat)
SELECT product_id, customer_id, weekly_start_date, sales_sun,
      sales_mon, sales_tue, sales_wed, sales_thu, sales_fri, sales_sat
FROM sales_input_table;
</pre><p>This statement only scans the source table once and then inserts the appropriate data for each day.</p>
                     </div>
                     <!-- class="example" -->
                     <div class="infoboxnotealso" id="GUID-BE3DFCBF-6BDF-421D-BA6D-F37EB98D6ECD__GUID-52555A81-C1EA-47A4-942E-9ACE219CBAED">
                        <p class="notep1">See Also:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><span class="q">"<a href="sql-analysis-reporting-data-warehouses.html#GUID-05BB22CD-0F53-4C90-AE84-CE3F88DBD591">Pivoting Operations</a>"</span> for more information regarding pivoting
                              </p>
                           </li>
                           <li>
                              <p><a href="../sqlrf/SELECT.html#SQLRF01702" target="_blank"><span class="italic">Oracle Database SQL Language Reference</span></a> for <code class="codeph">pivot_clause</code> syntax
                              </p>
                           </li>
                        </ul>
                     </div>
                  </div>
               </div>
            </div>
         </div>
      </article>
   </body>
</html>