<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xml:lang="en-us" lang="en-us">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <meta name="abstract" content="Parallel execution enables the application of multiple CPU and I/O resources to the execution of a single SQL statement.">
      <meta name="description" content="Parallel execution enables the application of multiple CPU and I/O resources to the execution of a single SQL statement.">
      <title>Parallel Execution Concepts</title>
      <meta property="og:site_name" content="Oracle Help Center">
      <meta property="og:title" content="VLDB and Partitioning Guide">
      <meta property="og:description" content="Parallel execution enables the application of multiple CPU and I/O resources to the execution of a single SQL statement.">
      <link rel="stylesheet" href="/sp_common/book-template/ohc-book-template/css/book.css">
      <link rel="shortcut icon" href="/sp_common/book-template/ohc-common/img/favicon.ico">
      <meta name="application-name" content="VLDB and Partitioning Guide">
      <meta name="generator" content="DITA Open Toolkit version 1.8.5 (Mode = doc)">
      <meta name="plugin" content="SP_docbuilder HTML plugin release 18.2.2">
      <link rel="alternate" href="vldb-and-partitioning-guide.pdf" title="PDF File" type="application/pdf">
      <meta name="robots" content="all">
      <link rel="schema.dcterms" href="http://purl.org/dc/terms/">
      <meta name="dcterms.created" content="2019-04-23T18:05:22-07:00">
      <meta name="dcterms.title" content="VLDB and Partitioning Guide">
      <meta name="dcterms.dateCopyrighted" content="2008, 2019">
      <meta name="dcterms.category" content="database">
      <meta name="dcterms.identifier" content="E96199-03">
      
      <meta name="dcterms.product" content="en/database/oracle/oracle-database/19">
      
      <link rel="prev" href="using-parallel.html" title="Previous" type="text/html">
      <link rel="next" href="degree-parallel.html" title="Next" type="text/html">
      <script>
        document.write('<style type="text/css">');
        document.write('body > .noscript, body > .noscript ~ * { visibility: hidden; }');
        document.write('</style>');
     </script>
      <script data-main="/sp_common/book-template/ohc-book-template/js/book-config" src="/sp_common/book-template/requirejs/require.js"></script>
      <script>
            if (window.require === undefined) {
                document.write('<script data-main="sp_common/book-template/ohc-book-template/js/book-config" src="sp_common/book-template/requirejs/require.js"><\/script>');
                document.write('<link href="sp_common/book-template/ohc-book-template/css/book.css" rel="stylesheet"/>');
            }
        </script>
      <script type="application/json" id="ssot-metadata">{"primary":{"category":{"short_name":"database","element_name":"Database","display_in_url":true},"suite":{"short_name":"oracle","element_name":"Oracle","display_in_url":true},"product_group":{"short_name":"not-applicable","element_name":"Not applicable","display_in_url":false},"product":{"short_name":"oracle-database","element_name":"Oracle Database","display_in_url":true},"release":{"short_name":"19","element_name":"Release 19","display_in_url":true}}}</script>
      
    <meta name="dcterms.isVersionOf" content="VLDBG">
    <meta name="dcterms.release" content="Release 19">
  </head>
   <body>
      <div class="noscript alert alert-danger text-center" role="alert">
         <a href="using-parallel.html" class="pull-left"><span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span>Previous</a>
         <a href="degree-parallel.html" class="pull-right">Next<span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span></a>
         <span class="fa fa-exclamation-triangle" aria-hidden="true"></span> JavaScript must be enabled to correctly display this content
        
      </div>
      <article>
         <header>
            <ol class="breadcrumb" vocab="http://schema.org/" typeof="BreadcrumbList">
               <li property="itemListElement" typeof="ListItem"><a href="index.html" property="item" typeof="WebPage"><span property="name">VLDB and Partitioning Guide</span></a></li>
               <li property="itemListElement" typeof="ListItem"><a href="using-parallel.html" property="item" typeof="WebPage"><span property="name">Using Parallel Execution</span></a></li>
               <li class="active" property="itemListElement" typeof="ListItem">Parallel Execution Concepts</li>
            </ol>
            <a id="GUID-F9A83EDB-42AD-4638-9A2E-F66FE09F2B43" name="GUID-F9A83EDB-42AD-4638-9A2E-F66FE09F2B43"></a><a id="VLDBG1377"></a>
            
            <h2 id="VLDBG-GUID-F9A83EDB-42AD-4638-9A2E-F66FE09F2B43" class="sect2">Parallel Execution Concepts</h2>
         </header>
         <div class="ind">
            <div>
               <p>Parallel execution enables the application of multiple CPU and I/O resources to the execution of a single SQL statement.</p>
               <p>Parallel execution dramatically reduces response time for data-intensive operations on large databases typically associated with a decision support system (DSS) and data warehouses. You can also implement parallel execution on an online transaction processing (OLTP) system for batch processing or schema maintenance operations, such as index creations. </p>
               <p>Parallel execution is sometimes called parallelism. Parallelism is the idea of breaking down a task so that, instead of one process doing all of the work in a query, many processes do part of the work at the same time. An example of this is when four processes combine to calculate the total sales for a year, each process handles one quarter of the year instead of a single process handling all four quarters by itself. The improvement in performance can be quite significant. </p>
               <p>Parallel execution improves processing for:</p>
               <ul style="list-style-type: disc;">
                  <li>
                     <p>Queries requiring large table scans, joins, or partitioned index scans</p>
                  </li>
                  <li>
                     <p>Creation of large indexes</p>
                  </li>
                  <li>
                     <p>Creation of large tables, including materialized views</p>
                  </li>
                  <li>
                     <p>Bulk insertions, updates, merges, and deletions</p>
                  </li>
               </ul>
               <p>This section contains the following topics:</p>
               <ul style="list-style-type: disc;">
                  <li>
                     <p><a href="parallel-exec-intro.html#GUID-6CFBCDB8-FEBB-4F78-A68C-0A96D97F9545" title="Parallel execution is used to reduce the execution time of queries by exploiting the CPU and I/O capabilities in the hardware.">When to Implement Parallel Execution</a></p>
                  </li>
                  <li>
                     <p><a href="parallel-exec-intro.html#GUID-F6186F8C-5B41-486E-BBDC-1B63A1BEB54B" title="Serial execution is different than parallel execution in that only one process executes a single database operation, such as a SQL query.">When Not to Implement Parallel Execution</a></p>
                  </li>
                  <li>
                     <p><a href="parallel-exec-intro.html#GUID-5BBC87C2-5FDB-4466-BF75-F49681A7B70F" title="Parallel execution is designed to effectively use multiple CPUs and disks to answer queries quickly.">Fundamental Hardware Requirements</a></p>
                  </li>
                  <li>
                     <p><a href="parallel-exec-intro.html#GUID-98409B8F-5D16-421C-A30F-B1C08E4CA9E1" title="Parallel execution breaks down a task so that, instead of one process doing all of the work in a query, many processes do part of the work at the same time.">How Parallel Execution Works</a></p>
                  </li>
                  <li>
                     <p><a href="parallel-exec-intro.html#GUID-8FC8977A-68A4-4E4D-9FE9-CFDF0DA45C08" title="When an instance starts, Oracle Database creates a pool of parallel execution servers, which are available for any parallel operation.">Parallel Execution Server Pool</a></p>
                  </li>
                  <li>
                     <p><a href="parallel-exec-intro.html#GUID-EFF3E2A2-5C18-43BE-9646-B9F8B00919F7" title="To optimize performance, all parallel execution servers should have equal workloads.">Balancing the Workload to Optimize Performance</a></p>
                  </li>
                  <li>
                     <p><a href="parallel-exec-intro.html#GUID-6BD448A7-E3AE-4171-BC01-70C823AFCE6C" title="Each parallel execution (PX) coordinator in an execution plan is called a parallelizer.">Multiple Parallelizers</a></p>
                  </li>
                  <li>
                     <p><a href="parallel-exec-intro.html#GUID-0266F26D-7342-49CB-9613-228687108924" title="By default in an Oracle RAC environment, a SQL statement executed in parallel can run across all the nodes in the cluster.">Parallel Execution on Oracle RAC</a></p>
                  </li>
               </ul>
            </div><a id="VLDBG1378"></a><div class="props_rev_3"><a id="GUID-6CFBCDB8-FEBB-4F78-A68C-0A96D97F9545" name="GUID-6CFBCDB8-FEBB-4F78-A68C-0A96D97F9545"></a><h3 id="VLDBG-GUID-6CFBCDB8-FEBB-4F78-A68C-0A96D97F9545" class="sect3">When to Implement Parallel Execution</h3>
               <div>
                  <p>Parallel execution is used to reduce the execution time of queries by exploiting the CPU and I/O capabilities in the hardware. </p>
                  <p>Parallel execution is a better choice than serial execution when:</p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p>The query references a large data set.</p>
                     </li>
                     <li>
                        <p>There is low concurrency.</p>
                     </li>
                     <li>
                        <p>Elapsed time is important.</p>
                     </li>
                  </ul>
                  <p>Parallel execution enables many processes working together to execute single operation, such as a SQL query. Parallel execution benefits systems with all of the following characteristics:</p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p>Symmetric multiprocessors (SMPs), clusters, or massively parallel systems</p>
                     </li>
                     <li>
                        <p>Sufficient I/O bandwidth</p>
                     </li>
                     <li>
                        <p>Underutilized or intermittently used CPUs (for example, systems where CPU usage is typically less than 30%)</p>
                     </li>
                     <li>
                        <p>Sufficient memory to support additional memory-intensive processes, such as sorting, hashing, and I/O buffers</p>
                     </li>
                  </ul>
                  <p>If your system lacks any of these characteristics, parallel execution might not significantly improve performance. In fact, parallel execution may reduce system performance on overutilized systems or systems with small I/O bandwidth.</p>
                  <p>The benefits of parallel execution can be observed in DSS and data warehouse environments. OLTP systems can also benefit from parallel execution during batch processing and during schema maintenance operations such as creation of indexes. The average simple DML or <code class="codeph">SELECT</code> statements that characterize OLTP applications would not experience any benefit from being executed in parallel.
                  </p>
               </div>
            </div><a id="VLDBG1379"></a><div class="props_rev_3"><a id="GUID-F6186F8C-5B41-486E-BBDC-1B63A1BEB54B" name="GUID-F6186F8C-5B41-486E-BBDC-1B63A1BEB54B"></a><h3 id="VLDBG-GUID-F6186F8C-5B41-486E-BBDC-1B63A1BEB54B" class="sect3">When Not to Implement Parallel Execution</h3>
               <div>
                  <p>Serial execution is different than parallel execution in that only one process executes a single database operation, such as a SQL query.</p>
                  <p>Serial execution is a better choice than parallel execution when:</p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p>The query references a small data set.</p>
                     </li>
                     <li>
                        <p>There is high concurrency.</p>
                     </li>
                     <li>
                        <p>Efficiency is important.</p>
                     </li>
                  </ul>
                  <p>Parallel execution is not typically useful for:</p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p>Environments in which the typical query or transaction is very short (a few seconds or less). </p>
                        <p>This includes most online transaction systems. Parallel execution is not useful in these environments because there is a cost associated with coordinating the parallel execution servers; for short transactions, the cost of this coordination may outweigh the benefits of parallelism.</p>
                     </li>
                     <li>
                        <p>Environments in which the CPU, memory, or I/O resources are heavily used.</p>
                        <p>Parallel execution is designed to exploit additional available hardware resources; if no such resources are available, then parallel execution does not yield any benefits and indeed may be detrimental to performance.</p>
                     </li>
                  </ul>
               </div>
            </div><a id="VLDBG1380"></a><div class="props_rev_3"><a id="GUID-5BBC87C2-5FDB-4466-BF75-F49681A7B70F" name="GUID-5BBC87C2-5FDB-4466-BF75-F49681A7B70F"></a><h3 id="VLDBG-GUID-5BBC87C2-5FDB-4466-BF75-F49681A7B70F" class="sect3">Fundamental Hardware Requirements</h3>
               <div>
                  <p>Parallel execution is designed to effectively use multiple CPUs and disks to answer queries quickly.</p>
                  <p>It is very I/O intensive by nature. To achieve optimal performance, each component in the hardware configuration must be sized to sustain the same level of throughput: from the CPUs and the Host Bus Adapters (HBAs) in the compute nodes, to the switches, and on into the I/O subsystem, including the storage controllers and the physical disks. If the system is an Oracle Real Application Clusters (Oracle RAC) system, then the interconnection also has to be sized appropriately. The weakest link is going to limit the performance and scalability of operations in a configuration.</p>
                  <p>It is recommended to measure the maximum I/O performance that a hardware configuration can achieve without Oracle Database. You can use this measurement as a baseline for the future system performance evaluations. Remember, it is not possible for parallel execution to achieve better I/O throughput than the underlying hardware can sustain. Oracle Database provides a free calibration tool called Orion, which is designed to measure the I/O performance of a system by simulating Oracle I/O workloads. A parallel execution typically performs large random I/Os.</p>
                  <div class="infoboxnotealso" id="GUID-5BBC87C2-5FDB-4466-BF75-F49681A7B70F__GUID-8C093DEE-07EB-4C5E-A9A5-A97C31D08DEF">
                     <p class="notep1">See Also:</p>
                     <p><a href="../tgdba/IO-configuration-and-design.html#TGDBA015" target="_blank"><span><cite>Oracle Database Performance Tuning Guide</cite></span></a> for information about I/O configuration and design
                     </p>
                  </div>
               </div>
            </div><a id="VLDBG1382"></a><div class="props_rev_3"><a id="GUID-98409B8F-5D16-421C-A30F-B1C08E4CA9E1" name="GUID-98409B8F-5D16-421C-A30F-B1C08E4CA9E1"></a><h3 id="VLDBG-GUID-98409B8F-5D16-421C-A30F-B1C08E4CA9E1" class="sect3">How Parallel Execution Works</h3>
               <div>
                  <p>Parallel execution breaks down a task so that, instead of one process doing all of the work in a query, many processes do part of the work at the same time.</p>
                  <p></p>
                  <p>This section contains the following topics:</p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p><a href="parallel-exec-intro.html#GUID-1DF2B82C-DD29-4500-B0B4-F296F1AC6240" title="Each SQL statement undergoes an optimization and parallelization process when it is parsed.">Parallel Execution of SQL Statements</a></p>
                     </li>
                     <li>
                        <p><a href="parallel-exec-intro.html#GUID-1C6BC851-DE4A-4651-9813-3E70023C8264" title="Parallel execution uses the producer/consumer model.">Producer/Consumer Model</a></p>
                     </li>
                     <li>
                        <p><a href="parallel-exec-intro.html#GUID-D28717E4-0F77-44F5-BB4E-234C31D4E4BA" title="The basic unit of work in parallelism is a called a granule.">Granules of Parallelism</a></p>
                     </li>
                     <li>
                        <p><a href="parallel-exec-intro.html#GUID-ADDF75ED-8CBE-4544-B59E-283A093A3337" title="A distribution method is the method by which data is sent (or redistributed) from one parallel execution (PX) server set to another.">Distribution Methods Between Producers and Consumers</a></p>
                     </li>
                     <li>
                        <p><a href="parallel-exec-intro.html#GUID-F8C73913-21CD-45D8-8417-10DA38C57762" title="To execute a query in parallel, Oracle Database generally creates a set of producer parallel execution servers and a set of consumer parallel execution servers.">How Parallel Execution Servers Communicate</a></p>
                     </li>
                  </ul>
               </div><a id="VLDBG0101"></a><div class="props_rev_3"><a id="GUID-1DF2B82C-DD29-4500-B0B4-F296F1AC6240" name="GUID-1DF2B82C-DD29-4500-B0B4-F296F1AC6240"></a><h4 id="VLDBG-GUID-1DF2B82C-DD29-4500-B0B4-F296F1AC6240" class="sect4">Parallel Execution of SQL Statements</h4>
                  <div>
                     <p>Each SQL statement undergoes an optimization and parallelization process when it is parsed.</p>
                     <p>If the statement is determined to be executed in parallel, then the following steps occur in the execution plan:</p>
                     <ol>
                        <li>
                           <p>The user session or shadow process takes on the role of a coordinator, often called the query coordinator (QC) or the parallel execution (PX) coordinator. The QC is the session that initiates the parallel SQL statement.</p>
                        </li>
                        <li>
                           <p>The PX coordinator obtains the necessary number of processes called parallel execution (PX) servers. The PX servers are the individual processes that perform work in parallel on behalf of the initiating session.</p>
                        </li>
                        <li>
                           <p>The SQL statement is executed as a sequence of operations, such as a full table scan or an <code class="codeph">ORDER BY</code> clause. Each operation is performed in parallel if possible.
                           </p>
                        </li>
                        <li>
                           <p>When the PX servers are finished executing the statement, the PX coordinator performs any portion of the work that cannot be executed in parallel. For example, a parallel query with a <code class="codeph">SUM()</code> operation requires adding the individual subtotals calculated by each PX server.
                           </p>
                        </li>
                        <li>
                           <p>Finally, the PX coordinator returns the results to the user.</p>
                        </li>
                     </ol>
                  </div>
               </div><a id="VLDBG1387"></a><a id="VLDBG1386"></a><div class="props_rev_3"><a id="GUID-1C6BC851-DE4A-4651-9813-3E70023C8264" name="GUID-1C6BC851-DE4A-4651-9813-3E70023C8264"></a><h4 id="VLDBG-GUID-1C6BC851-DE4A-4651-9813-3E70023C8264" class="sect4">Producer/Consumer Model</h4>
                  <div>
                     <p>Parallel execution uses the producer/consumer model. </p>
                     <p>A parallel execution plan is carried out as a series of producer/consumer operations. Parallel execution (PX) servers that produce data for subsequent operations are called producers, PX servers that require the output of other operations are called consumers. Each producer or consumer parallel operation is performed by a set of PX servers called PX server sets. The number of PX servers in PX server set is called Degree of Parallelism (DOP).  The basic unit of work for a PX server set is called a data flow operation (DFO).</p>
                     <p>A PX coordinator can have multiple levels of producer/consumer operations (multiple DFOs), but the number of PX servers sets for a PX coordinator is limited to two. Therefore, at one point in time only two PX server sets can be active for a PX coordinator. As a result, there is parallelism in both the operations in a DFO and between DFOs. The parallelism of an individual DFO is called intra-operation parallelism and the parallelism between DFOs is called inter-operation parallelism. To illustrate intra- and inter-operation parallelism, consider the following statement:</p><pre class="oac_no_warn" dir="ltr">SELECT * FROM employees ORDER BY last_name;
</pre><p>The execution plan implements a full scan of the <code class="codeph">employees</code> table. This operation is followed by a sorting of the retrieved rows, based on the value of the <code class="codeph">last_name</code> column. For the sake of this example, assume the <code class="codeph">last_name</code> column is not indexed. Also assume that the DOP for the query is set to <code class="codeph">4</code>, which means that four parallel execution servers can be active for any given operation.
                     </p>
                     <p><a href="parallel-exec-intro.html#GUID-1C6BC851-DE4A-4651-9813-3E70023C8264__I1010979">Figure 8-1</a> illustrates the parallel execution of the example query.
                     </p>
                     <div class="figure" id="GUID-1C6BC851-DE4A-4651-9813-3E70023C8264__I1010979">
                        <p class="titleinfigure">Figure 8-1 Inter-operation Parallelism and Dynamic Partitioning</p><img src="img/vldbg013.gif" width="600" alt="Description of Figure 8-1 follows" title="Description of Figure 8-1 follows" longdesc="img_text/vldbg013.html"><br><a href="img_text/vldbg013.html">Description of "Figure 8-1 Inter-operation Parallelism and Dynamic Partitioning"</a></div>
                     <!-- class="figure" -->
                     <p>As illustrated in <a href="parallel-exec-intro.html#GUID-1C6BC851-DE4A-4651-9813-3E70023C8264__I1010979">Figure 8-1</a>, there are actually eight PX servers involved in the query even though the DOP is <code class="codeph">4</code>. This is because a producer and consumer operator can be performed at the same time (inter-operation parallelism).
                     </p>
                     <p>Also all of the PX servers involved in the scan operation send rows to the appropriate PX server performing the <code class="codeph">SORT</code> operation. If a row scanned by a PX server contains a value for the <code class="codeph">last_name</code> column between <code class="codeph">A</code> and <code class="codeph">G</code>, that row is sent to the first <code class="codeph">ORDER</code> <code class="codeph">BY</code> parallel execution server. When the scan operation is complete, the sorting processes can return the sorted results to the query coordinator, which returns the complete query results to the user.
                     </p>
                  </div>
               </div><a id="VLDBG0105"></a><div class="props_rev_3"><a id="GUID-D28717E4-0F77-44F5-BB4E-234C31D4E4BA" name="GUID-D28717E4-0F77-44F5-BB4E-234C31D4E4BA"></a><h4 id="VLDBG-GUID-D28717E4-0F77-44F5-BB4E-234C31D4E4BA" class="sect4">Granules of Parallelism</h4>
                  <div>
                     <p>The basic unit of work in parallelism is a called a granule. </p>
                     <p>Oracle Database divides the operation executed in parallel, such as a table scan or index creation, into granules. Parallel execution (PX) servers execute the operation one granule at a time. The number of granules and their sizes correlate with the degree of parallelism (DOP). The number of granules also affect how well the work is balanced across PX servers.</p>
                  </div><a id="VLDBG1399"></a><div class="props_rev_3"><a id="GUID-48C2A3DF-80CB-4607-BBD5-50059E672366" name="GUID-48C2A3DF-80CB-4607-BBD5-50059E672366"></a><h5 id="VLDBG-GUID-48C2A3DF-80CB-4607-BBD5-50059E672366" class="sect5">Block Range Granules</h5>
                     <div>
                        <p>Block range granules are the basic unit of most parallel operations, even on partitioned tables. From an Oracle Database perspective, the degree of parallelism is not related to the number of partitions.</p>
                        <p>Block range granules are ranges of physical blocks from a table. Oracle Database computes the number and the size of the granules during run-time to optimize and balance the work distribution for all affected parallel execution (PX) servers. The number and size of granules are dependent upon the size of the object and the DOP. Block range granules do not depend on static preallocation of tables or indexes. During the computation of the granules, Oracle Database takes the DOP into account and tries to assign granules from different data files to each of the PX servers to avoid contention whenever possible. Additionally, Oracle Database considers the disk affinity of the granules on massive parallel processing (MPP) systems to take advantage of the physical proximity between PX servers and disks.</p>
                     </div>
                  </div><a id="VLDBG1400"></a><div class="props_rev_3"><a id="GUID-C4EF1FEF-B7D1-4CFA-85F2-B1345E936277" name="GUID-C4EF1FEF-B7D1-4CFA-85F2-B1345E936277"></a><h5 id="VLDBG-GUID-C4EF1FEF-B7D1-4CFA-85F2-B1345E936277" class="sect5">Partition Granules</h5>
                     <div>
                        <p>When partition granules are used, a parallel execution (PX) server works on an entire partition or subpartition of a table or index.</p>
                        <p>Because partition granules are statically determined by the structure of the table or index when a table or index is created, partition granules do not give you the flexibility in executing an operation in parallel that block granules do. The maximum allowable degree of parallelism (DOP) is the number of partitions. This might limit the utilization of the system and the load balancing across PX servers. </p>
                        <p>When partition granules are used for parallel access to a table or index, you should use a relatively large number of partitions, ideally three times the DOP, so that Oracle Database can effectively balance work across the PX servers.</p>
                        <p>Partition granules are the basic unit of parallel index range scans, joins between two equipartitioned tables where the query optimizer has chosen to use partition-wise joins, and parallel operations that modify multiple partitions of a partitioned object. These operations include parallel creation of partitioned indexes, and parallel creation of partitioned tables.</p>
                        <p>You can tell which types of granules were used by looking at the execution plan of a statement. The line <code class="codeph">PX</code> <code class="codeph">BLOCK</code> <code class="codeph">ITERATOR</code> above the table or index access indicates that block range granules have been used. In the following example, you can see this on line 7 of the explain plan output just above the <code class="codeph">TABLE</code> <code class="codeph">FULL</code> <code class="codeph">ACCESS</code> on the <code class="codeph">SALES</code> table.
                        </p><pre class="oac_no_warn" dir="ltr">-------------------------------------------------------------------------------------------------
|Id|      Operation          |  Name  |Rows|Bytes|Cost%CPU|  Time  |Pst|Pst|  TQ |INOUT|PQDistri|
-------------------------------------------------------------------------------------------------
| 0|SELECT STATEMENT         |        |  17| 153 |565(100)|00:00:07|   |   |     |     |        |
| 1| PX COORDINATOR          |        |    |     |        |        |   |   |     |     |        |
| 2|  PX SEND QC(RANDOM)     |:TQ10001|  17| 153 |565(100)|00:00:07|   |   |Q1,01|P-&gt;S |QC(RAND)|
| 3|   HASH GROUP BY         |        |  17| 153 |565(100)|00:00:07|   |   |Q1,01|PCWP |        |
| 4|    PX RECEIVE           |        |  17| 153 |565(100)|00:00:07|   |   |Q1,01|PCWP |        |
| 5|     PX SEND HASH        |:TQ10000|  17| 153 |565(100)|00:00:07|   |   |Q1,00|P-&gt;P | HASH   |
| 6|      HASH GROUP BY      |        |  17| 153 |565(100)|00:00:07|   |   |Q1,00|PCWP |        |
| 7|       PX BLOCK ITERATOR |        | 10M| 85M | 60(97) |00:00:01| 1 | 16|Q1,00|PCWC |        |
|*8|        TABLE ACCESS FULL|  SALES | 10M| 85M | 60(97) |00:00:01| 1 | 16|Q1,00|PCWP |        |
-------------------------------------------------------------------------------------------------

Predicate Information (identified by operation id):
---------------------------------------------------
8 - filter("CUST_ID"&lt;=22810 AND "CUST_ID"&gt;=22300)
</pre><p>When partition granules are used, you see the line <code class="codeph">PX</code> <code class="codeph">PARTITION</code> <code class="codeph">RANGE</code> above the table or index access in the explain plan output. On line 6 of the example that follows, the plan has <code class="codeph">PX</code> <code class="codeph">PARTITION</code> <code class="codeph">RANGE</code> <code class="codeph">ALL</code> because this statement accesses all of the 16 partitions in the table. If not all of the partitions are accessed, it simply shows <code class="codeph">PX</code> <code class="codeph">PARTITION</code> <code class="codeph">RANGE</code>.
                        </p><pre class="oac_no_warn" dir="ltr">---------------------------------------------------------------------------------------------------------
|Id|      Operation                    |  Name    |Rows|Byte|Cost%CPU|  Time  |Ps|Ps|  TQ |INOU|PQDistri|
---------------------------------------------------------------------------------------------------------
| 0|SELECT STATEMENT                   |          |  17| 153|   2(50)|00:00:01|  |  |     |    |        |
| 1| PX COORDINATOR                    |          |    |    |        |        |  |  |     |    |        |
| 2|  PX SEND QC(RANDOM)               |:TQ10001  |  17| 153|   2(50)|00:00:01|  |  |Q1,01|P-&gt;S|QC(RAND)|
| 3|   HASH GROUP BY                   |          |  17| 153|   2(50)|00:00:01|  |  |Q1,01|PCWP|        |
| 4|    PX RECEIVE                     |          |  26| 234|    1(0)|00:00:01|  |  |Q1,01|PCWP|        |
| 5|     PX SEND HASH                  |:TQ10000  |  26| 234|    1(0)|00:00:01|  |  |Q1,00|P-&gt;P| HASH   |
| 6|      PX PARTITION RANGE ALL       |          |  26| 234|    1(0)|00:00:01|  |  |Q1,00|PCWP|        |
| 7|       TABLEACCESSLOCAL INDEX ROWID|SALES     |  26| 234|    1(0)|00:00:01| 1|16|Q1,00|PCWC|        |
|*8|        INDEX RANGE SCAN           |SALES_CUST|  26|    |    1(0)|00:00:01| 1|16|Q1,00|PCWP|        |
---------------------------------------------------------------------------------------------------------

Predicate Information (identified by operation id):
---------------------------------------------------
8 - access("CUST_ID"&lt;=22810 AND "CUST_ID"&gt;=22300)</pre></div>
                  </div>
               </div><a id="VLDBG1384"></a><a id="VLDBG14083"></a><a id="VLDBG14084"></a><a id="VLDBG1383"></a><div class="props_rev_3"><a id="GUID-ADDF75ED-8CBE-4544-B59E-283A093A3337" name="GUID-ADDF75ED-8CBE-4544-B59E-283A093A3337"></a><h4 id="VLDBG-GUID-ADDF75ED-8CBE-4544-B59E-283A093A3337" class="sect4">Distribution Methods Between Producers and Consumers</h4>
                  <div>
                     <p>A distribution method is the method by which data is sent (or redistributed) from one parallel execution (PX) server set to another. </p>
                     <div class="p">The following are the most commonly used distribution methods in parallel execution.
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Hash Distribution</p>
                              <p>The hash distribution method uses a hash function on one or more columns in the row which then determines the consumer where the producer should send the row. This distribution attempts to divide the work equally among consumers based on hash values.</p>
                           </li>
                           <li>
                              <p>Broadcast Distribution</p>
                              <p>In the broadcast distribution method, each producer sends all rows to all consumers. This method is used when the result set of the left side in a join operation is small and the cost of broadcasting all rows is not high. The result set from the right side of the join does not need to be distributed in this case; consumer PX servers assigned to the join operation can scan the right side and perform the join.</p>
                           </li>
                           <li>
                              <p>Range Distribution</p>
                              <p>Range distribution is mostly used in parallel sort operations. In this method each producer sends rows that have a range of values to the same consumer. This is the method used in <a href="parallel-exec-intro.html#GUID-1C6BC851-DE4A-4651-9813-3E70023C8264__I1010979">Figure 8-1</a>.
                              </p>
                           </li>
                           <li>
                              <p>Hybrid Hash Distribution</p>
                              <p>Hybrid hash is an adaptive distribution method used in join operations. The actual distribution method is decided at runtime by the optimizer depending on the size of the result set of the left side of the join. The number of rows returned from the left side is counted and checked against a threshold value. When the number of rows is less than or equal to the threshold value, broadcast distribution is used for the left side of the join, and the right side is not distributed as the same consumer PX servers assigned to the join operation scan the right side and perform the join. When the number of rows returned from the left side is higher than the threshold value, hash distribution is used for both sides of the join. </p>
                           </li>
                        </ul>
                     </div>
                     <p>To determine the distribution method, the parallel execution (PX) coordinator examines each operation in a SQL statement's execution plan and then determines the way in which the rows operated on by the operation must be redistributed among the PX servers. As an example of parallel query, consider the query in <a href="parallel-exec-intro.html#GUID-ADDF75ED-8CBE-4544-B59E-283A093A3337__BEIJGGBB">Example 8-1</a>. <a href="parallel-exec-intro.html#GUID-ADDF75ED-8CBE-4544-B59E-283A093A3337__I1010878">Figure 8-2</a> illustrates the data flow or query plan for the query in <a href="parallel-exec-intro.html#GUID-ADDF75ED-8CBE-4544-B59E-283A093A3337__BEIJGGBB">Example 8-1</a>, and <a href="parallel-exec-intro.html#GUID-ADDF75ED-8CBE-4544-B59E-283A093A3337__BEIFFBHE">Example 8-2</a> shows the explain plan output for the same query.
                     </p>
                     <p>The query plan shows that an adaptive distribution methods was picked by the PX coordinator. Assuming the optimizer picks hash distribution at runtime, the execution proceeds as follows: two sets of PX servers, SS1 and SS2, are allocated for the query, each server set has four PX servers because of the <code class="codeph">PARALLEL</code> hint that specifies the DOP of the statement. 
                     </p>
                     <p>PX set SS1 first scans the table <code class="codeph">customers</code> and sends rows to SS2, which builds a hash table on the rows. In other words, the consumers in SS2 and the producers in SS1 work concurrently: one in scanning <code class="codeph">customers</code> in parallel, the other is consuming rows and building the hash table to enable the hash join in parallel. This is an example of inter-operation parallelism.
                     </p>
                     <p>After a PX server process in SS1 scans a row from the customers table, which PX server process in SS2 should it send it to? In this case, the redistribution of rows flowing up from SS1 performing the parallel scan of customers into SS2 performing the parallel hash-join is done by hash distribution on the join column. That is, a PX server process scanning customers computes a hash function on the value of the column customers.cust_id to decide which PX server process in SS2 to send it to. The redistribution method used is explicitly shown in the Distrib column in the <code class="codeph">EXPLAIN</code> <code class="codeph">PLAN</code> of the query. In <a href="parallel-exec-intro.html#GUID-ADDF75ED-8CBE-4544-B59E-283A093A3337__I1010878">Figure 8-2</a>, this can be seen on lines 5, 9, and 14 of the <code class="codeph">EXPLAIN</code> <code class="codeph">PLAN</code>.
                     </p>
                     <p>After SS1 has finished scanning the entire <code class="codeph">customers</code> table, it scans the <code class="codeph">sales</code> table in parallel. It sends its rows to PX servers in SS2, which then perform the probes to finish the hash join in parallel. These PX servers also perform a <code class="codeph">GROUP</code> <code class="codeph">BY</code> operation after the join. After SS1 has scanned the <code class="codeph">sales</code> table in parallel and sent the rows to SS2, it switches to performing the final group by operation in parallel. At this point the PX servers in SS2 send their rows using hash distribution to PX servers on SS1 for the group by operation. This is how two server sets run concurrently to achieve inter-operation parallelism across various operators in the query tree.
                     </p>
                     <div class="figure" id="GUID-ADDF75ED-8CBE-4544-B59E-283A093A3337__I1010878">
                        <p class="titleinfigure">Figure 8-2 Data Flow Diagram for Joining Tables</p><img src="img/vldbg004b.png" width="188" alt="Description of Figure 8-2 follows" title="Description of Figure 8-2 follows" longdesc="img_text/vldbg004b.html"><br><a href="img_text/vldbg004b.html">Description of "Figure 8-2 Data Flow Diagram for Joining Tables"</a></div>
                     <!-- class="figure" -->
                     <div class="example" id="GUID-ADDF75ED-8CBE-4544-B59E-283A093A3337__BEIJGGBB">
                        <p class="titleinexample">Example 8-1 Running an Explain Plan for a Query on Customers and Sales</p><pre class="oac_no_warn" dir="ltr">EXPLAIN PLAN FOR
SELECT /*+ PARALLEL(4) */ customers.cust_first_name, customers.cust_last_name, 
  MAX(QUANTITY_SOLD), AVG(QUANTITY_SOLD)
  FROM sales, customers
  WHERE sales.cust_id=customers.cust_id
  GROUP BY customers.cust_first_name, customers.cust_last_name;

Explained.
</pre></div>
                     <!-- class="example" -->
                     <div class="example" id="GUID-ADDF75ED-8CBE-4544-B59E-283A093A3337__BEIFFBHE">
                        <p class="titleinexample">Example 8-2 Explain Plan Output for a Query on Customers and Sales</p><pre class="oac_no_warn" dir="ltr">PLAN_TABLE_OUTPUT
---------------------------------------------------------------------------------------------------------------------------------------
Plan hash value: 3260900439
---------------------------------------------------------------------------------------------------------------------------------------
|Id  |Operation                      |Name     |Rows  | Bytes |TempSpc|Cost (%CPU)| Time     |Pstart|Pstop |   TQ  |IN-OUT|PQ Distrib |
---------------------------------------------------------------------------------------------------------------------------------------
|  0 |SELECT STATEMENT               |         |  960 | 26880 |       |    6  (34)| 00:00:01 |      |      |       |      |           |
|  1 | PX COORDINATOR                |         |      |       |       |           |          |      |      |       |      |           |
|  2 |  PX SEND QC (RANDOM)          |:TQ10003 |  960 | 26880 |       |    6  (34)| 00:00:01 |      |      | Q1,03 | P-&gt;S |QC (RAND)  |
|  3 |   HASH GROUP BY               |         |  960 | 26880 | 50000 |    6  (34)| 00:00:01 |      |      | Q1,03 | PCWP |           |
|  4 |    PX RECEIVE                 |         |  960 | 26880 |       |    6  (34)| 00:00:01 |      |      | Q1,03 | PCWP |           |
|  5 |     PX SEND HASH              |:TQ10002 |  960 | 26880 |       |    6  (34)| 00:00:01 |      |      | Q1,02 | P-&gt;P |HASH       |
|  6 |      HASH GROUP BY            |         |  960 | 26880 | 50000 |    6  (34)| 00:00:01 |      |      | Q1,02 | PCWP |           |
|* 7 |       HASH JOIN               |         |  960 | 26880 |       |    5  (20)| 00:00:01 |      |      | Q1,02 | PCWP |           |
|  8 |        PX RECEIVE             |         |  630 | 12600 |       |    2   (0)| 00:00:01 |      |      | Q1,02 | PCWP |           |
|  9 |         PX SEND HYBRID HASH   |:TQ10000 |  630 | 12600 |       |    2   (0)| 00:00:01 |      |      | Q1,00 | P-&gt;P |HYBRID HASH|
| 10 |          STATISTICS COLLECTOR |         |      |       |       |           |          |      |      | Q1,00 | PCWC |           |
| 11 |           PX BLOCK ITERATOR   |         |  630 | 12600 |       |    2   (0)| 00:00:01 |      |      | Q1,00 | PCWC |           |
| 12 |            TABLE ACCESS FULL  |CUSTOMERS|  630 | 12600 |       |    2   (0)| 00:00:01 |      |      | Q1,00 | PCWP |           |
| 13 |        PX RECEIVE             |         |  960 |  7680 |       |    2   (0)| 00:00:01 |      |      | Q1,02 | PCWP |           |
| 14 |         PX SEND HYBRID HASH   |:TQ10001 |  960 |  7680 |       |    2   (0)| 00:00:01 |      |      | Q1,01 | P-&gt;P |HYBRID HASH|
| 15 |          PX BLOCK ITERATOR    |         |  960 |  7680 |       |    2   (0)| 00:00:01 |    1 |   16 | Q1,01 | PCWC |           |
| 16 |           TABLE ACCESS FULL   |SALES    |  960 |  7680 |       |    2   (0)| 00:00:01 |    1 |   16 | Q1,01 | PCWP |           |
---------------------------------------------------------------------------------------------------------------------------------------
Predicate Information (identified by operation id):
---------------------------------------------------
7 - access("SALES"."CUST_ID"="CUSTOMERS"."CUST_ID")
Note
-----
   - Degree of Parallelism is 4 because of hint
</pre></div>
                     <!-- class="example" -->
                  </div>
               </div><a id="VLDBG1389"></a><a id="VLDBG1388"></a><div class="props_rev_3"><a id="GUID-F8C73913-21CD-45D8-8417-10DA38C57762" name="GUID-F8C73913-21CD-45D8-8417-10DA38C57762"></a><h4 id="VLDBG-GUID-F8C73913-21CD-45D8-8417-10DA38C57762" class="sect4">How Parallel Execution Servers Communicate</h4>
                  <div>
                     <p>To execute a query in parallel, Oracle Database generally creates a set of producer parallel execution servers and a set of consumer parallel execution servers. </p>
                     <p>The producer server retrieves rows from tables and the consumer server performs operations such as join, sort, DML, and DDL on these rows. Each server in the producer set has a connection to each server in the consumer set. The number of virtual connections between parallel execution servers increases as the square of the degree of parallelism.</p>
                     <p>Each communication channel has at least one, and sometimes up to four memory buffers, which are allocated from the shared pool. Multiple memory buffers facilitate asynchronous communication among the parallel execution servers.</p>
                     <p>A single-instance environment uses at most three buffers for each communication channel. An Oracle Real Application Clusters environment uses at most four buffers for each channel. <a href="parallel-exec-intro.html#GUID-F8C73913-21CD-45D8-8417-10DA38C57762__BABECFHI">Figure 8-3</a> illustrates message buffers and how producer parallel execution servers connect to consumer parallel execution servers.
                     </p>
                     <div class="figure" id="GUID-F8C73913-21CD-45D8-8417-10DA38C57762__BABECFHI">
                        <p class="titleinfigure">Figure 8-3 Parallel Execution Server Connections and Buffers</p><img src="img/vldbg015.gif" width="504" alt="Description of Figure 8-3 follows" title="Description of Figure 8-3 follows" longdesc="img_text/vldbg015.html"><br><a href="img_text/vldbg015.html">Description of "Figure 8-3 Parallel Execution Server Connections and Buffers"</a></div>
                     <!-- class="figure" -->
                     <p>When a connection is between two processes on the same instance, the servers communicate by passing the buffers back and forth in memory (in the shared pool). When the connection is between processes in different instances, the messages are sent using external high-speed network protocols over the interconnect. In <a href="parallel-exec-intro.html#GUID-F8C73913-21CD-45D8-8417-10DA38C57762__BABECFHI">Figure 8-3</a>, the DOP equals the number of parallel execution servers, which in this case is n. <a href="parallel-exec-intro.html#GUID-F8C73913-21CD-45D8-8417-10DA38C57762__BABECFHI">Figure 8-3</a> does not show the parallel execution coordinator. Each parallel execution server actually has an additional connection to the parallel execution coordinator. It is important to size the shared pool adequately when using parallel execution. If there is not enough free space in the shared pool to allocate the necessary memory buffers for a parallel server, it fails to start.
                     </p>
                  </div>
               </div>
            </div><a id="VLDBG0104"></a><div class="props_rev_3"><a id="GUID-8FC8977A-68A4-4E4D-9FE9-CFDF0DA45C08" name="GUID-8FC8977A-68A4-4E4D-9FE9-CFDF0DA45C08"></a><h3 id="VLDBG-GUID-8FC8977A-68A4-4E4D-9FE9-CFDF0DA45C08" class="sect3">Parallel Execution Server Pool</h3>
               <div>
                  <p>When an instance starts, Oracle Database creates a pool of parallel execution servers, which are available for any parallel operation. </p>
                  <p>The initialization parameter <code class="codeph">PARALLEL_MIN_SERVERS</code> specifies the number of parallel execution servers that Oracle Database creates at instance startup.
                  </p>
                  <p>When executing a parallel operation, the parallel execution coordinator obtains parallel execution servers from the pool and assigns them to the operation. If necessary, Oracle Database can create additional parallel execution servers for the operation. These parallel execution servers remain with the operation throughout execution. After the statement has been processed, the parallel execution servers return to the pool.</p>
                  <p>If the number of parallel operations increases, Oracle Database creates additional parallel execution servers to handle incoming requests. However, Oracle Database never creates more parallel execution servers for an instance than the value specified by the initialization parameter <code class="codeph">PARALLEL_MAX_SERVERS</code>.
                  </p>
                  <p>If the number of parallel operations decreases, Oracle Database terminates any parallel execution servers that have been idle for a threshold interval. Oracle Database does not reduce the size of the pool less than the value of <code class="codeph">PARALLEL_MIN_SERVERS</code>, no matter how long the parallel execution servers have been idle.
                  </p>
               </div><a id="VLDBG1398"></a><div class="props_rev_3"><a id="GUID-CF5F8609-5ECF-4A92-89A3-FBCB242BB3BF" name="GUID-CF5F8609-5ECF-4A92-89A3-FBCB242BB3BF"></a><h4 id="VLDBG-GUID-CF5F8609-5ECF-4A92-89A3-FBCB242BB3BF" class="sect4">Processing without Enough Parallel Execution Servers</h4>
                  <div>
                     <p>Oracle Database can process a parallel operation with fewer than the requested number of processes. </p>
                     <p>If all parallel execution servers in the pool are occupied and the maximum number of parallel execution servers has been started, the parallel execution coordinator switches to serial processing.</p>
                     <p></p>
                     <div class="infoboxnotealso" id="GUID-CF5F8609-5ECF-4A92-89A3-FBCB242BB3BF__GUID-743006E8-21E2-46BC-8245-03A8D1D04F26">
                        <p class="notep1">See Also:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><a href="parameters-parallel-exec.html#GUID-8632FD0C-AB90-4F1F-81B3-58D24C3AAD74" title="The discussion about tuning general parameters for parallel execution is introduced in the topic.">Tuning General Parameters for Parallel Execution</a> for information about the <code class="codeph">PARALLEL_MIN_PERCENT</code> and <code class="codeph">PARALLEL_MAX_SERVERS</code> initialization parameters
                              </p>
                           </li>
                           <li>
                              <p><a href="../refrn/PARALLEL_MIN_PERCENT.html#REFRN10159" target="_blank"><span><cite>Oracle Database Reference</cite></span></a> for information about using the initialization parameter <code class="codeph">PARALLEL_MIN_PERCENT</code> 
                              </p>
                           </li>
                        </ul>
                     </div>
                  </div>
               </div>
            </div><a id="VLDBG1401"></a><div class="props_rev_3"><a id="GUID-EFF3E2A2-5C18-43BE-9646-B9F8B00919F7" name="GUID-EFF3E2A2-5C18-43BE-9646-B9F8B00919F7"></a><h3 id="VLDBG-GUID-EFF3E2A2-5C18-43BE-9646-B9F8B00919F7" class="sect3">Balancing the Workload to Optimize Performance</h3>
               <div>
                  <p>To optimize performance, all parallel execution servers should have equal workloads. </p>
                  <p>For SQL statements run in parallel by block range or by parallel execution servers, the workload is dynamically divided among the parallel execution servers. This minimizes workload skewing, which occurs when some parallel execution servers perform significantly more work than the other processes.</p>
                  <p>For the relatively few SQL statements executed in parallel by partitions, if the workload is evenly distributed among the partitions, you can optimize performance by matching the number of parallel execution servers to the number of partitions or by choosing a DOP in which the number of partitions is a multiple of the number of processes. This applies to partition-wise joins and parallel DML on tables created before Oracle9<span class="italic">i</span>. Refer to <a href="parallel-exec-tips.html#GUID-FEE610A3-F12C-47F6-9571-ADBB08096B06" title="There are certain limitations on the degree of parallelism based on the software level of Oracle Database in use.">Limitation on the Degree of Parallelism</a> for more information.
                  </p>
                  <p>For example, suppose a table has 16 partitions, and a parallel operation divides the work evenly among them. You can use 16 parallel execution servers (DOP equals 16) to do the work in approximately one-tenth the time that one process would take. You might also use five processes to do the work in one-fifth the time, or two processes to do the work in one-half the time.</p>
                  <p>If, however, you use 15 processes to work on 16 partitions, the first process to finish its work on one partition then begins work on the 16th partition; and as the other processes finish their work, they become idle. This configuration does not provide good performance when the work is evenly divided among partitions. When the work is unevenly divided, the performance varies depending on whether the partition that is left for last has more or less work than the other partitions.</p>
                  <p>Similarly, suppose you use six processes to work on 16 partitions and the work is evenly divided. In this case, each process works on a second partition after finishing its first partition, but only four of the processes work on a third partition while the other two remain idle.</p>
                  <p>In general, you cannot assume that the time taken to perform a parallel operation on a given number of partitions (N) with a given number of parallel execution servers (P) equals N divided by P. This formula does not consider the possibility that some processes might have to wait while others finish working on the last partitions. By choosing an appropriate DOP, however, you can minimize the workload skew and optimize performance.</p>
               </div>
            </div>
            <div class="sect2"><a id="GUID-6BD448A7-E3AE-4171-BC01-70C823AFCE6C" name="GUID-6BD448A7-E3AE-4171-BC01-70C823AFCE6C"></a><h3 id="VLDBG-GUID-6BD448A7-E3AE-4171-BC01-70C823AFCE6C" class="sect3">Multiple Parallelizers</h3>
               <div>
                  <p>Each parallel execution (PX) coordinator in an execution plan is called a parallelizer. </p>
                  <p>The number of PX servers used by a SQL statement is determined by the statement degree of parallelism (DOP) and the number of parallelizers. Because the number of PX server sets for a parallelizer is limited to two, the number of PX servers for most statements is DOP*2. Some statements can have more than one parallelizer. Because each parallelizer can use two PX server sets, the number of PX servers for these statements can be more than DOP*2. You can identify these statements by looking at the <code class="codeph">EXPLAIN</code> <code class="codeph">PLAN</code>. If the plan has multiple PX coordinators it means the statement has multiple parallelizers.
                  </p>
                  <p>A few example cases where SQL statements use multiple parallelizers are subquery factoring, grouping sets, star queries, in-memory aggregation, and noncorrelated subqueries.</p>
                  <p>Multiple parallelizers in a SQL statement can be active concurrently or one after the other depending on the execution plan.</p>
                  <p>A statement with a single parallelizer allocates the required number of PX servers at the start of execution and holds these allocated PX servers without releasing until the statement completes. This ensures that the number of PX servers throughout the execution is constant. Statements with multiple parallelizers are different as they allocate PX servers when each parallelizer starts. Because parallelizers can start at different times during the execution, each parallelizer may be running with a different number of PX servers based on the number of available processes in the system.</p>
                  <p>If multiple parallelizers are executed concurrently the statement can use more PX servers than DOP*2.</p>
                  <p>The view <code class="codeph">V$PQ_SESSTAT</code> shows the number of parallelizers in the <code class="codeph">STATISTIC</code> column. The data flow operation statistic,<code class="codeph">DFO Trees</code> , shows the number of parallelizers. The <code class="codeph">Server Threads</code> statistic shows the maximum number of PX servers used concurrently for a SQL statement.
                  </p>
                  <div class="infoboxnotealso" id="GUID-6BD448A7-E3AE-4171-BC01-70C823AFCE6C__ORACLEDATABASEREFERENCEFORINFORMATI-D37017EB">
                     <p class="notep1">See Also:</p>
                     <p><a href="../refrn/dynamic-performance-views.html#REFRN003" target="_blank"><span><cite>Oracle Database Reference</cite></span></a> for information about <code class="codeph">V$PQ_SESSTAT</code> and other dynamic views
                     </p>
                  </div>
               </div>
            </div><a id="VLDBG0106"></a><div class="props_rev_3"><a id="GUID-0266F26D-7342-49CB-9613-228687108924" name="GUID-0266F26D-7342-49CB-9613-228687108924"></a><h3 id="VLDBG-GUID-0266F26D-7342-49CB-9613-228687108924" class="sect3">Parallel Execution on Oracle RAC</h3>
               <div>
                  <p>By default in an Oracle RAC environment, a SQL statement executed in parallel can run across all the nodes in the cluster. </p>
                  <div class="section">
                     <p>For this cross-node or inter-node parallel execution to perform, the interconnect in the Oracle RAC environment must be sized appropriately because inter-node parallel execution may result in heavy interconnect traffic. Inter-node parallel execution does not scale with an undersized interconnect.</p>
                  </div>
                  <!-- class="section" -->
                  <div class="section">
                     <p class="subhead2" id="GUID-0266F26D-7342-49CB-9613-228687108924__GUID-4ED15CC5-6C2A-4314-9472-C34776E4794A">Limiting the Number of Available Instances</p>
                     <p>In an Oracle RAC environment, you can use services to limit the number of instances that participate in the execution of a parallel SQL statement. The default service includes all available instances. You can create any number of services, each consisting of one or more instances. When a user connects to the database using a service, only PX servers on the instances that are members of the service can participate in the execution of a parallel statement.</p>
                     <p>To limit parallel execution to a single node, you can set the <code class="codeph">PARALLEL_FORCE_LOCAL</code> initialization parameter to <code class="codeph">TRUE</code>. In this case, only PX servers on the instance that a session connects to is used to execute parallel statements from that session. Note that when this parameter is set to <code class="codeph">TRUE</code>, all parallel statements running on that instance are executed locally, whether the session connects to the instance directly or connects using a service.
                     </p>
                  </div>
                  <!-- class="section" -->
                  <div class="section">
                     <p class="subhead2" id="GUID-0266F26D-7342-49CB-9613-228687108924__GUID-6B0BD926-6F81-40C4-8F89-94327F5CB85E">Parallel Execution on Flex Clusters</p>
                     <p>Parallel statements executed on flex clusters can use both hub and leaf nodes. As user sessions are only allowed to connect to the hub nodes, the coordinator process (Query Coordinator or PX Coordinator) resides on hub nodes and can use PX server processes from any node in the cluster. For parallel queries any PX server on any node can participate in the execution of the statement. For parallel DML operations only PX servers on hub nodes can participate in the execution of the DML part of the statement as only hub nodes are allowed to perform DML operations.</p>
                     <p>When there is data distribution from the leaf nodes to the hub nodes for DML operations, the execution plan indicates this distribution. In the following example, data is distributed to hub nodes in line <code class="codeph">Id 5</code>, indicating the load operation in line <code class="codeph">Id 3</code> is executed only on hub nodes.
                     </p><pre class="oac_no_warn" dir="ltr">--------------------------------------------------------
| Id  | Operation                          | Name      |
--------------------------------------------------------
|   0 | CREATE TABLE STATEMENT             |           |
|   1 |  PX COORDINATOR                    |           |
|   2 |   PX SEND QC (RANDOM)              | :TQ10001  |
|   3 |    LOAD AS SELECT (HYBRID TSM/HWMB)| SALESTEMP |
|   4 |     PX RECEIVE                     |           |
|   5 |      PX SEND ROUND-ROBIN (HUB)     | :TQ10000  |
|   6 |       PX BLOCK ITERATOR            |           |
|   7 |        TABLE ACCESS FULL           | SALES     |
--------------------------------------------------------</pre></div>
                  <!-- class="section" -->
                  <div class="section">
                     <div class="infoboxnotealso" id="GUID-0266F26D-7342-49CB-9613-228687108924__ORACLEREALAPPLICATIONCLUSTERSADMINI-3A62A12B">
                        <p class="notep1">See Also:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><a href="../cwadd/oracle-flex-clusters.html#CWADD92560" target="_blank"><span><cite>Oracle Clusterware Administration and Deployment Guide</cite></span></a> for information about nodes in hub, leaf, and flex cluster architecture
                              </p>
                           </li>
                           <li>
                              <p> <a href="../cwlin/installing-oracle-grid-infrastructure.html#CWLIN-GUID-D4E3FADF-360E-49EB-89A2-E4CBBB9CC61F" target="_blank"><span><cite>Oracle Grid Infrastructure Installation and Upgrade Guide for Linux</cite></span></a> for information about cluster installation options for Grid Infrastructure
                              </p>
                           </li>
                           <li>
                              <p><a href="../racad/administering-database-instances-and-cluster-databases.html#RACAD900" target="_blank"><span><cite>Oracle Real Application Clusters Administration and Deployment Guide</cite></span></a> for more information about instance groups
                              </p>
                           </li>
                        </ul>
                     </div>
                  </div>
                  <!-- class="section" -->
               </div>
            </div>
         </div>
      </article>
   </body>
</html>