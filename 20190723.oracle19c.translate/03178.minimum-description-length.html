<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xml:lang="en-us" lang="en-us">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <meta name="abstract" content="Learn how to use Minimum Description Length, the supervised technique for calculating Attribute Importance.">
      <meta name="description" content="Learn how to use Minimum Description Length, the supervised technique for calculating Attribute Importance.">
      <title>Minimum Description Length</title>
      <meta property="og:site_name" content="Oracle Help Center">
      <meta property="og:title" content="Concepts">
      <meta property="og:description" content="Learn how to use Minimum Description Length, the supervised technique for calculating Attribute Importance.">
      <link rel="stylesheet" href="/sp_common/book-template/ohc-book-template/css/book.css">
      <link rel="shortcut icon" href="/sp_common/book-template/ohc-common/img/favicon.ico">
      <meta name="application-name" content="Concepts">
      <meta name="generator" content="DITA Open Toolkit version 1.8.5 (Mode = doc)">
      <meta name="plugin" content="SP_docbuilder HTML plugin release 18.2.2">
      <link rel="alternate" href="data-mining-concepts.pdf" title="PDF File" type="application/pdf">
      <meta name="robots" content="all">
      <link rel="schema.dcterms" href="http://purl.org/dc/terms/">
      <meta name="dcterms.created" content="2019-01-10T04:37:09-08:00">
      
      <meta name="dcterms.dateCopyrighted" content="2005, 2019">
      <meta name="dcterms.category" content="database">
      <meta name="dcterms.identifier" content="E97867-01">
      
      <meta name="dcterms.product" content="en/database/oracle/oracle-database/19">
      
      <link rel="prev" href="k-means.html" title="Previous" type="text/html">
      <link rel="next" href="naive-bayes.html" title="Next" type="text/html">
      <script>
        document.write('<style type="text/css">');
        document.write('body > .noscript, body > .noscript ~ * { visibility: hidden; }');
        document.write('</style>');
     </script>
      <script data-main="/sp_common/book-template/ohc-book-template/js/book-config" src="/sp_common/book-template/requirejs/require.js"></script>
      <script>
            if (window.require === undefined) {
                document.write('<script data-main="sp_common/book-template/ohc-book-template/js/book-config" src="sp_common/book-template/requirejs/require.js"><\/script>');
                document.write('<link href="sp_common/book-template/ohc-book-template/css/book.css" rel="stylesheet"/>');
            }
        </script>
      <script type="application/json" id="ssot-metadata">{"primary":{"category":{"short_name":"database","element_name":"Database","display_in_url":true},"suite":{"short_name":"oracle","element_name":"Oracle","display_in_url":true},"product_group":{"short_name":"not-applicable","element_name":"Not applicable","display_in_url":false},"product":{"short_name":"oracle-database","element_name":"Oracle Database","display_in_url":true},"release":{"short_name":"19","element_name":"Release 19","display_in_url":true}}}</script>
      
    <meta name="dcterms.title" content="Data Mining Concepts">
    <meta name="dcterms.isVersionOf" content="DMCON">
    <meta name="dcterms.release" content="Release 19">
  </head>
   <body>
      <div class="noscript alert alert-danger text-center" role="alert">
         <a href="k-means.html" class="pull-left"><span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span>Previous</a>
         <a href="naive-bayes.html" class="pull-right">Next<span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span></a>
         <span class="fa fa-exclamation-triangle" aria-hidden="true"></span> JavaScript must be enabled to correctly display this content
        
      </div>
      <article>
         <header>
            <ol class="breadcrumb" vocab="http://schema.org/" typeof="BreadcrumbList">
               <li property="itemListElement" typeof="ListItem"><a href="index.html" property="item" typeof="WebPage"><span property="name">Concepts</span></a></li>
               <li property="itemListElement" typeof="ListItem"><a href="algorithms.html" property="item" typeof="WebPage"><span property="name"> Algorithms</span></a></li>
               <li class="active" property="itemListElement" typeof="ListItem"> Minimum Description Length</li>
            </ol>
            <a id="GUID-96A38D67-2F09-4659-976D-4DDF478555E0" name="GUID-96A38D67-2F09-4659-976D-4DDF478555E0"></a><a id="DMCON340"></a>
            
            <h2 id="DMCON-GUID-96A38D67-2F09-4659-976D-4DDF478555E0" class="sect2"><span class="enumeration_chapter">19 </span> Minimum Description Length
            </h2>
         </header>
         <div class="ind">
            <div>
               <p>Learn how to use Minimum Description Length, the supervised technique for calculating Attribute Importance.</p>
               <p><a id="d22211e19" class="indexterm-anchor"></a><a id="d22211e21" class="indexterm-anchor"></a></p>
               <ul style="list-style-type: disc;">
                  <li>
                     <p><a href="minimum-description-length.html#GUID-71E4E7B8-D213-4B84-8A32-9634EA6392EF" title="Introduces Minimum Description Length (MDL) algorithm.">About MDL</a></p>
                  </li>
                  <li>
                     <p><a href="minimum-description-length.html#GUID-10380313-0C6B-4744-B0DD-74ED1176CC8C" title="Learn about preparing data for Minimum Description Length (MDL).">Data Preparation for MDL</a></p>
                  </li>
               </ul>
            </div>
            <div>
               <div class="relinfo">
                  <p><strong>Related Topics</strong></p>
                  <ul>
                     <li><a href="feature-selection-extraction.html#GUID-FE2DFE18-670E-4E1A-83A8-5C67CA4D8564">About Feature Selection and Attribute Importance</a></li>
                  </ul>
               </div>
            </div><a id="DMCON341"></a><div class="props_rev_3"><a id="GUID-71E4E7B8-D213-4B84-8A32-9634EA6392EF" name="GUID-71E4E7B8-D213-4B84-8A32-9634EA6392EF"></a><h3 id="DMCON-GUID-71E4E7B8-D213-4B84-8A32-9634EA6392EF" class="sect3"><span class="enumeration_section">19.1 </span>About MDL
               </h3>
               <div>
                  <p>Introduces Minimum Description Length (MDL) algorithm.</p>
                  <p>MDL<a id="d22211e67" class="indexterm-anchor"></a><a id="d22211e69" class="indexterm-anchor"></a><a id="d22211e73" class="indexterm-anchor"></a> is an information theoretic model selection principle. It is an important concept in information theory (the study of the quantification of information) and in learning theory (the study of the capacity for generalization based on empirical data).
                  </p>
                  <p>MDL assumes that the simplest, most compact representation of the data is the best and most probable explanation of the data. The MDL principle is used to build Oracle Data Mining attribute importance models.</p>
                  <p>The build process for attribute importance supports <a id="d22211e82" class="indexterm-anchor"></a>parallel execution.
                  </p>
               </div>
               <div>
                  <div class="relinfo">
                     <p><strong>Related Topics</strong></p>
                     <ul>
                        <li><a href="../vldbg/using-parallel.html#VLDBG010" target="_blank"><span><cite>Oracle Database VLDB and Partitioning Guide</cite></span></a></li>
                     </ul>
                  </div>
               </div><a id="DMCON563"></a><div class="props_rev_3"><a id="GUID-3696659A-6FBD-4FDE-A771-81D4D67405B4" name="GUID-3696659A-6FBD-4FDE-A771-81D4D67405B4"></a><h4 id="DMCON-GUID-3696659A-6FBD-4FDE-A771-81D4D67405B4" class="sect4"><span class="enumeration_section">19.1.1 </span>Compression and Entropy
                  </h4>
                  <div>
                     <p><strong class="term">Data compression</strong> is the process of encoding information using fewer <strong class="term">bits</strong> than what the original representation uses. The MDL Principle is based on the notion that the shortest description of the data is the most probable. In typical instantiations of this principle, a model is used to compress the data by reducing the uncertainty (entropy) as discussed below. The description of the data includes a description of the model and the data as described by the model. 
                     </p>
                     <p><strong class="term">Entropy</strong> is a measure of uncertainty. It quantifies the uncertainty in a random variable as the information required to specify its value. <strong class="term">Information</strong> in this sense is defined as the number of yes/no questions known as <strong class="term">bits</strong> (encoded as 0 or 1) that must be answered for a complete specification. Thus, the information depends upon the number of values that variable can assume. 
                     </p>
                     <p>For example, if the variable represents the sex of an individual, then the number of possible values is two: female and male. If the variable represents the salary of individuals expressed in whole dollar amounts, then the values can be in the range $0-$10B, or billions of unique values. Clearly it takes more information to specify an exact salary than to specify an individual's sex.</p>
                  </div><a id="DMCON586"></a><div class="props_rev_3"><a id="GUID-49039FE0-83BB-4FF4-9C44-FE8B0932189F" name="GUID-49039FE0-83BB-4FF4-9C44-FE8B0932189F"></a><h5 id="DMCON-GUID-49039FE0-83BB-4FF4-9C44-FE8B0932189F" class="sect5"><span class="enumeration_section">19.1.1.1 </span>Values of a Random Variable: Statistical Distribution 
                     </h5>
                     <div>
                        <p>Information (the number of bits) depends on the statistical distribution of the values of the variable as well as the number of values of the variable. If we are judicious in the choice of Yes/No questions, then the amount of information for salary specification cannot be as much as it first appears. Most people do not have billion dollar salaries. If most people have salaries in the range $32000-$64000, then most of the time, it requires only 15 questions to discover their salary, rather than the 30 required, if every salary from $0-$1000000000 were equally likely. In the former example, if the persons were known to be pregnant, then their sex is known to be female. There is no uncertainty, no Yes/No questions need be asked. The entropy is 0. </p>
                     </div>
                  </div><a id="DMCON587"></a><div class="props_rev_3"><a id="GUID-DF66A57B-000B-44AC-892A-033401004CCB" name="GUID-DF66A57B-000B-44AC-892A-033401004CCB"></a><h5 id="DMCON-GUID-DF66A57B-000B-44AC-892A-033401004CCB" class="sect5"><span class="enumeration_section">19.1.1.2 </span>Values of a Random Variable: Significant Predictors
                     </h5>
                     <div>
                        <p>Suppose that for some random variable there is a predictor that when its values are known reduces the uncertainty of the random variable. For example, knowing whether a person is pregnant or not, reduces the uncertainty of the random variable sex-of-individual. This predictor seems like a valuable feature to include in a model. How about name? Imagine that if you knew the name of the person, you would also know the person's sex. If so, the name predictor would seemingly reduce the uncertainty to zero. However, if names are unique, then what was gained? Is the person named Sally? Is the person named George?... We would have as many Yes/No predictors in the name model as there are people. Therefore, specifying the name model would require as many bits as specifying the sex of each person.</p>
                     </div>
                  </div><a id="DMCON588"></a><div class="props_rev_3"><a id="GUID-CC92EFF3-D388-478A-BB98-D4CF2B308A10" name="GUID-CC92EFF3-D388-478A-BB98-D4CF2B308A10"></a><h5 id="DMCON-GUID-CC92EFF3-D388-478A-BB98-D4CF2B308A10" class="sect5"><span class="enumeration_section">19.1.1.3 </span>Total Entropy
                     </h5>
                     <div>
                        <p>For a random variable, X, the <strong class="term">total entropy</strong> is defined as minus the Probability(X) multiplied by the log to the base 2 of the Probability(X). This can be shown to be the variable's most efficient encoding. 
                        </p>
                     </div>
                  </div>
               </div><a id="DMCON589"></a><div class="props_rev_3"><a id="GUID-267E5C51-6801-4CAF-91BD-BF4FB0A14517" name="GUID-267E5C51-6801-4CAF-91BD-BF4FB0A14517"></a><h4 id="DMCON-GUID-267E5C51-6801-4CAF-91BD-BF4FB0A14517" class="sect4"><span class="enumeration_section">19.1.2 </span>Model Size
                  </h4>
                  <div>
                     <p>Minimum Description Length (MDL) takes into consideration the size of the model as well as the reduction in uncertainty due to using the model. Both model size and entropy are measured in bits. For our purposes, both numeric and categorical predictors are binned. Thus the size of each single predictor model is the number of predictor bins. The uncertainty is reduced to the within-bin target distribution.</p>
                  </div>
               </div><a id="DMCON564"></a><div class="props_rev_3"><a id="GUID-58603837-D1C4-402C-87A5-1260BB1C233C" name="GUID-58603837-D1C4-402C-87A5-1260BB1C233C"></a><h4 id="DMCON-GUID-58603837-D1C4-402C-87A5-1260BB1C233C" class="sect4"><span class="enumeration_section">19.1.3 </span>Model Selection
                  </h4>
                  <div>
                     <p>Minimum Description Length (MDL) considers each attribute as a simple predictive model of the target class. <strong class="term">Model selection</strong> refers to the process of comparing and ranking the single-predictor models. 
                     </p>
                     <p>MDL uses a communication model for solving the model selection problem. In the communication model there is a sender, a receiver, and data to be transmitted.</p>
                     <p>These single predictor models are compared and ranked with respect to the MDL metric, which is the relative compression in bits. MDL penalizes model complexity to avoid over-fit. It is a principled approach that takes into account the complexity of the predictors (as models) to make the comparisons fair. </p>
                  </div>
               </div><a id="DMCON565"></a><div class="props_rev_3"><a id="GUID-DE44EEEF-52F8-4D40-916D-A7B9E6783A4F" name="GUID-DE44EEEF-52F8-4D40-916D-A7B9E6783A4F"></a><h4 id="DMCON-GUID-DE44EEEF-52F8-4D40-916D-A7B9E6783A4F" class="sect4"><span class="enumeration_section">19.1.4 </span>The MDL Metric
                  </h4>
                  <div>
                     <p>Attribute importance uses a two-part code as the metric for transmitting each unit of data. The first part (preamble) transmits the model. The parameters of the model are the target probabilities associated with each value of the prediction. </p>
                     <p>For a target with <span class="italic">j</span> values and a predictor with <span class="italic">k</span> values, <span class="italic">n</span><sub>i</sub> (<span class="italic">i</span>= 1,..., k) rows per value, there are C<sub>i</sub>, the combination of <span class="italic">j</span>-1 things taken <span class="italic">n</span><sub>i</sub>-1 at a time possible conditional probabilities. The size of the preamble in bits can be shown to be Sum(log<sub>2</sub>(C<sub>i</sub>)), where the sum is taken over <span class="italic">k</span>. Computations like this represent the penalties associated with each single prediction model. The second part of the code transmits the target values using the model.
                     </p>
                     <p>It is well known that the most compact encoding of a sequence is the encoding that best matches the probability of the symbols (target class values). Thus, the model that assigns the highest probability to the sequence has the smallest target class value transmission cost. In bits, this is the Sum(log<sub>2</sub>(p<sub>i</sub>)), where the p<sub>i</sub> are the predicted probabilities for row <sub>i</sub> associated with the model.
                     </p>
                     <p>The predictor rank is the position in the list of associated description lengths, smallest first.</p>
                  </div>
               </div>
            </div><a id="DMCON342"></a><div class="props_rev_3"><a id="GUID-10380313-0C6B-4744-B0DD-74ED1176CC8C" name="GUID-10380313-0C6B-4744-B0DD-74ED1176CC8C"></a><h3 id="DMCON-GUID-10380313-0C6B-4744-B0DD-74ED1176CC8C" class="sect3"><span class="enumeration_section">19.2 </span>Data Preparation for MDL
               </h3>
               <div>
                  <p>Learn about preparing data for Minimum Description Length (MDL).</p>
                  <p><a id="d22211e344" class="indexterm-anchor"></a>Automatic Data Preparation performs supervised <a id="d22211e349" class="indexterm-anchor"></a>binning for MDL. Supervised binning uses decision trees to create the optimal bin boundaries. Both categorical and numerical attributes are binned.
                  </p>
                  <p>MDL handles missing values naturally as missing at random. The algorithm replaces sparse numerical data with zeros and sparse categorical data with zero vectors. Missing values in nested columns are interpreted as sparse. Missing values in columns with simple data types are interpreted as missing at random.</p>
                  <p>If you choose to manage your own data preparation, keep in mind that MDL usually benefits from binning. However, the discriminating power of an attribute importance model can be significantly reduced when there are outliers in the data and external <a id="d22211e358" class="indexterm-anchor"></a>equal-width binning is used. This technique can cause most of the data to concentrate in a few bins (a single bin in extreme cases). In this case, quantile binning is a better solution.
                  </p>
               </div>
               <div>
                  <div class="relinfo">
                     <p><strong>Related Topics</strong></p>
                     <ul>
                        <li><a href="../dmprg/preparing-data.html#DMPRG-GUID-E1AB599C-1921-4BD7-B06B-FC466180A460" target="_blank">Preparing the Data</a></li>
                        <li><a href="../dmprg/transforming-data.html#DMPRG-GUID-C3FDDEC7-8CC9-4AC1-A6C3-75D91E26B703" target="_blank">Transforming the Data</a></li>
                     </ul>
                  </div>
               </div>
            </div>
         </div>
      </article>
   </body>
</html>