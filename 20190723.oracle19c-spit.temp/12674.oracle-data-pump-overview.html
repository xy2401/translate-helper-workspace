<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xml:lang="en-us" lang="en-us">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <meta name="abstract" content="Oracle Data Pump technology enables very high-speed movement of data and metadata from one database to another.">
      <meta name="description" content="Oracle Data Pump technology enables very high-speed movement of data and metadata from one database to another.">
      <title>Overview of Oracle Data Pump</title>
      <meta property="og:site_name" content="Oracle Help Center">
      <meta property="og:title" content="Utilities ">
      <meta property="og:description" content="Oracle Data Pump technology enables very high-speed movement of data and metadata from one database to another.">
      <link rel="stylesheet" href="/sp_common/book-template/ohc-book-template/css/book.css">
      <link rel="shortcut icon" href="/sp_common/book-template/ohc-common/img/favicon.ico">
      <meta name="application-name" content="Utilities">
      <meta name="generator" content="DITA Open Toolkit version 1.8.5 (Mode = doc)">
      <meta name="plugin" content="SP_docbuilder HTML plugin release 18.2.2">
      <link rel="alternate" href="database-utilities.pdf" title="PDF File" type="application/pdf">
      <meta name="robots" content="all">
      <link rel="schema.dcterms" href="http://purl.org/dc/terms/">
      <meta name="dcterms.created" content="2019-04-23T19:07:17-07:00">
      
      <meta name="dcterms.dateCopyrighted" content="2002, 2019">
      <meta name="dcterms.category" content="database">
      <meta name="dcterms.identifier" content="E96081-02">
      
      <meta name="dcterms.product" content="en/database/oracle/oracle-database/19">
      
      <link rel="prev" href="oracle-data-pump.html" title="Previous" type="text/html">
      <link rel="next" href="oracle-data-pump-export-utility.html" title="Next" type="text/html">
      <script>
        document.write('<style type="text/css">');
        document.write('body > .noscript, body > .noscript ~ * { visibility: hidden; }');
        document.write('</style>');
     </script>
      <script data-main="/sp_common/book-template/ohc-book-template/js/book-config" src="/sp_common/book-template/requirejs/require.js"></script>
      <script>
            if (window.require === undefined) {
                document.write('<script data-main="sp_common/book-template/ohc-book-template/js/book-config" src="sp_common/book-template/requirejs/require.js"><\/script>');
                document.write('<link href="sp_common/book-template/ohc-book-template/css/book.css" rel="stylesheet"/>');
            }
        </script>
      <script type="application/json" id="ssot-metadata">{"primary":{"category":{"short_name":"database","element_name":"Database","display_in_url":true},"suite":{"short_name":"oracle","element_name":"Oracle","display_in_url":true},"product_group":{"short_name":"not-applicable","element_name":"Not applicable","display_in_url":false},"product":{"short_name":"oracle-database","element_name":"Oracle Database","display_in_url":true},"release":{"short_name":"19","element_name":"Release 19","display_in_url":true}}}</script>
      
    <meta name="dcterms.title" content="Database Utilities">
    <meta name="dcterms.isVersionOf" content="SUTIL">
    <meta name="dcterms.release" content="Release 19">
  </head>
   <body>
      <div class="noscript alert alert-danger text-center" role="alert">
         <a href="oracle-data-pump.html" class="pull-left"><span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span>Previous</a>
         <a href="oracle-data-pump-export-utility.html" class="pull-right">Next<span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span></a>
         <span class="fa fa-exclamation-triangle" aria-hidden="true"></span> JavaScript must be enabled to correctly display this content
        
      </div>
      <article>
         <header>
            <ol class="breadcrumb" vocab="http://schema.org/" typeof="BreadcrumbList">
               <li property="itemListElement" typeof="ListItem"><a href="index.html" property="item" typeof="WebPage"><span property="name">Utilities </span></a></li>
               <li property="itemListElement" typeof="ListItem"><a href="oracle-data-pump.html" property="item" typeof="WebPage"><span property="name"> Oracle Data Pump</span></a></li>
               <li class="active" property="itemListElement" typeof="ListItem"> Overview of Oracle Data Pump</li>
            </ol>
            <a id="GUID-17FAE261-0972-4220-A2E4-44D479F519D4" name="GUID-17FAE261-0972-4220-A2E4-44D479F519D4"></a><a id="SUTIL100"></a>
            
            <h2 id="SUTIL-GUID-17FAE261-0972-4220-A2E4-44D479F519D4" class="sect2"><span class="enumeration_chapter">1 </span> Overview of Oracle Data Pump
            </h2>
         </header>
         <div class="ind">
            <div>
               <p>Oracle Data Pump technology enables very high-speed movement of data and metadata from one database to another.</p>
               <p>An understanding of the following topics can help you to successfully use Oracle Data Pump to its fullest advantage:</p>
            </div>
            <div>
               <ul class="ullinks">
                  <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-47B26B0B-3C95-4182-ACDF-2EEDD577FC9E">Oracle Data Pump Components</a><br>Oracle Data Pump is made up of three distinct components: Command-line clients, <code class="codeph">expdp</code> and <code class="codeph">impdp</code>; the <code class="codeph">DBMS_DATAPUMP</code> PL/SQL package (also known as the Data Pump API); and the <code class="codeph">DBMS_METADATA</code> PL/SQL package (also known as the Metadata API).
                  </li>
                  <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-3F418F02-5FE2-455A-B5AD-C1910DB3B5E0">How Does Data Pump Move Data?</a><br>There are several Oracle Data Pump methods that you can use to move data in and out of databases. You can select the method that best fits your use case.
                  </li>
                  <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-45B17B65-20F2-4128-9A39-B1B0F5E323BB">Using Oracle Data Pump With CDBs</a><br>Oracle Data Pump can migrate all, or portions of, a database from a non-CDB into a PDB, between PDBs within the same or different CDBs, and from a PDB into a non-CDB.
                  </li>
                  <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-8B6975D3-3BEC-4584-B416-280125EEC57E">Required Roles for Data Pump Export and Import Operations</a><br>Many Data Pump Export and Import operations require the user to have the <code class="codeph">DATAPUMP_EXP_FULL_DATABASE</code> role, or the <code class="codeph">DATAPUMP_IMP_FULL_DATABASE</code> role, or both.
                  </li>
                  <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-6BDC1CC8-8596-402D-B016-602985B97AB6">What Happens During Execution of an Oracle Data Pump Job?</a><br>Oracle Data Pump jobs use a master table, a master process, and worker processes to perform the work and keep track of progress.
                  </li>
                  <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-E365D74E-12CD-495C-BA23-5A55F679C7E7">Monitoring Job Status</a><br>The Oracle Data Pump Export and Import client utilities can attach to a job in either logging mode or interactive-command mode.
                  </li>
                  <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-A4C5E6C1-28DE-45AF-B90C-B7FEEFF62069">Monitoring the Progress of Executing Jobs</a><br>To monitor table data transfers, you can use the <code class="codeph">V$SESSION_LONGOPS</code> dynamic performance view to monitor Oracle Data Pump jobs.
                  </li>
                  <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-FE7E746D-A343-463E-A4E2-A6AD1349FE4B">File Allocation</a><br>Oracle Data Pump manages several different types of files. You can use commands in interactive mode to modify how OracleData Pump allocates and handles these files.
                  </li>
                  <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-BAA3B679-A758-4D55-9820-432D9EB83C68">Exporting and Importing Between Different Oracle Database Releases</a><br>You can use Oracle Data Pump to migrate all or any portion of an Oracle Database between different releases of the database software.
                  </li>
                  <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-9030BC32-193B-4455-8DBB-4271DD44FA7A">SecureFiles LOB Considerations</a><br>When you use Oracle Data Pump Export to export SecureFiles LOBs, the export behavior depends on several things, including the Export <code class="codeph">VERSION</code> parameter value, whether ContentType is present, and whether the LOB is archived and data is cached.
                  </li>
                  <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-34D0DEE7-3530-42DC-BE01-C2588CC73CE5">Oracle Data Pump Exit Codes</a><br>You can review Oracle Data Pump export and import operation results in a log file, and in a process exit code.
                  </li>
                  <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-4443B80B-0446-4010-B8CA-2524659516BC">Auditing Data Pump Jobs</a><br>To monitor and record specific user database actions, perform auditing on Data Pump jobs with unified auditing.
                  </li>
                  <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-7EE60BAB-0D3D-46EB-8E11-4FDDA68EF14E">How Does Data Pump Handle Timestamp Data?</a><br>This section describes factors that can affect successful completion of export and import jobs that involve the timestamp data types <code class="codeph">TIMESTAMP WITH TIMEZONE</code> and <code class="codeph">TIMESTAMP WITH LOCAL TIMEZONE</code>.
                  </li>
                  <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-72F01BF0-61F5-4775-8C7B-4E227F244866">Character Set and Globalization Support Considerations</a><br>Globalization support behavior of Data Pump Export and Import.
                  </li>
                  <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-B1A6BBA2-0269-48CC-8A0E-8E3955A231C0">Oracle Data Pump Behavior with Data-Bound Collation</a><br>Oracle Data Pump supports data-bound collation (DBC).
                  </li>
               </ul>
               <div class="familylinks">
                  <div class="parentlink">
                     <p><strong>Parent topic:</strong> <a href="oracle-data-pump.html#GUID-501A9908-BCC5-434C-8853-9A6096766B5A">Oracle Data Pump</a></p>
                  </div>
               </div>
            </div>
            <a id="SUTIL801"></a><div class="props_rev_3"><a id="GUID-47B26B0B-3C95-4182-ACDF-2EEDD577FC9E" name="GUID-47B26B0B-3C95-4182-ACDF-2EEDD577FC9E"></a><h3 id="SUTIL-GUID-47B26B0B-3C95-4182-ACDF-2EEDD577FC9E" class="sect3"><span class="enumeration_section">1.1 </span>Oracle Data Pump Components
               </h3>
               <div>
                  <p>Oracle Data Pump is made up of three distinct components: Command-line clients, <code class="codeph">expdp</code> and <code class="codeph">impdp</code>; the <code class="codeph">DBMS_DATAPUMP</code> PL/SQL package (also known as the Data Pump API); and the <code class="codeph">DBMS_METADATA</code> PL/SQL package (also known as the Metadata API).
                  </p>
                  <p>The Oracle Data Pump clients, <code class="codeph">expdp</code> and <code class="codeph">impdp</code>, start the Oracle Data Pump Export utility and Oracle Data Pump Import utility, respectively.
                  </p>
                  <p>The <code class="codeph">expdp</code> and <code class="codeph">impdp</code> clients use the procedures provided in the <code class="codeph">DBMS_DATAPUMP</code> PL/SQL package to execute export and import commands, using the parameters entered at the command line. These parameters enable the exporting and importing of data and metadata for a complete database or for subsets of a database.
                  </p>
                  <p>When metadata is moved, Data Pump uses functionality provided by the <code class="codeph">DBMS_METADATA</code> PL/SQL package. The <code class="codeph">DBMS_METADATA</code> package provides a centralized facility for the extraction, manipulation, and re-creation of dictionary metadata.
                  </p>
                  <p>The <code class="codeph">DBMS_DATAPUMP</code> and <code class="codeph">DBMS_METADATA</code> PL/SQL packages can be used independently of the Data Pump clients.
                  </p>
                  <div class="infoboxnote" id="GUID-47B26B0B-3C95-4182-ACDF-2EEDD577FC9E__GUID-F0F71B60-F143-4EE4-B5BF-40FD1CD1A594">
                     <p class="notep1">Note:</p>
                     <p>All Oracle Data Pump Export and Import processing, including the reading and writing of dump files, is done on the system (server) selected by the specified database connect string. <span class="bold">This means that for unprivileged users, the database administrator (DBA) must create directory objects for the Data Pump files that are read and written on that server file system.</span> (For security reasons, DBAs must ensure that only approved users are allowed access to directory objects.) For privileged users, a default directory object is available. 
                     </p>
                  </div>
                  <p>Starting with Oracle Database 18c, you can include the unified audit trail in either full or partial export and import operations using Oracle Data Pump. There is no change to the user interface. When you perform the export or import operations of a database, the unified audit trail is automatically included in the Oracle Data Pump dump files. See <cite>Oracle Database PL/SQL Packages and Types Reference</cite> for a description of the <code class="codeph">DBMS_DATAPUMP</code> and the <code class="codeph">DBMS_METADATA</code> packages. See <cite>Oracle Database Security Guide</cite> for information about exporting and importing the unified audit trail using Oracle Data Pump.
                  </p>
               </div>
               <div>
                  <div class="relinfo">
                     <p><strong>Related Topics</strong></p>
                     <ul>
                        <li><a href="oracle-data-pump-overview.html#GUID-EEB32B50-8A00-40B0-8787-CC2C8BA05DC5" title="Data Pump is server-based rather than client-based. Dump files, log files, and SQL files are accessed relative to server-based directory paths.">Understanding Dump, Log, and SQL File Default Locations</a></li>
                        <li><a href="../arpls/DBMS_DATAPUMP.html#ARPLS356" target="_blank"><span><cite>Oracle Database PL/SQL Packages and Types Reference</cite></span></a></li>
                        <li><a href="../dbseg/administering-the-audit-trail.html#DBSEG-GUID-8140CCBF-77EE-4F86-A055-B9F9AB8B4573" target="_blank"><span><cite>Oracle Database Security Guide</cite></span></a></li>
                     </ul>
                  </div>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-17FAE261-0972-4220-A2E4-44D479F519D4" title="Oracle Data Pump technology enables very high-speed movement of data and metadata from one database to another.">Overview of Oracle Data Pump</a></p>
                     </div>
                  </div>
               </div>
            </div><a id="SUTIL802"></a><div class="props_rev_3"><a id="GUID-3F418F02-5FE2-455A-B5AD-C1910DB3B5E0" name="GUID-3F418F02-5FE2-455A-B5AD-C1910DB3B5E0"></a><h3 id="SUTIL-GUID-3F418F02-5FE2-455A-B5AD-C1910DB3B5E0" class="sect3"><span class="enumeration_section">1.2 </span>How Does Data Pump Move Data?
               </h3>
               <div>
                  <p>There are several Oracle Data Pump methods that you can use to move data in and out of databases. You can select the method that best fits your use case.</p>
                  <div class="infoboxnote" id="GUID-3F418F02-5FE2-455A-B5AD-C1910DB3B5E0__GUID-B77A4D96-BC67-431E-9C68-09DF5865A7C4">
                     <p class="notep1">Note:</p>
                     <p>Data Pump does not load tables with disabled unique indexes. To load data into the table, the indexes must be either dropped or reenabled.</p>
                  </div>
               </div>
               <div>
                  <ul class="ullinks">
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-06B2DF71-2A66-498F-B659-1EF5859B1648">Using Data File Copying to Move Data</a><br>The fastest method of moving data is to copy the database data files to the target database without interpreting or altering the data. With this method, Data Pump Export is used to unload only structural information (metadata) into the dump file.
                     </li>
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-F5790243-15A3-4932-9258-1A466985964D">Using Direct Path to Move Data</a><br>After data file copying, direct path is the fastest method of moving data. In this method, the SQL layer of the database is bypassed and rows are moved to and from the dump file with only minimal interpretation.
                     </li>
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-EDB0DFE2-A20A-4FF6-B584-1D31583054AB">Using External Tables to Move Data</a><br>If you do not select data file copying, and the data cannot be moved using direct path, you can use the external tables mechanism.
                     </li>
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-C746E643-C199-4746-AD16-13334734778F">Using Conventional Path to Move Data</a><br>Where there are conflicting table attributes, Oracle Data Pump uses conventional path to move data.
                     </li>
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-3E1D4B46-E856-4ABE-ACC5-977A898BB0F1">Using Network Link Import to Move Data</a><br>When the Import <code class="codeph">NETWORK_LINK</code> parameter is used to specify a network link for an import operation, the direct path method is used by default. Review supported database link types.
                     </li>
                  </ul>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-17FAE261-0972-4220-A2E4-44D479F519D4" title="Oracle Data Pump technology enables very high-speed movement of data and metadata from one database to another.">Overview of Oracle Data Pump</a></p>
                     </div>
                  </div>
               </div>
               <a id="SUTIL803"></a><div class="props_rev_3"><a id="GUID-06B2DF71-2A66-498F-B659-1EF5859B1648" name="GUID-06B2DF71-2A66-498F-B659-1EF5859B1648"></a><h4 id="SUTIL-GUID-06B2DF71-2A66-498F-B659-1EF5859B1648" class="sect4"><span class="enumeration_section">1.2.1 </span>Using Data File Copying to Move Data
                  </h4>
                  <div>
                     <p>The fastest method of moving data is to copy the database data files to the target database without interpreting or altering the data. With this method, Data Pump Export is used to unload only structural information (metadata) into the dump file.</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>The <code class="codeph">TRANSPORT_TABLESPACES</code> parameter is used to specify a transportable tablespace export. Only metadata for the specified tablespaces is exported.
                           </p>
                        </li>
                        <li>
                           <p>The <code class="codeph">TRANSPORTABLE=ALWAYS</code> parameter is supplied on a table mode export (specified with the <code class="codeph">TABLES</code> parameter) or a full mode export (specified with the <code class="codeph">FULL</code> parameter) or a full mode network import (specified with the <code class="codeph">FULL</code> and <code class="codeph">NETWORK_LINK</code> parameters). 
                           </p>
                        </li>
                     </ul>
                     <p>When an export operation uses data file copying, the corresponding import job always also uses data file copying. During the ensuing import operation, both the data files and the export dump file must be loaded. </p>
                     <div class="infoboxnote" id="GUID-06B2DF71-2A66-498F-B659-1EF5859B1648__GUID-79DBB18B-5A11-4880-85B9-AA9894400F69">
                        <p class="notep1">Note:</p>
                        <p>During transportable imports tablespaces are temporarily made read/write and then set back to read-only.The temporary setting change was introduced with Oracle Database 12<span class="italic">c</span> Release 1 (12.1.0.2) to improve performance. However, be aware that this behavior also causes the SCNs of the import job data files to change. Changing the SCNs for data files can cause issues during future transportable imports of those files.
                        </p>
                        <p>For example, if a transportable tablespace import fails at any point after the tablespaces have been made read/write (even if they are now read-only again), then the data files become corrupt. <span class="italic">They cannot be recovered.</span></p>
                        <p>Because transportable jobs are not restartable, you must restart the failed job from the beginning. You must delete the corrupt datafiles, and copy fresh versions to the target destination.</p>
                        <p>When transportable jobs are performed, it is best practice to keep a copy of the data files on the source system until the import job has successfully completed on the target system. If the import job fails for some reason, then keeping copies ensures that you can have uncorrupted copies of the data files.</p>
                     </div>
                     <p>When data is moved by using data file copying, there are some limitations regarding character set compatibility between the source and target databases.</p>
                     <p>If the source platform and the target platform are of different endianness, then you must convert the data being transported so that it is in the format of the target platform. You can use the <code class="codeph">DBMS_FILE_TRANSFER</code> PL/SQL package or the <code class="codeph">RMAN</code> <code class="codeph">CONVERT</code> command to convert the data.
                     </p>
                  </div>
                  <div>
                     <div class="infoboxnotealso" id="GUID-06B2DF71-2A66-498F-B659-1EF5859B1648__GUID-55F4DEF3-2F9E-4FB5-B565-39500D43E464">
                        <p class="notep1">See Also:</p>
                        <p></p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><a href="../rcmrf/CONVERT.html#RCMRF192" target="_blank"><span><cite>Oracle Database Backup and Recovery Reference</cite></span></a> for information about the RMAN <code class="codeph">CONVERT</code> command
                              </p>
                           </li>
                           <li>
                              <p><a href="https://www.oracle.com/pls/topic/lookup?ctx=en/database/oracle/oracle-database/19/sutil&amp;id=ADMIN10140" target="_blank"><span><cite>Oracle Database Administrator’s Guide</cite></span></a> for a description and example (including how to convert the data) of transporting tablespaces between databases
                              </p>
                           </li>
                        </ul>
                     </div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-3F418F02-5FE2-455A-B5AD-C1910DB3B5E0" title="There are several Oracle Data Pump methods that you can use to move data in and out of databases. You can select the method that best fits your use case.">How Does Data Pump Move Data?</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="SUTIL2878"></a><a id="SUTIL2879"></a><a id="SUTIL804"></a><div class="props_rev_3"><a id="GUID-F5790243-15A3-4932-9258-1A466985964D" name="GUID-F5790243-15A3-4932-9258-1A466985964D"></a><h4 id="SUTIL-GUID-F5790243-15A3-4932-9258-1A466985964D" class="sect4"><span class="enumeration_section">1.2.2 </span>Using Direct Path to Move Data
                  </h4>
                  <div>
                     <p>After data file copying, direct path is the fastest method of moving data. In this method, the SQL layer of the database is bypassed and rows are moved to and from the dump file with only minimal interpretation.</p>
                     <p>Data Pump automatically uses the direct path method for loading and unloading data unless the structure of a table does not allow it. For example, if a table contains a column of type <code class="codeph">BFILE</code>, then direct path cannot be used to load that table and external tables is used instead.
                     </p>
                     <p>The following sections describe situations in which direct path cannot be used for loading and unloading.</p>
                     <div class="section" id="GUID-F5790243-15A3-4932-9258-1A466985964D__CJAJJJBH">
                        <p class="subhead3" id="GUID-F5790243-15A3-4932-9258-1A466985964D__GUID-828E0A7A-B1DE-4F6B-8074-9B3DEE67D4B7">Situations in Which Direct Path Load Is Not Used</p>
                        <p>If any of the following conditions exist for a table, then Data Pump uses external tables to load the data for that table, instead of direct path:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>A domain index that is not a <code class="codeph">CONTEXT</code> type index exists for a LOB column.
                              </p>
                           </li>
                           <li>
                              <p>A global index on multipartition tables exists during a single-partition load. This case includes object tables that are partitioned.</p>
                           </li>
                           <li>
                              <p>A table is in a cluster.</p>
                           </li>
                           <li>
                              <p>There is an active trigger on a preexisting table.</p>
                           </li>
                           <li>
                              <p>Fine-grained access control is enabled in insert mode on a preexisting table.</p>
                           </li>
                           <li>
                              <p>A table contains <code class="codeph">BFILE</code> columns or columns of opaque types.
                              </p>
                           </li>
                           <li>
                              <p>A referential integrity constraint is present on a preexisting table.</p>
                           </li>
                           <li>
                              <p>A table contains <code class="codeph">VARRAY</code> columns with an embedded opaque type.
                              </p>
                           </li>
                           <li>
                              <p>The table has encrypted columns.</p>
                           </li>
                           <li>
                              <p>The table into which data is being imported is a preexisting table and at least one of the following conditions exists:</p>
                              <ul style="list-style-type: disc;">
                                 <li>
                                    <p>There is an active trigger</p>
                                 </li>
                                 <li>
                                    <p>The table is partitioned</p>
                                 </li>
                                 <li>
                                    <p>Fine-grained access control is in insert mode</p>
                                 </li>
                                 <li>
                                    <p>A referential integrity constraint exists</p>
                                 </li>
                                 <li>
                                    <p>A unique index exists</p>
                                 </li>
                              </ul>
                           </li>
                           <li>
                              <p>Supplemental logging is enabled, and the table has at least one LOB column.</p>
                           </li>
                           <li>
                              <p>The Data Pump command for the specified table used the <code class="codeph">QUERY</code>, <code class="codeph">SAMPLE</code>, or <code class="codeph">REMAP_DATA</code> parameter. 
                              </p>
                           </li>
                           <li>
                              <p>A table contains a column (including a <code class="codeph">VARRAY</code> column) with a <code class="codeph">TIMESTAMP WITH TIME ZONE</code> data type, and the version of the time zone data file is different between the export and import systems. 
                              </p>
                           </li>
                        </ul>
                     </div>
                     <!-- class="section" -->
                     <div class="section" id="GUID-F5790243-15A3-4932-9258-1A466985964D__CJAEGFIF">
                        <p class="subhead3" id="GUID-F5790243-15A3-4932-9258-1A466985964D__GUID-5936D5A5-9682-49E5-AD0F-76447AB4F3CC">Situations in Which Direct Path Unload Is Not Used</p>
                        <p>If any of the following conditions exist for a table, then Data Pump uses external tables rather than direct path to unload the data:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Fine-grained access control for <code class="codeph">SELECT</code> is enabled.
                              </p>
                           </li>
                           <li>
                              <p>The table is a queue table.</p>
                           </li>
                           <li>
                              <p>The table contains one or more columns of type <code class="codeph">BFILE</code> or opaque, or an object type containing opaque columns.
                              </p>
                           </li>
                           <li>
                              <p>The table contains encrypted columns.</p>
                           </li>
                           <li>
                              <p>The table contains a column of an evolved type that needs upgrading.</p>
                           </li>
                           <li>
                              <p>The Data Pump command for the specified table used the <code class="codeph">QUERY</code>, <code class="codeph">SAMPLE</code>, or <code class="codeph">REMAP_DATA</code> parameter.
                              </p>
                           </li>
                           <li>
                              <p>Before the unload operation, the table was altered to contain a column that is NOT NULL, and also has a default value specified.</p>
                           </li>
                        </ul>
                     </div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-3F418F02-5FE2-455A-B5AD-C1910DB3B5E0" title="There are several Oracle Data Pump methods that you can use to move data in and out of databases. You can select the method that best fits your use case.">How Does Data Pump Move Data?</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="SUTIL805"></a><div class="props_rev_3"><a id="GUID-EDB0DFE2-A20A-4FF6-B584-1D31583054AB" name="GUID-EDB0DFE2-A20A-4FF6-B584-1D31583054AB"></a><h4 id="SUTIL-GUID-EDB0DFE2-A20A-4FF6-B584-1D31583054AB" class="sect4"><span class="enumeration_section">1.2.3 </span>Using External Tables to Move Data
                  </h4>
                  <div>
                     <p>If you do not select data file copying, and the data cannot be moved using direct path, you can use the external tables mechanism.</p>
                     <p>The external tables mechanism creates an external table that maps to the dump file data for the database table. The SQL engine is then used to move the data. If possible, use the <code class="codeph">APPEND</code> hint on import to speed the copying of the data into the database. The representation of data for direct path data and external table data is the same in a dump file. Because they are the same, Oracle Data Pump can use the direct path mechanism at export time, but use external tables when the data is imported into the target database. Similarly, Oracle Data Pump can use external tables for the export, but use direct path for the import.
                     </p>
                     <p>In particular, Oracle Data Pump can use external tables in the following situations:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Loading and unloading very large tables and partitions in situations where it is advantageous to use parallel SQL capabilities</p>
                        </li>
                        <li>
                           <p>Loading tables with global or domain indexes defined on them, including partitioned object tables</p>
                        </li>
                        <li>
                           <p>Loading tables with active triggers or clustered tables</p>
                        </li>
                        <li>
                           <p>Loading and unloading tables with encrypted columns</p>
                        </li>
                        <li>
                           <p>Loading tables with fine-grained access control enabled for inserts</p>
                        </li>
                        <li>
                           <p>Loading a table not created by the import operation (the table exists before the import starts)</p>
                        </li>
                     </ul>
                     <div class="infoboxnote" id="GUID-EDB0DFE2-A20A-4FF6-B584-1D31583054AB__GUID-A53E13CA-BB76-4558-8618-B6CC3A49F7A0">
                        <p class="notep1">Note:</p>
                        <p>When Oracle Data Pump uses external tables as the data access mechanism, it uses the <code class="codeph">ORACLE_DATAPUMP</code> access driver. However, be aware that the files that Data Pump creates when it uses external tables are not compatible with files created when you manually create an external table using the SQL <code class="codeph">CREATE TABLE ... ORGANIZATION EXTERNAL</code> statement.
                        </p>
                     </div>
                  </div>
                  <div>
                     <div class="relinfo">
                        <p><strong>Related Topics</strong></p>
                        <ul>
                           <li><a href="oracle_datapump-access-driver.html#GUID-084DC623-9656-499C-885B-D8180C07704B" title="The ORACLE_DATAPUMP access driver provides a set of access parameters that are unique to external tables of the type ORACLE_DATAPUMP.">The ORACLE_DATAPUMP Access Driver</a></li>
                        </ul>
                     </div>
                     <div class="infoboxnotealso" id="GUID-EDB0DFE2-A20A-4FF6-B584-1D31583054AB__GUID-55AC5DAD-8AF7-4DC7-9AB9-60B967F73049">
                        <p class="notep1">See Also:</p>
                        <p><a href="https://www.oracle.com/pls/topic/lookup?ctx=en/database/oracle/oracle-database/19/sutil&amp;id=SQLRF50901" target="_blank"><span><cite>Oracle Database SQL Language Reference</cite></span></a> for information about using the <code class="codeph">APPEND</code> hint
                        </p>
                     </div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-3F418F02-5FE2-455A-B5AD-C1910DB3B5E0" title="There are several Oracle Data Pump methods that you can use to move data in and out of databases. You can select the method that best fits your use case.">How Does Data Pump Move Data?</a></p>
                        </div>
                     </div>
                  </div>
               </div><a id="SUTIL2880"></a><div class="props_rev_3"><a id="GUID-C746E643-C199-4746-AD16-13334734778F" name="GUID-C746E643-C199-4746-AD16-13334734778F"></a><h4 id="SUTIL-GUID-C746E643-C199-4746-AD16-13334734778F" class="sect4"><span class="enumeration_section">1.2.4 </span>Using Conventional Path to Move Data
                  </h4>
                  <div>
                     <p>Where there are conflicting table attributes, Oracle Data Pump uses conventional path to move data.</p>
                     <p>In situations where there are conflicting table attributes, Oracle Data Pump is not able to load data into a table using either direct path or external tables. In such cases, conventional path is used, which can affect performance.</p>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-3F418F02-5FE2-455A-B5AD-C1910DB3B5E0" title="There are several Oracle Data Pump methods that you can use to move data in and out of databases. You can select the method that best fits your use case.">How Does Data Pump Move Data?</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="SUTIL2881"></a><a id="SUTIL2882"></a><a id="SUTIL806"></a><div class="props_rev_3"><a id="GUID-3E1D4B46-E856-4ABE-ACC5-977A898BB0F1" name="GUID-3E1D4B46-E856-4ABE-ACC5-977A898BB0F1"></a><h4 id="SUTIL-GUID-3E1D4B46-E856-4ABE-ACC5-977A898BB0F1" class="sect4"><span class="enumeration_section">1.2.5 </span>Using Network Link Import to Move Data
                  </h4>
                  <div>
                     <p>When the Import <code class="codeph">NETWORK_LINK</code> parameter is used to specify a network link for an import operation, the direct path method is used by default. Review supported database link types.
                     </p>
                     <p>If direct path cannot be used (for example, because one of the columns is a <code class="codeph">BFILE</code>), then SQL is used to move the data using an <code class="codeph">INSERT SELECT</code> statement. (Before Oracle Database 12<span class="italic">c</span> Release 2 (12.2.0.1), the default was to use the <code class="codeph">INSERT SELECT</code> statement.) The <code class="codeph">SELECT</code> clause retrieves the data from the remote database over the network link. The <code class="codeph">INSERT</code> clause uses SQL to insert the data into the target database. There are no dump files involved.
                     </p>
                     <p>When the Export <code class="codeph">NETWORK_LINK</code> parameter is used to specify a network link for an export operation, the data from the remote database is written to dump files on the target database. (Note that to export from a read-only database, the <code class="codeph">NETWORK_LINK</code> parameter is required.)
                     </p>
                     <p>Because the link can identify a remotely networked database, the terms database link and network link are used interchangeably.</p>
                     <div class="section">
                        <p class="subhead3" id="GUID-3E1D4B46-E856-4ABE-ACC5-977A898BB0F1__GUID-EB393636-DC5C-492B-879E-7FD63D84292F">Supported Link Types</p>
                        <p>The following types of database links are supported for use with Data Pump Export and Import:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Public fixed user</p>
                           </li>
                           <li>
                              <p>Public connected user</p>
                           </li>
                           <li>
                              <p>Public shared user (only when used by link owner)</p>
                           </li>
                           <li>
                              <p>Private shared user (only when used by link owner)</p>
                           </li>
                           <li>
                              <p>Private fixed user (only when used by link owner)</p>
                           </li>
                        </ul>
                     </div>
                     <!-- class="section" -->
                     <div class="section">
                        <p class="subhead3" id="GUID-3E1D4B46-E856-4ABE-ACC5-977A898BB0F1__GUID-8181A476-E862-44D4-8DEE-EE496E7C411E">Unsupported Link Types</p>
                        <p>The following types of database links are not supported for use with Data Pump Export and Import:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Private connected user</p>
                           </li>
                           <li>
                              <p>Current user</p>
                           </li>
                        </ul>
                     </div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="infoboxnotealso" id="GUID-3E1D4B46-E856-4ABE-ACC5-977A898BB0F1__GUID-143DC5B2-FD38-4980-BC29-6CE34E65D953">
                        <p class="notep1">See Also:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>The Export <a href="oracle-data-pump-export-utility.html#GUID-23E58D59-A477-4A87-BD0E-C82447581D0A" title="The Data Pump Export command-line utility NETWORK_LINK parameter enables an export from a (source) database identified by a valid database link. The data from the source database instance is written to a dump file set on the connected database instance.">NETWORK_LINK</a> parameter for information about performing exports over a database link
                              </p>
                           </li>
                           <li>
                              <p>The Import <a href="datapump-import-utility.html#GUID-0871E56B-07EB-43B3-91DA-D1F457CF6182" title="The Data Pump Import command-line mode NETWORK_LINK parameter enables an import from a (source) database identified by a valid database link/">NETWORK_LINK</a> parameter for information about performing imports over a database link
                              </p>
                           </li>
                           <li>
                              <p><a href="../admin/managing-a-distributed-database.html#ADMIN12150" target="_blank"><span><cite>Oracle Database Administrator’s Guide</cite></span></a> for information about creating database links and the different types of links
                              </p>
                           </li>
                        </ul>
                     </div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-3F418F02-5FE2-455A-B5AD-C1910DB3B5E0" title="There are several Oracle Data Pump methods that you can use to move data in and out of databases. You can select the method that best fits your use case.">How Does Data Pump Move Data?</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
            </div><a id="SUTIL4334"></a><div class="props_rev_3"><a id="GUID-45B17B65-20F2-4128-9A39-B1B0F5E323BB" name="GUID-45B17B65-20F2-4128-9A39-B1B0F5E323BB"></a><h3 id="SUTIL-GUID-45B17B65-20F2-4128-9A39-B1B0F5E323BB" class="sect3"><span class="enumeration_section">1.3 </span>Using Oracle Data Pump With CDBs
               </h3>
               <div>
                  <p>Oracle Data Pump can migrate all, or portions of, a database from a non-CDB into a PDB, between PDBs within the same or different CDBs, and from a PDB into a non-CDB.</p>
               </div>
               <div>
                  <ul class="ullinks">
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-BD76463C-0867-477E-983F-4329610EC458">About Using Data Pump in a Multitenant Environment</a><br>In general, using Data Pump with PDBs is identical to using Data Pump with a non-CDB. 
                     </li>
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-49A847B1-3193-4C45-B7F3-B7F514B75C71">Using Data Pump to Move Data Into a CDB</a><br>After you create an empty PDB, you can use an Oracle Data Pump full-mode export and import operation to move data into the PDB.
                     </li>
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-C1578FB6-216F-473E-A6D5-18453D4F9021">Using Data Pump to Move PDBs Within Or Between CDBs</a><br>Data Pump export and import operations on PDBs are identical to those on non-CDBs, with the exception of how common users are handled.
                     </li>
                  </ul>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-17FAE261-0972-4220-A2E4-44D479F519D4" title="Oracle Data Pump technology enables very high-speed movement of data and metadata from one database to another.">Overview of Oracle Data Pump</a></p>
                     </div>
                  </div>
               </div>
               
               <div class="sect3"><a id="GUID-BD76463C-0867-477E-983F-4329610EC458" name="GUID-BD76463C-0867-477E-983F-4329610EC458"></a><h4 id="SUTIL-GUID-BD76463C-0867-477E-983F-4329610EC458" class="sect4"><span class="enumeration_section">1.3.1 </span>About Using Data Pump in a Multitenant Environment
                  </h4>
                  <div>
                     <p>In general, using Data Pump with PDBs is identical to using Data Pump with a non-CDB. </p>
                     <p>A multitenant container database (CDB) is an Oracle database that includes zero, one, or many user-created pluggable databases (PDBs). A PDB is a portable set of schemas, schema objects, and nonschema objects that appear to an Oracle Net client as a non-CDB. A non-CDB is an Oracle database that is not a CDB.</p>
                     <p>You can use Data Pump to migrate all or some of a database in the following scenarios:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>From a non-CDB into a PDB</p>
                        </li>
                        <li>
                           <p>Between PDBs within the same or different CDBs</p>
                        </li>
                        <li>
                           <p>From a PDB into a non-CDB</p>
                        </li>
                     </ul>
                     <div class="infoboxnote" id="GUID-BD76463C-0867-477E-983F-4329610EC458__GUID-140B9CD4-E02E-4A16-9410-B036E8310254">
                        <p class="notep1">Note:</p>
                        <p>Data Pump does not support any CDB-wide operations. If you are connected to the root or seed database of a CDB, then Data Pump issues the following warning:</p><pre class="pre codeblock"><code>ORA-39357: Warning: Oracle Data Pump operations are not typically needed when connected to the root or seed of a container database.</code></pre></div>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-45B17B65-20F2-4128-9A39-B1B0F5E323BB" title="Oracle Data Pump can migrate all, or portions of, a database from a non-CDB into a PDB, between PDBs within the same or different CDBs, and from a PDB into a non-CDB.">Using Oracle Data Pump With CDBs</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="SUTIL4335"></a><div class="props_rev_3"><a id="GUID-49A847B1-3193-4C45-B7F3-B7F514B75C71" name="GUID-49A847B1-3193-4C45-B7F3-B7F514B75C71"></a><h4 id="SUTIL-GUID-49A847B1-3193-4C45-B7F3-B7F514B75C71" class="sect4"><span class="enumeration_section">1.3.2 </span>Using Data Pump to Move Data Into a CDB
                  </h4>
                  <div>
                     <p>After you create an empty PDB, you can use an Oracle Data Pump full-mode export and import operation to move data into the PDB.</p>
                     <p>You can import data with or without the transportable option. If you use the transportable option on a full mode export or import, then it is referred to as a full transportable export/import. </p>
                     <p>When the transportable option is used, export and import use both transportable tablespace data movement and conventional data movement; the latter for those tables that reside in non-transportable tablespaces such as <code class="codeph">SYSTEM</code> and <code class="codeph">SYSAUX</code>. Using the transportable option can reduce the export time and especially, the import time, because table data does not need to be unloaded and reloaded and index structures in user tablespaces do not need to be recreated.
                     </p>
                     <p>Note the following requirements when using Data Pump to move data into a CDB:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>To administer a multitenant environment, you must have the <code class="codeph">CDB_DBA</code> role.
                           </p>
                        </li>
                        <li>
                           <p>Full database exports from Oracle Database 11.2.0.2 and earlier can be imported into Oracle Database 12c (CDB or non-CDB). However, Oracle recommends that you first upgrade the source database to Oracle Database 11g release 2 (11.2.0.3 or later), so that information about registered options and components is included in the export.</p>
                        </li>
                        <li>
                           <p>When migrating Oracle Database 11g release 2 (11.2.0.3 or later) to a CDB (or to a non-CDB) using either full database export or full transportable database export, you must set the Data Pump Export parameter <code class="codeph">VERSION=12</code> in order to generate a dump file that is ready for import into Oracle Database 12c. If you do not set <code class="codeph">VERSION=12</code>, then the export file that is generated does not contain complete information about registered database options and components. 
                           </p>
                        </li>
                        <li>
                           <p>Network-based full transportable imports require use of the <code class="codeph">FULL=YES</code>, <code class="codeph">TRANSPORTABLE=ALWAYS</code>, and <code class="codeph">TRANSPORT_DATAFILES=<span class="variable" translate="no">datafile_name</span></code> parameters. When the source database is Oracle Database 11g release 11.2.0.3 or later, but earlier than Oracle Database 12c Release 1 (12.1), the <code class="codeph">VERSION=12</code> parameter is also required.
                           </p>
                        </li>
                        <li>
                           <p>File-based full transportable imports only require use of the <code class="codeph">TRANSPORT_DATAFILES=<span class="variable" translate="no">datafile_name</span></code> parameter. Data Pump Import infers the presence of the <code class="codeph">TRANSPORTABLE=ALWAYS</code> and <code class="codeph">FULL=YES</code> parameters.
                           </p>
                        </li>
                        <li>
                           <p>As of Oracle Database 12c release 2 (12.2), in a multitenant container database (CDB) environment, the default Data Pump directory object, <code class="codeph">DATA_PUMP_DIR</code>, is defined as a unique path for each PDB in the CDB. This unique path is defined whether the <code class="codeph">PATH_PREFIX</code> clause of the <code class="codeph">CREATE PLUGGABLE DATABASE</code> statement is defined or is not defined for relative paths. 
                           </p>
                        </li>
                        <li>
                           <p>Starting in Oracle Database 19c, the <code class="codeph">credential</code> parameter of <code class="codeph">impdp</code> specifies the name of the credential object that contains the user name and password required to access an object store bucket. You can also specify a default credential using the PDB property named <code class="codeph">DEFAULT_CREDENTIAL</code>. When you run <code class="codeph">impdb</code> with then default credential, you prefix the dump file name with <code class="codeph">DEFAULT_CREDENTIAL:</code> and you do not specify the <code class="codeph">credential</code> parameter. 
                           </p>
                        </li>
                     </ul>
                     <div class="example" id="GUID-49A847B1-3193-4C45-B7F3-B7F514B75C71__GUID-13F8CE65-B6F4-4A75-AB27-5F6268C39C84">
                        <p class="titleinexample">Example 1-1 Importing a Table into a PDB</p>
                        <p>To specify a particular PDB for the export/import operation, supply a connect identifier in the connect string when you start Data Pump. For example, to import data to a PDB named <code class="codeph">pdb1</code>, you could enter the following on the Data Pump command line:
                        </p><pre class="pre codeblock"><code>impdp hr@pdb1 DIRECTORY=dpump_dir1 DUMPFILE=hr.dmp TABLES=employees
</code></pre></div>
                     <!-- class="example" -->
                     <div class="example" id="GUID-49A847B1-3193-4C45-B7F3-B7F514B75C71__GUID-30BBDAEB-AC3A-4672-BC72-09052CFBFB35">
                        <p class="titleinexample">Example 1-2 Specifying a Credential When Importing Data</p>
                        <p>This example assumes that you created a credential named <code class="codeph">HR_CRED</code> using <code class="codeph">DBMS_CREDENTIAL.CREATE_CREDENTIAL</code> as follows: 
                        </p><pre class="pre codeblock"><code>BEGIN
  DBMS_CLOUD.CREATE_CREDENTIAL(
    credential_name =&gt; 'HR_CRED',
    username =&gt; 'atpc_user@oracle.com',
    password =&gt; '<span class="italic">password</span>'
  );
END;
/</code></pre><p>The following command specifies credential <code class="codeph">HR_CRED</code>, and specifies the a file stored in an object store. The URL of the file is <code class="codeph">https://example.com/ostore/dnfs/myt.dmp</code>.
                        </p><pre class="pre codeblock"><code>impdp hr@pdb1 \
      table_exists_action=replace \
      credential=HR_CRED \
      parallel=16 \
      dumpfile=https://example.com/ostore/dnfs/myt.dmp</code></pre></div>
                     <!-- class="example" -->
                     <div class="example" id="GUID-49A847B1-3193-4C45-B7F3-B7F514B75C71__GUID-73EF3BB4-46CA-44E4-B67C-1DD09FC48DA3">
                        <p class="titleinexample">Example 1-3 Importing Data Using a Default Credential</p>
                        <ol id="GUID-49A847B1-3193-4C45-B7F3-B7F514B75C71__OL_D5V_NX3_QFB">
                           <li>
                              <p>You create a credential named <code class="codeph">HR_CRED</code> using <code class="codeph">DBMS_CREDENTIAL.CREATE_CREDENTIAL</code> as follows: 
                              </p><pre class="pre codeblock"><code>BEGIN
  DBMS_CLOUD.CREATE_CREDENTIAL(
    credential_name =&gt; 'HR_CRED',
    username =&gt; 'atpc_user@oracle.com',
    password =&gt; '<span class="italic">password</span>'
  );
END;
/</code></pre></li>
                           <li>
                              <p>You set the PDB property <code class="codeph">DEFAULT_CREDENTIAL</code> as follows:
                              </p><pre class="pre codeblock"><code>ALTER DATABASE PROPERTY SET DEFAULT_CREDENTIAL = 'ADMIN.HR_CRED'</code></pre></li>
                           <li>
                              <p>The following command specifies the default credential as a prefix to the dump file location <code class="codeph">https://example.com/ostore/dnfs/myt.dmp</code>:
                              </p><pre class="pre codeblock"><code>impdp hr@pdb1 \
      table_exists_action=replace \
      parallel=16 \
      dumpfile=default_credential:https://example.com/ostore/dnfs/myt.dmp</code></pre><p>Note that the <code class="codeph">credential</code> parameter is not specified.
                              </p>
                           </li>
                        </ol>
                     </div>
                     <!-- class="example" -->
                  </div>
                  <div>
                     <div class="infoboxnotealso" id="GUID-49A847B1-3193-4C45-B7F3-B7F514B75C71__GUID-3144C863-B387-49F4-AEDF-010D15E4D2B1">
                        <p class="notep1">See Also:</p>
                        <ul style="list-style-type: disc;" id="GUID-49A847B1-3193-4C45-B7F3-B7F514B75C71__UL_BYJ_FW3_QFB">
                           <li>
                              <p><a href="../dbseg/configuring-secure-sockets-layer-authentication.html#DBSEG-GUID-6AD89576-526F-4D6B-A539-ADF4B840819F" target="_blank"><span><cite>Oracle Database Security Guide</cite></span></a> to learn how to configure SSL authentication, which is necessary for object store access
                              </p>
                           </li>
                           <li>
                              <p><a href="datapump-import-utility.html#SUTIL-GUID-D11E340E-14C6-43B8-AB09-6335F0C1F71B" target="_blank"><span><cite>Oracle Database Utilities</cite></span></a> to learn about using Data Pump Import to load files to the object store
                              </p>
                           </li>
                        </ul>
                     </div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-45B17B65-20F2-4128-9A39-B1B0F5E323BB" title="Oracle Data Pump can migrate all, or portions of, a database from a non-CDB into a PDB, between PDBs within the same or different CDBs, and from a PDB into a non-CDB.">Using Oracle Data Pump With CDBs</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="SUTIL4336"></a><div class="props_rev_3"><a id="GUID-C1578FB6-216F-473E-A6D5-18453D4F9021" name="GUID-C1578FB6-216F-473E-A6D5-18453D4F9021"></a><h4 id="SUTIL-GUID-C1578FB6-216F-473E-A6D5-18453D4F9021" class="sect4"><span class="enumeration_section">1.3.3 </span>Using Data Pump to Move PDBs Within Or Between CDBs
                  </h4>
                  <div>
                     <p>Data Pump export and import operations on PDBs are identical to those on non-CDBs, with the exception of how common users are handled.</p>
                     <div class="section">
                        <p>If you have created a common user in a CDB, then a full database or privileged schema export of that user from within any PDB in the CDB results in a standard <code class="codeph">CREATE USER C##common name</code> DDL statement being performed upon import. The statement will fail because of the common user prefix <code class="codeph">C##</code> on the user name. The following error message will be returned:
                        </p><pre class="pre codeblock"><code>ORA-65094:invalid local user or role name
</code></pre><p>In the PDB being exported, if you have created local objects in that user's schema and you want to import them, then either make sure a common user of the same name already exists in the target CDB instance or use the Data Pump Import <code class="codeph">REMAP_SCHEMA</code> parameter on the <code class="codeph">impdp</code> command, as follows:
                        </p><pre class="pre codeblock"><code>REMAP_SCHEMA=C##<span class="variable" translate="no">common name:local user name</span>
</code></pre></div>
                     <!-- class="section" -->
                  </div>
                  <div>
                     <div class="relinfo">
                        <p><strong>Related Topics</strong></p>
                        <ul>
                           <li><a href="oracle-data-pump-export-utility.html#GUID-079769D8-40F4-432F-88AD-E7264D7A2E2D" title="You can use Data Pump to carry out a full database export by using the FULL parameter.">Full Mode</a></li>
                           <li><a href="datapump-import-utility.html#GUID-E27D2DC9-A6D8-4F0B-AB72-6BF526B3AA18" title="A full import is specified using the FULL parameter.">Full Import Mode</a></li>
                           <li><a href="oracle-original-export-utility.html#GUID-1EAD5074-652B-46AB-9F4B-B9902E3F2BDE" title="Describes factors to consider when using Export across a network.">Network Considerations</a></li>
                        </ul>
                     </div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-45B17B65-20F2-4128-9A39-B1B0F5E323BB" title="Oracle Data Pump can migrate all, or portions of, a database from a non-CDB into a PDB, between PDBs within the same or different CDBs, and from a PDB into a non-CDB.">Using Oracle Data Pump With CDBs</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
            </div><a id="SUTIL807"></a><div class="props_rev_3"><a id="GUID-8B6975D3-3BEC-4584-B416-280125EEC57E" name="GUID-8B6975D3-3BEC-4584-B416-280125EEC57E"></a><h3 id="SUTIL-GUID-8B6975D3-3BEC-4584-B416-280125EEC57E" class="sect3"><span class="enumeration_section">1.4 </span>Required Roles for Data Pump Export and Import Operations
               </h3>
               <div>
                  <p>Many Data Pump Export and Import operations require the user to have the <code class="codeph">DATAPUMP_EXP_FULL_DATABASE</code> role, or the <code class="codeph">DATAPUMP_IMP_FULL_DATABASE</code> role, or both.
                  </p>
                  <p>These roles are automatically defined for Oracle databases when you run the standard scripts that are part of database creation. (Note that although the names of these roles contain the word FULL, these roles actually apply to any privileged operations in any export or import mode, not only Full mode.)</p>
                  <p>The <code class="codeph">DATAPUMP_EXP_FULL_DATABASE</code> role affects only export operations. The <code class="codeph">DATAPUMP_IMP_FULL_DATABASE</code> role affects import operations and operations that use the Import <code class="codeph">SQLFILE</code> parameter. These roles allow users performing exports and imports to do the following:
                  </p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p>Perform the operation outside the scope of their schema</p>
                     </li>
                     <li>
                        <p>Monitor jobs that were initiated by another user</p>
                     </li>
                     <li>
                        <p>Export objects (such as tablespace definitions) and import objects (such as directory definitions) that unprivileged users cannot reference</p>
                     </li>
                  </ul>
                  <p>These are powerful roles. Database administrators should use caution when granting these roles to users.</p>
                  <p>Although the <code class="codeph">SYS</code> schema does not have either of these roles assigned to it, all security checks performed by Data Pump that require these roles also grant access to the <code class="codeph">SYS</code> schema.
                  </p>
                  <div class="infoboxnote" id="GUID-8B6975D3-3BEC-4584-B416-280125EEC57E__GUID-51ABDCC3-9DC6-44B6-882E-7344F314E00D">
                     <p class="notep1">Note:</p>
                     <p>If you receive an <code class="codeph">ORA-39181: Only Partial Data Exported Due to Fine Grain Access Control</code> error message, then see the My Oracle Support note 422480.1 for information about security during an export of table data with fine-grained access control policies enabled.:
                     </p>
                     <p><a href="https://support.oracle.com/rs?type=doc&amp;id=422480.1" target="_blank">https://support.oracle.com/rs?type=doc&amp;id=422480.1</a></p>
                  </div>
               </div>
               <div>
                  <div class="infoboxnotealso" id="GUID-8B6975D3-3BEC-4584-B416-280125EEC57E__GUID-75AB188A-BC01-4230-9879-B9F91687A311">
                     <p class="notep1">See Also:</p>
                     <p><a href="../dbseg/configuring-privilege-and-role-authorization.html#DBSEG4414" target="_blank"><span><cite>Oracle Database Security Guide</cite></span></a> for more information about predefined roles in an Oracle Database installation
                     </p>
                  </div>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-17FAE261-0972-4220-A2E4-44D479F519D4" title="Oracle Data Pump technology enables very high-speed movement of data and metadata from one database to another.">Overview of Oracle Data Pump</a></p>
                     </div>
                  </div>
               </div>
               
            </div><a id="SUTIL808"></a><div class="props_rev_3"><a id="GUID-6BDC1CC8-8596-402D-B016-602985B97AB6" name="GUID-6BDC1CC8-8596-402D-B016-602985B97AB6"></a><h3 id="SUTIL-GUID-6BDC1CC8-8596-402D-B016-602985B97AB6" class="sect3"><span class="enumeration_section">1.5 </span>What Happens During Execution of an Oracle Data Pump Job?
               </h3>
               <p>Oracle Data Pump jobs use a master table, a master process, and worker processes to perform the work and keep track of progress.</p>
               <div>
                  <ul class="ullinks">
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-E4F373D6-0D0C-4FBD-AEC1-FDC91F46BD28">Coordination of a Job</a><br>A master process is created to coordinate every Data Pump Export and Data Pump Import job.
                     </li>
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-B9A676E5-B3CB-417B-BC97-65FE33448C2F">Tracking Progress Within a Job</a><br>While the data and metadata are being transferred, a master table is used to track the progress within a job.
                     </li>
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-DB178A4E-36D4-4ECF-932A-6DE26FE2C2EF">Filtering Data and Metadata During a Job</a><br>You can use the <code class="codeph">EXCLUDE</code> and <code class="codeph">INCLUDE</code> parameters to filter the types of objects that are exported and imported.
                     </li>
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-15CF2160-0F2C-49D4-9FCC-8B60BD111331">Transforming Metadata During a Job</a><br>Transformations on the metadata can be done using the Data Pump Import parameters <code class="codeph">REMAP_DATAFILE</code>, <code class="codeph">REMAP_SCHEMA</code>, <code class="codeph">REMAP_TABLE,REMAP_TABLESPACE</code>, <code class="codeph">TRANSFORM,</code> and <code class="codeph">PARTITION_OPTIONS</code>.
                     </li>
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-AE83786E-EFC9-4552-BF79-AC72CE063EB6">Maximizing Job Performance</a><br>Data Pump can employ multiple worker processes, running in parallel, to increase job performance.
                     </li>
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-31DA185F-92E9-49F7-8431-B10354199C5A">Loading and Unloading of Data</a><br>The worker processes unload and load metadata and table data. For export, all metadata and data are unloaded in parallel, with the exception of jobs that use transportable tablespace. For import, objects must be created in the correct dependency order. 
                     </li>
                  </ul>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-17FAE261-0972-4220-A2E4-44D479F519D4" title="Oracle Data Pump technology enables very high-speed movement of data and metadata from one database to another.">Overview of Oracle Data Pump</a></p>
                     </div>
                  </div>
               </div>
               <a id="SUTIL809"></a><div class="props_rev_3"><a id="GUID-E4F373D6-0D0C-4FBD-AEC1-FDC91F46BD28" name="GUID-E4F373D6-0D0C-4FBD-AEC1-FDC91F46BD28"></a><h4 id="SUTIL-GUID-E4F373D6-0D0C-4FBD-AEC1-FDC91F46BD28" class="sect4"><span class="enumeration_section">1.5.1 </span>Coordination of a Job
                  </h4>
                  <div>
                     <p>A master process is created to coordinate every Data Pump Export and Data Pump Import job.</p>
                     <p>The master process controls the entire job, including communicating with the clients, creating and controlling a pool of worker processes, and performing logging operations.</p>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-6BDC1CC8-8596-402D-B016-602985B97AB6" title="Oracle Data Pump jobs use a master table, a master process, and worker processes to perform the work and keep track of progress.">What Happens During Execution of an Oracle Data Pump Job?</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="SUTIL810"></a><div class="props_rev_3"><a id="GUID-B9A676E5-B3CB-417B-BC97-65FE33448C2F" name="GUID-B9A676E5-B3CB-417B-BC97-65FE33448C2F"></a><h4 id="SUTIL-GUID-B9A676E5-B3CB-417B-BC97-65FE33448C2F" class="sect4"><span class="enumeration_section">1.5.2 </span>Tracking Progress Within a Job
                  </h4>
                  <div>
                     <p>While the data and metadata are being transferred, a master table is used to track the progress within a job.</p>
                     <p>The master table is implemented as a user table within the database. The specific function of the master table for export and import jobs is as follows:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>For export jobs, the master table records the location of database objects within a dump file set. Export builds and maintains the master table for the duration of the job. At the end of an export job, the content of the master table is written to a file in the dump file set. </p>
                        </li>
                        <li>
                           <p>For import jobs, the master table is loaded from the dump file set and is used to control the sequence of operations for locating objects that need to be imported into the target database. </p>
                        </li>
                     </ul>
                     <p>The master table is created in the schema of the current user performing the export or import operation. Therefore, that user must have the <code class="codeph">CREATE TABLE</code> system privilege and a sufficient tablespace quota for creation of the master table. The name of the master table is the same as the name of the job that created it. Therefore, you cannot explicitly give a Data Pump job the same name as a preexisting table or view. 
                     </p>
                     <p>For all operations, the information in the master table is used to restart a job. (Note that transportable jobs are not restartable.)</p>
                     <p>The master table is either retained or dropped, depending on the circumstances, as follows:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Upon successful job completion, the master table is dropped. You can override this by setting the Data Pump <code class="codeph">KEEP_MASTER=YES</code> parameter for the job. 
                           </p>
                        </li>
                        <li>
                           <p>The master table is automatically retained for jobs that do not complete successfully.</p>
                        </li>
                        <li>
                           <p>If a job is stopped using the <code class="codeph">STOP_JOB</code> interactive command, then the master table is retained for use in restarting the job.
                           </p>
                        </li>
                        <li>
                           <p>If a job is killed using the <code class="codeph">KILL_JOB</code> interactive command, then the master table is dropped and the job cannot be restarted.
                           </p>
                        </li>
                        <li>
                           <p>If a job terminates unexpectedly, then the master table is retained. You can delete it if you do not intend to restart the job.</p>
                        </li>
                        <li>
                           <p>If a job stops before it starts running (that is, before any database objects have been copied), then the master table is dropped.</p>
                        </li>
                     </ul>
                  </div>
                  <div>
                     <div class="infoboxnotealso" id="GUID-B9A676E5-B3CB-417B-BC97-65FE33448C2F__GUID-D903556B-4797-4296-B374-182932E81663">
                        <p class="notep1">See Also:</p>
                        <p><a href="oracle-data-pump-export-utility.html#GUID-C146E99F-CBAB-43B4-A802-A8D5AD5898AE" title="The Data Pump Export command-line utility JOB_NAME parameter identifies the export job in subsequent actions, such as when using ATTACH to attach to a job, or to identify a job using DBA_DATAPUMP_JOBS or USER_DATAPUMP_JOBS views.">JOB_NAME</a> for more information about how job names are formed
                        </p>
                     </div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-6BDC1CC8-8596-402D-B016-602985B97AB6" title="Oracle Data Pump jobs use a master table, a master process, and worker processes to perform the work and keep track of progress.">What Happens During Execution of an Oracle Data Pump Job?</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="SUTIL811"></a><div class="props_rev_3"><a id="GUID-DB178A4E-36D4-4ECF-932A-6DE26FE2C2EF" name="GUID-DB178A4E-36D4-4ECF-932A-6DE26FE2C2EF"></a><h4 id="SUTIL-GUID-DB178A4E-36D4-4ECF-932A-6DE26FE2C2EF" class="sect4"><span class="enumeration_section">1.5.3 </span>Filtering Data and Metadata During a Job
                  </h4>
                  <div>
                     <p>You can use the <code class="codeph">EXCLUDE</code> and <code class="codeph">INCLUDE</code> parameters to filter the types of objects that are exported and imported.
                     </p>
                     <p>Within the master table, specific objects are assigned attributes such as name or owning schema. Objects also belong to a class of objects (such as <code class="codeph">TABLE</code>, <code class="codeph">INDEX,</code> or <code class="codeph">DIRECTORY</code>). The class of an object is called its object type. You can use the <code class="codeph">EXCLUDE</code> and <code class="codeph">INCLUDE</code> parameters to restrict the types of objects that are exported and imported. The objects can be based upon the name of the object or the name of the schema that owns the object. You can also specify data-specific filters to restrict the rows that are exported and imported.
                     </p>
                  </div>
                  <div>
                     <div class="infoboxnotealso" id="GUID-DB178A4E-36D4-4ECF-932A-6DE26FE2C2EF__GUID-64C90897-556D-466A-AA03-C040A8D9340F">
                        <p class="notep1">See Also:</p>
                        <p></p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><a href="oracle-data-pump-export-utility.html#GUID-1F85C939-E439-4436-BFEF-6DC7E167C912" title="Data Pump Export provides data and metadata filtering capability. This capability helps you limit the type of information that is exported.">Filtering During Export Operations</a></p>
                           </li>
                           <li>
                              <p><a href="datapump-import-utility.html#GUID-107CA775-350C-4CCE-9601-E1E810589B40" title="Data Pump Import provides data and metadata filtering capability, which can help you limit the type of information that is imported..">Filtering During Import Operations</a></p>
                           </li>
                        </ul>
                     </div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-6BDC1CC8-8596-402D-B016-602985B97AB6" title="Oracle Data Pump jobs use a master table, a master process, and worker processes to perform the work and keep track of progress.">What Happens During Execution of an Oracle Data Pump Job?</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="SUTIL812"></a><div class="props_rev_3"><a id="GUID-15CF2160-0F2C-49D4-9FCC-8B60BD111331" name="GUID-15CF2160-0F2C-49D4-9FCC-8B60BD111331"></a><h4 id="SUTIL-GUID-15CF2160-0F2C-49D4-9FCC-8B60BD111331" class="sect4"><span class="enumeration_section">1.5.4 </span>Transforming Metadata During a Job
                  </h4>
                  <div>
                     <p>Transformations on the metadata can be done using the Data Pump Import parameters <code class="codeph">REMAP_DATAFILE</code>, <code class="codeph">REMAP_SCHEMA</code>, <code class="codeph">REMAP_TABLE,REMAP_TABLESPACE</code>, <code class="codeph">TRANSFORM,</code> and <code class="codeph">PARTITION_OPTIONS</code>.
                     </p>
                     <p>When you are moving data from one database to another, it is often useful to perform transformations on the metadata for remapping storage between tablespaces or redefining the owner of a particular set of objects.</p>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-6BDC1CC8-8596-402D-B016-602985B97AB6" title="Oracle Data Pump jobs use a master table, a master process, and worker processes to perform the work and keep track of progress.">What Happens During Execution of an Oracle Data Pump Job?</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="SUTIL813"></a><div class="props_rev_3"><a id="GUID-AE83786E-EFC9-4552-BF79-AC72CE063EB6" name="GUID-AE83786E-EFC9-4552-BF79-AC72CE063EB6"></a><h4 id="SUTIL-GUID-AE83786E-EFC9-4552-BF79-AC72CE063EB6" class="sect4"><span class="enumeration_section">1.5.5 </span>Maximizing Job Performance
                  </h4>
                  <div>
                     <p>Data Pump can employ multiple worker processes, running in parallel, to increase job performance.</p>
                     <p>Use the <code class="codeph">PARALLEL</code> parameter to set a degree of parallelism that takes maximum advantage of current conditions. For example, to limit the effect of a job on a production system, the database administrator (DBA) might want to restrict the parallelism. The degree of parallelism can be reset at any time during a job. For example, <code class="codeph">PARALLEL</code> could be set to 2 during production hours to restrict a particular job to only two degrees of parallelism, and during nonproduction hours it could be reset to 8. The parallelism setting is enforced by the master process, which allocates work to be executed to worker processes that perform the data and metadata processing within an operation. These worker processes operate in parallel. For recommendations on setting the degree of parallelism, see the Export PARALLEL and Import PARALLEL parameter descriptions.
                     </p>
                     <div class="infoboxnote" id="GUID-AE83786E-EFC9-4552-BF79-AC72CE063EB6__GUID-75136923-D9BA-4537-871A-CE2DD6CBC98F">
                        <p class="notep1">Note:</p>
                        <p>The ability to adjust the degree of parallelism is available only in the Enterprise Edition of Oracle Database.</p>
                     </div>
                  </div>
                  <div>
                     <div class="infoboxnotealso" id="GUID-AE83786E-EFC9-4552-BF79-AC72CE063EB6__GUID-A1A74F5D-703D-4D0E-B093-E37DBDC419BA">
                        <p class="notep1">See Also:</p>
                        <p></p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p><a href="oracle-data-pump-export-utility.html#GUID-55E6AC71-5CDE-410E-AB02-798AEC54F411__CIHGACIA">Using PARALLEL During An Export In An Oracle RAC Environment</a></p>
                           </li>
                           <li>
                              <p><a href="datapump-import-utility.html#GUID-3081A258-0C23-40B0-8487-9C7A0D248E23__CIHFEFCD">Using PARALLEL During An Import In An Oracle RAC Environment</a></p>
                           </li>
                        </ul>
                     </div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-6BDC1CC8-8596-402D-B016-602985B97AB6" title="Oracle Data Pump jobs use a master table, a master process, and worker processes to perform the work and keep track of progress.">What Happens During Execution of an Oracle Data Pump Job?</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="SUTIL814"></a><div class="props_rev_3"><a id="GUID-31DA185F-92E9-49F7-8431-B10354199C5A" name="GUID-31DA185F-92E9-49F7-8431-B10354199C5A"></a><h4 id="SUTIL-GUID-31DA185F-92E9-49F7-8431-B10354199C5A" class="sect4"><span class="enumeration_section">1.5.6 </span>Loading and Unloading of Data
                  </h4>
                  <div>
                     <p>The worker processes unload and load metadata and table data. For export, all metadata and data are unloaded in parallel, with the exception of jobs that use transportable tablespace. For import, objects must be created in the correct dependency order. </p>
                     <p>If there are enough objects of the same type to make use of multiple workers, then the objects will be imported by multiple worker processes. Some metadata objects have interdependencies which require one worker process to create them serially to satisfy those dependencies. Worker processes are created as needed until the number of worker processes equals the value supplied for the <code class="codeph">PARALLEL</code> command-line parameter. The number of active worker processes can be reset throughout the life of a job. Worker processes can be started on different nodes in an Oracle Real Application Clusters (Oracle RAC) environment.
                     </p>
                     <div class="infoboxnote" id="GUID-31DA185F-92E9-49F7-8431-B10354199C5A__GUID-4DF1D2B5-224A-4302-A8D3-50A4A8043CF7">
                        <p class="notep1">Note:</p>
                        <p>The value of <code class="codeph">PARALLEL</code> is restricted to 1 in the Standard Edition of Oracle Database.
                        </p>
                     </div>
                     <p>When a worker process is assigned the task of loading or unloading a very large table or partition, it may choose to use the external tables access method to make maximum use of parallel execution. In such a case, the worker process becomes a parallel execution coordinator. The actual loading and unloading work is divided among some number of parallel I/O execution processes (sometimes called slaves) allocated from a pool of available processes in an Oracle RAC environment.</p>
                  </div>
                  <div>
                     <div class="relinfo">
                        <p><strong>Related Topics</strong></p>
                        <ul>
                           <li><a href="oracle-data-pump-export-utility.html#GUID-55E6AC71-5CDE-410E-AB02-798AEC54F411">PARALLEL</a></li>
                           <li><a href="datapump-import-utility.html#GUID-3081A258-0C23-40B0-8487-9C7A0D248E23">PARALLEL</a></li>
                        </ul>
                     </div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-6BDC1CC8-8596-402D-B016-602985B97AB6" title="Oracle Data Pump jobs use a master table, a master process, and worker processes to perform the work and keep track of progress.">What Happens During Execution of an Oracle Data Pump Job?</a></p>
                        </div>
                     </div>
                  </div>
               </div>
            </div><a id="SUTIL815"></a><div class="props_rev_3"><a id="GUID-E365D74E-12CD-495C-BA23-5A55F679C7E7" name="GUID-E365D74E-12CD-495C-BA23-5A55F679C7E7"></a><h3 id="SUTIL-GUID-E365D74E-12CD-495C-BA23-5A55F679C7E7" class="sect3"><span class="enumeration_section">1.6 </span>Monitoring Job Status
               </h3>
               <div>
                  <p>The Oracle Data Pump Export and Import client utilities can attach to a job in either logging mode or interactive-command mode.</p>
                  <p>In logging mode, real-time detailed status about the job is automatically displayed during job execution. The information displayed can include the job and parameter descriptions, an estimate of the amount of data to be processed, a description of the current operation or item being processed, files used during the job, any errors encountered, and the final job state (Stopped or Completed).</p>
                  <p>In interactive-command mode, job status can be displayed on request. The information displayed can include the job description and state, a description of the current operation or item being processed, files being written, and a cumulative status.</p>
                  <p>You can also have a log file written during the execution of a job. The log file summarizes the progress of the job, lists any errors encountered during execution of the job, and records the completion status of the job.</p>
                  <p>As an alternative to determine job status or other information about Oracle Data Pump jobs, you can query the <code class="codeph">DBA_DATAPUMP_JOBS</code>, <code class="codeph">USER_DATAPUMP_JOBS</code>, or <code class="codeph">DBA_DATAPUMP_SESSIONS</code> views. Refer to <cite>Oracle Database Reference</cite> for more information. 
                  </p>
               </div>
               <div>
                  <div class="relinfo">
                     <p><strong>Related Topics</strong></p>
                     <ul>
                        <li><a href="../refrn/DBA_DATAPUMP_JOBS.html#REFRN23338" target="_blank"><span><cite>Oracle Database Reference</cite></span></a></li>
                     </ul>
                  </div>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-17FAE261-0972-4220-A2E4-44D479F519D4" title="Oracle Data Pump technology enables very high-speed movement of data and metadata from one database to another.">Overview of Oracle Data Pump</a></p>
                     </div>
                  </div>
               </div>
            </div><a id="SUTIL816"></a><div class="props_rev_3"><a id="GUID-A4C5E6C1-28DE-45AF-B90C-B7FEEFF62069" name="GUID-A4C5E6C1-28DE-45AF-B90C-B7FEEFF62069"></a><h3 id="SUTIL-GUID-A4C5E6C1-28DE-45AF-B90C-B7FEEFF62069" class="sect3"><span class="enumeration_section">1.7 </span>Monitoring the Progress of Executing Jobs
               </h3>
               <div>
                  <p>To monitor table data transfers, you can use the <code class="codeph">V$SESSION_LONGOPS</code> dynamic performance view to monitor Oracle Data Pump jobs.
                  </p>
                  <p>Oracle Data Pump operations that transfer table data (export and import) maintain an entry in the <code class="codeph">V$SESSION_LONGOPS</code> dynamic performance view indicating the job progress (in megabytes of table data transferred). The entry contains the estimated transfer size and is periodically updated to reflect the actual amount of data transferred.
                  </p>
                  <p>Use of the <code class="codeph">COMPRESSION</code>, <code class="codeph">ENCRYPTION</code>, <code class="codeph">ENCRYPTION_ALGORITHM</code>, <code class="codeph">ENCRYPTION_MODE</code>, <code class="codeph">ENCRYPTION_PASSWORD</code>, <code class="codeph">QUERY</code>, and <code class="codeph">REMAP_DATA</code> parameters are not reflected in the determination of estimate values.
                  </p>
                  <p>The usefulness of the estimate value for export operations depends on the type of estimation requested when the operation was initiated, and it is updated as required if exceeded by the actual transfer amount. The estimate value for import operations is exact.</p>
                  <p>The <code class="codeph">V$SESSION_LONGOPS</code> columns that are relevant to a Data Pump job are as follows:
                  </p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p><code class="codeph">USERNAME</code>: Job owner
                        </p>
                     </li>
                     <li>
                        <p><code class="codeph">OPNAME</code>: Job name
                        </p>
                     </li>
                     <li>
                        <p><code class="codeph">TARGET_DESC</code>: Job operation
                        </p>
                     </li>
                     <li>
                        <p><code class="codeph">SOFAR</code>: Megabytes transferred thus far during the job
                        </p>
                     </li>
                     <li>
                        <p><code class="codeph">TOTALWORK</code> Estimated number of megabytes in the job
                        </p>
                     </li>
                     <li>
                        <p><code class="codeph">UNITS</code>: Megabytes (MB)
                        </p>
                     </li>
                     <li>
                        <p><code class="codeph">MESSAGE</code>: A formatted status message that uses the following format: 
                        </p><pre class="pre codeblock"><code>'<span class="variable" translate="no">job_name</span>: <span class="variable" translate="no">operation_name</span> : <span class="variable" translate="no">nnn</span> out of <span class="variable" translate="no">mmm</span> MB done'</code></pre></li>
                  </ul>
               </div>
               <div>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-17FAE261-0972-4220-A2E4-44D479F519D4" title="Oracle Data Pump technology enables very high-speed movement of data and metadata from one database to another.">Overview of Oracle Data Pump</a></p>
                     </div>
                  </div>
               </div>
               
            </div><a id="SUTIL817"></a><div class="props_rev_3"><a id="GUID-FE7E746D-A343-463E-A4E2-A6AD1349FE4B" name="GUID-FE7E746D-A343-463E-A4E2-A6AD1349FE4B"></a><h3 id="SUTIL-GUID-FE7E746D-A343-463E-A4E2-A6AD1349FE4B" class="sect3"><span class="enumeration_section">1.8 </span>File Allocation
               </h3>
               <div>
                  <p>Oracle Data Pump manages several different types of files. You can use commands in interactive mode to modify how OracleData Pump allocates and handles these files.</p>
               </div>
               <div>
                  <ul class="ullinks">
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-29E88FEC-5F68-4841-B1B2-D4CD8B2880EE">Understanding File Allocation in Data Pump</a><br>Understanding how Data Pump allocates and handles files will help you to use Export and Import to their fullest advantage.
                     </li>
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-8C1CD0EA-F6F8-4627-867E-956ABCB984F0">Specifying Files and Adding Additional Dump Files</a><br>For export operations, you can specify dump files at the time the job is defined, and also at a later time during the operation.
                     </li>
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-02A2E765-03BA-4097-B3A3-67B006C749AC">Default Locations for Dump, Log, and SQL Files</a><br>Review these topics to understand the Oracle Data Pump default file locations, and to understand how these locations are affected when you are using Oracle RAC, Oracle Automatic Storage Management, and multitenant architecture.
                     </li>
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-6F532CA9-CE90-47D6-84ED-AD10F1E18056">Using Substitution Variables</a><br>Instead of, or in addition to, listing specific file names, you can use the <code class="codeph">DUMPFILE</code> parameter during export operations to specify multiple dump files, by using a substitution variable in the file name. This is called a dump file template.
                     </li>
                  </ul>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-17FAE261-0972-4220-A2E4-44D479F519D4" title="Oracle Data Pump technology enables very high-speed movement of data and metadata from one database to another.">Overview of Oracle Data Pump</a></p>
                     </div>
                  </div>
               </div>
               
               <div class="sect3"><a id="GUID-29E88FEC-5F68-4841-B1B2-D4CD8B2880EE" name="GUID-29E88FEC-5F68-4841-B1B2-D4CD8B2880EE"></a><h4 id="SUTIL-GUID-29E88FEC-5F68-4841-B1B2-D4CD8B2880EE" class="sect4"><span class="enumeration_section">1.8.1 </span>Understanding File Allocation in Data Pump
                  </h4>
                  <div>
                     <p>Understanding how Data Pump allocates and handles files will help you to use Export and Import to their fullest advantage.</p>
                     <p>Data Pump jobs manage the following types of files:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Dump files to contain the data and metadata that is being moved.</p>
                        </li>
                        <li>
                           <p>Log files to record the messages associated with an operation.</p>
                        </li>
                        <li>
                           <p>SQL files to record the output of a SQLFILE operation. A SQLFILE operation is started using the Data Pump Import <code class="codeph">SQLFILE</code> parameter and results in all the SQL DDL that Import would be executing based on other parameters, being written to a SQL file.
                           </p>
                        </li>
                        <li>
                           <p>Files specified by the <code class="codeph">DATA_FILES</code> parameter during a transportable import.
                           </p>
                        </li>
                     </ul>
                     <div class="infoboxnote" id="GUID-29E88FEC-5F68-4841-B1B2-D4CD8B2880EE__GUID-4FD8114C-E2B6-4B7A-B39E-A59B26BD5E28">
                        <p class="notep1">Note:</p>
                        <p>If your Data Pump job generates errors related to Network File Storage (NFS), then consult the installation guide for your platform to determine the correct NFS mount settings.</p>
                     </div>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-FE7E746D-A343-463E-A4E2-A6AD1349FE4B" title="Oracle Data Pump manages several different types of files. You can use commands in interactive mode to modify how OracleData Pump allocates and handles these files.">File Allocation</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="SUTIL818"></a><div class="props_rev_3"><a id="GUID-8C1CD0EA-F6F8-4627-867E-956ABCB984F0" name="GUID-8C1CD0EA-F6F8-4627-867E-956ABCB984F0"></a><h4 id="SUTIL-GUID-8C1CD0EA-F6F8-4627-867E-956ABCB984F0" class="sect4"><span class="enumeration_section">1.8.2 </span>Specifying Files and Adding Additional Dump Files
                  </h4>
                  <div>
                     <p>For export operations, you can specify dump files at the time the job is defined, and also at a later time during the operation.</p>
                     <p>If you discover that space is running low during an export operation, then you can add additional dump files by using the Data Pump Export <code class="codeph">ADD_FILE</code> command in interactive mode. 
                     </p>
                     <p>For import operations, all dump files must be specified at the time the job is defined. </p>
                     <p>Log files and SQL files overwrite previously existing files. For dump files, you can use the Export <code class="codeph">REUSE_DUMPFILES</code> parameter to specify whether to overwrite a preexisting dump file.
                     </p>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-FE7E746D-A343-463E-A4E2-A6AD1349FE4B" title="Oracle Data Pump manages several different types of files. You can use commands in interactive mode to modify how OracleData Pump allocates and handles these files.">File Allocation</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
               <div class="sect3"><a id="GUID-02A2E765-03BA-4097-B3A3-67B006C749AC" name="GUID-02A2E765-03BA-4097-B3A3-67B006C749AC"></a><h4 id="SUTIL-GUID-02A2E765-03BA-4097-B3A3-67B006C749AC" class="sect4"><span class="enumeration_section">1.8.3 </span>Default Locations for Dump, Log, and SQL Files
                  </h4>
                  <div>
                     <p>Review these topics to understand the Oracle Data Pump default file locations, and to understand how these locations are affected when you are using Oracle RAC, Oracle Automatic Storage Management, and multitenant architecture.</p>
                     <p></p>
                  </div>
                  <div>
                     <ul class="ullinks">
                        <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-EEB32B50-8A00-40B0-8787-CC2C8BA05DC5">Understanding Dump, Log, and SQL File Default Locations</a><br>Data Pump is server-based rather than client-based. Dump files, log files, and SQL files are accessed relative to server-based directory paths.
                        </li>
                        <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-8E63A90B-8E72-4E94-B2F4-41CF0603293E">Understanding How to Use Oracle Data Pump with Oracle RAC</a><br>Using Oracle Data Pump in an Oracle Real Application Clusters (Oracle RAC) environment requires you to perform a few checks to make sure that you are making cluster member nodes available. 
                        </li>
                        <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-1A269231-3365-4A3B-B838-649AAC2766CB">Using Directory Objects When Oracle Automatic Storage Management Is Enabled</a><br>You can use Data Pump Export or Import with Oracle Automatic Storage Management (Oracle ASM) enabled. You must define the directory object used for the dump file so that the Oracle ASM disk group name is used, instead of an operating system directory path.
                        </li>
                        <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-BB478188-0F26-44E3-99E6-C161ED5A2473">The DATA_PUMP_DIR Directory Object and Pluggable Databases</a><br>The default Data Pump directory object, <code class="codeph">DATA_PUMP_DIR</code>, is defined as a unique path for each PDB in the CDB.
                        </li>
                     </ul>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-FE7E746D-A343-463E-A4E2-A6AD1349FE4B" title="Oracle Data Pump manages several different types of files. You can use commands in interactive mode to modify how OracleData Pump allocates and handles these files.">File Allocation</a></p>
                        </div>
                     </div>
                  </div>
                  <a id="SUTIL819"></a><div class="props_rev_3"><a id="GUID-EEB32B50-8A00-40B0-8787-CC2C8BA05DC5" name="GUID-EEB32B50-8A00-40B0-8787-CC2C8BA05DC5"></a><h5 id="SUTIL-GUID-EEB32B50-8A00-40B0-8787-CC2C8BA05DC5" class="sect5"><span class="enumeration_section">1.8.3.1 </span>Understanding Dump, Log, and SQL File Default Locations
                     </h5>
                     <div>
                        <p>Data Pump is server-based rather than client-based. Dump files, log files, and SQL files are accessed relative to server-based directory paths.</p>
                        <p>Data Pump requires that directory paths be specified as directory objects. A directory object maps a name to a directory path on the file system. DBAs must ensure that only approved users are allowed access to the directory object associated with the directory path.</p>
                        <p>The following example shows a SQL statement that creates a directory object named <code class="codeph">dpump_dir1</code> that is mapped to a directory located at <code class="codeph">/usr/apps/datafiles.</code></p><pre class="oac_no_warn" dir="ltr">SQL&gt; CREATE DIRECTORY dpump_dir1 AS '/usr/apps/datafiles';
</pre><p>The reason that a directory object is required is to ensure data security and integrity. For example:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>If you were allowed to specify a directory path location for an input file, then you might be able to read data that the server has access to, but to which you should not. </p>
                           </li>
                           <li>
                              <p>If you were allowed to specify a directory path location for an output file, then the server might overwrite a file that you might not normally have privileges to delete.</p>
                           </li>
                        </ul>
                        <p>On UNIX and Windows operating systems, a default directory object, <code class="codeph">DATA_PUMP_DIR</code>, is created at database creation or whenever the database dictionary is upgraded. By default, it is available only to privileged users. (The user <code class="codeph">SYSTEM</code> has read and write access to the <code class="codeph">DATA_PUMP_DIR</code> directory, by default.) The definition of the <code class="codeph">DATA_PUMP_DIR</code> directory may be changed by Oracle during upgrades or when patches are applied.
                        </p>
                        <p>If you are not a privileged user, then before you can run Data Pump Export or Data Pump Import, a directory object must be created by a database administrator (DBA) or by any user with the <code class="codeph">CREATE</code> <code class="codeph">ANY</code> <code class="codeph">DIRECTORY</code> privilege.
                        </p>
                        <p>After a directory is created, the user creating the directory object must grant <code class="codeph">READ</code> or <code class="codeph">WRITE</code> permission on the directory to other users. For example, to allow the Oracle database to read and write files on behalf of user <code class="codeph">hr</code> in the directory named by <code class="codeph">dpump_dir1</code>, the DBA must execute the following command:
                        </p><pre class="oac_no_warn" dir="ltr">SQL&gt; GRANT READ, WRITE ON DIRECTORY dpump_dir1 TO hr;
</pre><p>Note that <code class="codeph">READ</code> or <code class="codeph">WRITE</code> permission to a directory object only means that the Oracle database can read or write files in the corresponding directory on your behalf. You are not given direct access to those files outside of the Oracle database unless you have the appropriate operating system privileges. Similarly, the Oracle database requires permission from the operating system to read and write files in the directories.
                        </p>
                        <p>Data Pump Export and Import use the following order of precedence to determine a file's location:</p>
                        <ol>
                           <li>
                              <p>If a directory object is specified as part of the file specification, then the location specified by that directory object is used. (The directory object must be separated from the file name by a colon.)</p>
                           </li>
                           <li>
                              <p>If a directory object is not specified as part of the file specification, then the directory object named by the <code class="codeph">DIRECTORY</code> parameter is used.
                              </p>
                           </li>
                           <li>
                              <p>If a directory object is not specified as part of the file specification, and if no directory object is named by the <code class="codeph">DIRECTORY</code> parameter, then the value of the environment variable, <code class="codeph">DATA_PUMP_DIR</code>, is used. This environment variable is defined using operating system commands on the client system where the Data Pump Export and Import utilities are run. The value assigned to this client-based environment variable must be the name of a server-based directory object, which must first be created on the server system by a DBA. For example, the following SQL statement creates a directory object on the server system. The name of the directory object is <code class="codeph">DUMP_FILES1</code>, and it is located at<code class="codeph"> '/usr/apps/dumpfiles1'</code>. 
                              </p><pre class="oac_no_warn" dir="ltr">SQL&gt; CREATE DIRECTORY DUMP_FILES1 AS '/usr/apps/dumpfiles1';
</pre><p>Then, a user on a UNIX-based client system using <code class="codeph">csh</code> can assign the value <code class="codeph">DUMP_FILES1</code> to the environment variable <code class="codeph">DATA_PUMP_DIR</code>. The <code class="codeph">DIRECTORY</code> parameter can then be omitted from the command line. The dump file <code class="codeph">employees.dmp</code>, and the log file<code class="codeph"> export.log</code>, are written to<code class="codeph"> '/usr/apps/dumpfiles1'</code>.   
                              </p><pre class="oac_no_warn" dir="ltr">%setenv DATA_PUMP_DIR DUMP_FILES1
%expdp hr TABLES=employees DUMPFILE=employees.dmp
</pre></li>
                           <li>
                              <p>If none of the previous three conditions yields a directory object and you are a privileged user, then Data Pump attempts to use the value of the default server-based directory object, <code class="codeph">DATA_PUMP_DIR</code>. This directory object is automatically created at database creation or when the database dictionary is upgraded. You can use the following SQL query to see the path definition for <code class="codeph">DATA_PUMP_DIR</code>:
                              </p><pre class="oac_no_warn" dir="ltr">SQL&gt; SELECT directory_name, directory_path FROM dba_directories
2 WHERE directory_name='DATA_PUMP_DIR';
</pre><p>If you are not a privileged user, then access to the <code class="codeph">DATA_PUMP_DIR</code> directory object must have previously been granted to you by a DBA. 
                              </p>
                              <p>Do not confuse the default <code class="codeph">DATA_PUMP_DIR</code> directory object with the client-based environment variable of the same name.
                              </p>
                           </li>
                        </ol>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-02A2E765-03BA-4097-B3A3-67B006C749AC" title="Review these topics to understand the Oracle Data Pump default file locations, and to understand how these locations are affected when you are using Oracle RAC, Oracle Automatic Storage Management, and multitenant architecture.">Default Locations for Dump, Log, and SQL Files</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div><a id="SUTIL3755"></a><div class="props_rev_3"><a id="GUID-8E63A90B-8E72-4E94-B2F4-41CF0603293E" name="GUID-8E63A90B-8E72-4E94-B2F4-41CF0603293E"></a><h5 id="SUTIL-GUID-8E63A90B-8E72-4E94-B2F4-41CF0603293E" class="sect5"><span class="enumeration_section">1.8.3.2 </span>Understanding How to Use Oracle Data Pump with Oracle RAC
                     </h5>
                     <div>
                        <p>Using Oracle Data Pump in an Oracle Real Application Clusters (Oracle RAC) environment requires you to perform a few checks to make sure that you are making cluster member nodes available. </p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>To use Data Pump or external tables in an Oracle RAC configuration, you must ensure that the directory object path is on a cluster-wide file system.</p>
                              <p>The directory object must point to shared physical storage that is visible to, and accessible from, all instances where Data Pump and/or external tables processes can run.</p>
                           </li>
                           <li>
                              <p>The default Data Pump behavior is that worker processes can run on any instance in an Oracle RAC configuration. Therefore, workers on those Oracle RAC instances must have physical access to the location defined by the directory object, such as shared storage media. If the configuration does not have shared storage for this purpose, but you still require parallelism, then you can use the <code class="codeph">CLUSTER=NO</code> parameter to constrain all worker processes to the instance where the Data Pump job was started.
                              </p>
                           </li>
                           <li>
                              <p>Under certain circumstances, Data Pump uses parallel query slaves to load or unload data. In an Oracle RAC environment, Data Pump does not control where these slaves run. Therefore, these slaves can run on other cluster member nodes in the cluster, regardless of which instance is specified for <code class="codeph">CLUSTER</code> and <code class="codeph">SERVICE_NAME</code> for the Data Pump job. Controls for parallel query operations are independent of Data Pump. When parallel query slaves run on other instances as part of a Data Pump job, they also require access to the physical storage of the dump file set.
                              </p>
                           </li>
                        </ul>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-02A2E765-03BA-4097-B3A3-67B006C749AC" title="Review these topics to understand the Oracle Data Pump default file locations, and to understand how these locations are affected when you are using Oracle RAC, Oracle Automatic Storage Management, and multitenant architecture.">Default Locations for Dump, Log, and SQL Files</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div><a id="SUTIL820"></a><div class="props_rev_3"><a id="GUID-1A269231-3365-4A3B-B838-649AAC2766CB" name="GUID-1A269231-3365-4A3B-B838-649AAC2766CB"></a><h5 id="SUTIL-GUID-1A269231-3365-4A3B-B838-649AAC2766CB" class="sect5"><span class="enumeration_section">1.8.3.3 </span>Using Directory Objects When Oracle Automatic Storage Management Is Enabled
                     </h5>
                     <div>
                        <p>You can use Data Pump Export or Import with Oracle Automatic Storage Management (Oracle ASM) enabled. You must define the directory object used for the dump file so that the Oracle ASM disk group name is used, instead of an operating system directory path.</p>
                        <div class="section">
                           <p>For log file, use a separate directory object that points to an operating system directory path. </p>
                        </div>
                        <!-- class="section" -->
                        <div class="example" id="GUID-1A269231-3365-4A3B-B838-649AAC2766CB__GUID-AEC0C77B-9277-446A-A2F7-AF942E0B3BAE">
                           <p>For example, you can create a directory object for the Oracle ASM dump file using this procedure. </p><pre class="pre codeblock"><code>SQL&gt; CREATE or REPLACE DIRECTORY dpump_dir as '+DATAFILES/';
</code></pre><p>After you create the directory object, you then create a separate directory object for the log file:</p><pre class="pre codeblock"><code>SQL&gt; CREATE or REPLACE DIRECTORY dpump_log as '/homedir/user1/';
</code></pre><p>To enable user <code class="codeph">hr</code> to have access to these directory objects, you assign the necessary privileges for that user:
                           </p><pre class="oac_no_warn" dir="ltr">SQL&gt; GRANT READ, WRITE ON DIRECTORY dpump_dir TO hr;
SQL&gt; GRANT READ, WRITE ON DIRECTORY dpump_log TO hr;
</pre><p>Finally, you then can use use the following Data Pump Export command:</p><pre class="pre codeblock"><code>&gt; expdp hr DIRECTORY=dpump_dir DUMPFILE=hr.dmp LOGFILE=dpump_log:hr.log</code></pre><p>Before the command executes, you are prompted for the password.</p>
                           <div class="infoboxnote" id="GUID-1A269231-3365-4A3B-B838-649AAC2766CB__GUID-8DF266E3-743D-4012-B2D4-42EA45D19979">
                              <p class="notep1">Note:</p>
                              <p>If you simply want to copy Data Pump dump files between ASM and disk directories, you can use the <code class="codeph">DBMS_FILE_TRANSFER</code> PL/SQL package.
                              </p>
                           </div>
                        </div>
                        <!-- class="example" -->
                     </div>
                     <div>
                        <div class="relinfo">
                           <p><strong>Related Topics</strong></p>
                           <ul>
                              <li><a href="../sqlrf/CREATE-DIRECTORY.html#SQLRF01207" target="_blank"><span><cite>Oracle Database SQL Language Reference</cite></span></a></li>
                              <li><a href="../arpls/DBMS_FILE_TRANSFER.html#ARPLS095" target="_blank"><span><cite>Oracle Database PL/SQL Packages and Types Reference</cite></span></a></li>
                           </ul>
                        </div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-02A2E765-03BA-4097-B3A3-67B006C749AC" title="Review these topics to understand the Oracle Data Pump default file locations, and to understand how these locations are affected when you are using Oracle RAC, Oracle Automatic Storage Management, and multitenant architecture.">Default Locations for Dump, Log, and SQL Files</a></p>
                           </div>
                        </div>
                     </div>
                  </div><a id="SUTIL4337"></a><div class="props_rev_3"><a id="GUID-BB478188-0F26-44E3-99E6-C161ED5A2473" name="GUID-BB478188-0F26-44E3-99E6-C161ED5A2473"></a><h5 id="SUTIL-GUID-BB478188-0F26-44E3-99E6-C161ED5A2473" class="sect5"><span class="enumeration_section">1.8.3.4 </span>The DATA_PUMP_DIR Directory Object and Pluggable Databases
                     </h5>
                     <div>
                        <p>The default Data Pump directory object, <code class="codeph">DATA_PUMP_DIR</code>, is defined as a unique path for each PDB in the CDB.
                        </p>
                        <p>As of Oracle Database 12<code class="codeph">c</code> release 2 (12.2), in a multitenant container database (CDB) environment, the default Data Pump directory object, <code class="codeph">DATA_PUMP_DIR</code>, is defined as a unique path for each PDB in the CDB, whether or not the <code class="codeph">PATH_PREFIX</code> clause of the <code class="codeph">CREATE PLUGGABLE DATABASE</code> statement is defined for relative paths. 
                        </p>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-02A2E765-03BA-4097-B3A3-67B006C749AC" title="Review these topics to understand the Oracle Data Pump default file locations, and to understand how these locations are affected when you are using Oracle RAC, Oracle Automatic Storage Management, and multitenant architecture.">Default Locations for Dump, Log, and SQL Files</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
               </div><a id="SUTIL822"></a><div class="props_rev_3"><a id="GUID-6F532CA9-CE90-47D6-84ED-AD10F1E18056" name="GUID-6F532CA9-CE90-47D6-84ED-AD10F1E18056"></a><h4 id="SUTIL-GUID-6F532CA9-CE90-47D6-84ED-AD10F1E18056" class="sect4"><span class="enumeration_section">1.8.4 </span>Using Substitution Variables
                  </h4>
                  <div>
                     <p>Instead of, or in addition to, listing specific file names, you can use the <code class="codeph">DUMPFILE</code> parameter during export operations to specify multiple dump files, by using a substitution variable in the file name. This is called a dump file template.
                     </p>
                     <div class="infoboxnote" id="GUID-6F532CA9-CE90-47D6-84ED-AD10F1E18056__GUID-80197391-6DE8-4FF7-90F0-C472D3D11095">
                        <p class="notep1">Note:</p>This section uses %U to explain how Data Pump uses substitution variables. For information about other available substitution variables, see the Data Pump Export <a href="oracle-data-pump-export-utility.html#GUID-A6300021-419F-4C1D-AFF1-38FE1123326B" title="The Data Pump Export command-line utility DUMPFILE parameter specifies the names, and optionally, the directory objects of dump files for an export job.">DUMPFILE</a> parameter and the Data Pump Import <a href="datapump-import-utility.html#GUID-DE156692-2955-4D5B-A327-C421F9E45FEB" title="The Data Pump Import command-line mode DUMPFILE parameter specifies the names, and optionally, the directory objects of the dump file set that Export created.">DUMPFILE</a> parameter.
                     </div>
                     <p>New dump files are created as they are needed. For example, if you are using the substitution variable %U, then new dump files are created as needed beginning with <code class="codeph">01</code> for <code class="codeph">%U</code>, then using <code class="codeph">02</code>, <code class="codeph">03</code>, and so on. Enough dump files are created to allow all processes specified by the current setting of the <code class="codeph">PARALLEL</code> parameter to be active. If one of the dump files becomes full because its size has reached the maximum size specified by the <code class="codeph">FILESIZE</code> parameter, then it is closed and a new dump file (with a new generated name) is created to take its place. 
                     </p>
                     <p>If multiple dump file templates are provided, they are used to generate dump files in a round-robin fashion. For example, if <code class="codeph">expa%U</code>, <code class="codeph">expb%U,</code> and <code class="codeph">expc%U</code> were all specified for a job having a parallelism of 6, then the initial dump files created would be <code class="codeph">expa01</code>.<code class="codeph">dmp</code>, <code class="codeph">expb01</code>.<code class="codeph">dmp</code>, <code class="codeph">expc01</code>.<code class="codeph">dmp</code>, <code class="codeph">expa02</code>.<code class="codeph">dmp</code>, <code class="codeph">expb02</code>.<code class="codeph">dmp</code>, and <code class="codeph">expc02</code>.<code class="codeph">dmp</code>.
                     </p>
                     <p>For import and SQLFILE operations, if dump file specifications <code class="codeph">expa%U</code>, <code class="codeph">expb%U,</code> and <code class="codeph">expc%U</code> are specified, then the operation begins by attempting to open the dump files <code class="codeph">expa01</code>.<code class="codeph">dmp</code>, <code class="codeph">expb01</code>.<code class="codeph">dmp</code>, and <code class="codeph">expc01</code>.<code class="codeph">dmp</code>. It is possible for the master table to span multiple dump files, so until all pieces of the master table are found, dump files continue to be opened by incrementing the substitution variable and looking up the new file names (for example, <code class="codeph">expa02</code>.<code class="codeph">dmp</code>, <code class="codeph">expb02</code>.<code class="codeph">dmp</code>, and <code class="codeph">expc02</code>.<code class="codeph">dmp</code>). If a dump file does not exist, then the operation stops incrementing the substitution variable for the dump file specification that was in error. For example, if <code class="codeph">expb01</code>.<code class="codeph">dmp</code> and <code class="codeph">expb02</code>.<code class="codeph">dmp</code> are found but <code class="codeph">expb03</code>.<code class="codeph">dmp</code> is not found, then no more files are searched for using the <code class="codeph">expb%U</code> specification. Once the entire master table is found, it is used to determine whether all dump files in the dump file set have been located.
                     </p>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-FE7E746D-A343-463E-A4E2-A6AD1349FE4B" title="Oracle Data Pump manages several different types of files. You can use commands in interactive mode to modify how OracleData Pump allocates and handles these files.">File Allocation</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
            </div><a id="SUTIL110"></a><div class="props_rev_3"><a id="GUID-BAA3B679-A758-4D55-9820-432D9EB83C68" name="GUID-BAA3B679-A758-4D55-9820-432D9EB83C68"></a><h3 id="SUTIL-GUID-BAA3B679-A758-4D55-9820-432D9EB83C68" class="sect3"><span class="enumeration_section">1.9 </span>Exporting and Importing Between Different Oracle Database Releases
               </h3>
               <div>
                  <p>You can use Oracle Data Pump to migrate all or any portion of an Oracle Database between different releases of the database software.</p>
                  <p>Typically, you use the Oracle Data Pump Export <code class="codeph">VERSION</code> parameter to migrate between database releases.Using <code class="codeph">VERSION</code> generates an Oracle Data Pump dump file set that is compatible with the specified version.
                  </p>
                  <p>The default value for <code class="codeph">VERSION</code> is <code class="codeph">COMPATIBLE</code>. This value indicates that exported database object definitions are compatible with the release specified for the <code class="codeph">COMPATIBLE</code> initialization parameter.
                  </p>
                  <p>In an upgrade situation, when the target release of an Oracle Data Pump-based migration is higher than the source, you typically do not have to specify the <code class="codeph">VERSION</code> parameter. When the target release is higher then the source, all objects in the source database are compatible with the higher target release. However,  an exception is when an entire Oracle Database 11g (Release 11.2.0.3 or higher) is exported in preparation for importing into Oracle Database 12c Release 1 (12.1.0.1) or later. In this case, to include a complete set of Oracle Database internal component metadata, explicitly specify <code class="codeph">VERSION=12</code> with <code class="codeph">FULL=YES</code>.
                  </p>
                  <p>In a downgrade situation, when the target release of an Oracle Data Pump-based migration is lower than the source, set the <code class="codeph">VERSION</code> parameter value to be the same version as the target. An exception is when the target release version is the same as the value of the <code class="codeph">COMPATIBLE</code> initialization parameter on the source system. In that case, you do not need to specify <code class="codeph">VERSION</code>. In general, however, Oracle Data Pump import cannot read dump file sets created by an Oracle Database release that is newer than the current release,  unless you explicitly specify the <code class="codeph">VERSION</code> parameter.
                  </p>
                  <p>Keep the following information in mind when you are exporting and importing between different database releases:</p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p>On an Oracle Data Pump export, if you specify a database version that is older than the current database version, then a dump file set is created that you can import into that older version of the database. For example, if you are running Oracle Database 12c Release 1 (12.1.0.2), and you specify <code class="codeph">VERSION=11.2</code> on an export, then the dump file set that is created can be imported into an Oracle Database 11g (Release 11.2)  database.
                        </p>
                        <div class="infoboxnote" id="GUID-BAA3B679-A758-4D55-9820-432D9EB83C68__GUID-CEF899D4-95B6-4A14-8992-944B04D1CFA8">
                           <p class="notep1">Note:</p>
                           <ul style="list-style-type: disc;">
                              <li>
                                 <p>Database privileges that are valid only in Oracle Database 12c Release 1 (12.1.0.2) and later (for example, the <code class="codeph">READ</code> privilege on tables, views, materialized views, and synonyms) cannot be imported into Oracle Database 12c Release 1 (12.1.0.1) or earlier. If an attempt is made to do so, then Import reports it as an error, and continues the import operation.
                                 </p>
                              </li>
                              <li>
                                 <p> When you export to a release earlier than Oracle Database 12c Release 2 (12.2.0.1), Oracle Data Pump does not filter out object names longer than 30 bytes. The objects are exported. At import time, if you attempt to create an object with a name longer than 30 bytes, then an error is returned. </p>
                              </li>
                           </ul>
                        </div>
                     </li>
                     <li>
                        <p>If you specify an Oracle Database release that is older than the current Oracle Database release, then certain features and data types can be unavailable. For example, specifying <code class="codeph">VERSION=10.1</code> causes an error if data compression is also specified for the job, because compression was not supported in Oracle Database 10g release 1 (10.1). Another example: If a user-defined type or Oracle-supplied type in the source Oracle Database release is a later version than the type in the target Oracle Database release, then that type is not loaded, because it does not match any version of the type in the target database. 
                        </p>
                     </li>
                     <li>
                        <p>Oracle Data Pump Import can always read Oracle Data Pump dump file sets created by older Oracle Database releases.</p>
                     </li>
                     <li>
                        <p>When operating across a network link, Oracle Data Pump requires that the source and target Oracle Database releases differ by no more than two versions. </p>
                        <p>For example, if one database is Oracle Database 12c, then the other Oracle Database release must be 12c, 11g, or 10g. Oracle Data Pump checks only the major version number (for example, 10g,11g, 12c), not specific Oracle Database release numbers (for example, 12.2, 12.1, 11.1, 11.2, 10.1, or 10.2).</p>
                     </li>
                     <li>
                        <p>Importing Oracle Database 11g dump files that contain table statistics into Oracle Database 12c Release 1 (12.1) or later Oracle Database releases can result in an Oracle ORA-39346 error. This error occurs because Oracle Database 11g dump files contain table statistics as metadata. Oracle Database 12c Release 1 (12.1) and later releases require table statistics to be presented as table data. The workaround is to ignore the error during the import operation. After the import operation completes, regather table statistics. </p>
                     </li>
                  </ul>
               </div>
               <div>
                  <div class="relinfo">
                     <p><strong>Related Topics</strong></p>
                     <ul>
                        <li><a href="oracle-data-pump-export-utility.html#GUID-2877B4DB-0082-438F-AC9B-18D1686F5DDC">VERSION</a></li>
                        <li><a href="datapump-import-utility.html#GUID-A5B19146-2CAA-47E7-8AE5-57A05E3347F6">VERSION</a></li>
                     </ul>
                  </div>
                  <div class="infoboxnotealso" id="GUID-BAA3B679-A758-4D55-9820-432D9EB83C68__GUID-DFB580D8-F11A-43A4-BCE7-74AFC99CE772">
                     <p class="notep1">See Also:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><a href="../dbseg/configuring-privilege-and-role-authorization.html#DBSEG992" target="_blank"><span class="italic">Oracle Database Security Guide</span></a> for more information about the <code class="codeph">READ</code> and <code class="codeph">READ ANY TABLE</code> privileges
                           </p>
                        </li>
                     </ul>
                  </div>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-17FAE261-0972-4220-A2E4-44D479F519D4" title="Oracle Data Pump technology enables very high-speed movement of data and metadata from one database to another.">Overview of Oracle Data Pump</a></p>
                     </div>
                  </div>
               </div>
            </div><a id="SUTIL2883"></a><div class="props_rev_3"><a id="GUID-9030BC32-193B-4455-8DBB-4271DD44FA7A" name="GUID-9030BC32-193B-4455-8DBB-4271DD44FA7A"></a><h3 id="SUTIL-GUID-9030BC32-193B-4455-8DBB-4271DD44FA7A" class="sect3"><span class="enumeration_section">1.10 </span>SecureFiles LOB Considerations
               </h3>
               <div>
                  <p>When you use Oracle Data Pump Export to export SecureFiles LOBs, the export behavior depends on several things, including the Export <code class="codeph">VERSION</code> parameter value, whether ContentType is present, and whether the LOB is archived and data is cached.
                  </p>
                  <p></p>
                  <p>The following scenarios cover different combinations of these variables:</p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p>If a table contains SecureFiles LOBs with ContentType and the Export <code class="codeph">VERSION</code> parameter is set to a value earlier than <code class="codeph">11.2.0.0.0</code>, then the ContentType is not exported.
                        </p>
                     </li>
                     <li>
                        <p>If a table contains SecureFiles LOBs with ContentType and the Export <code class="codeph">VERSION</code> parameter is set to a value of <code class="codeph">11.2.0.0.0</code> or later, then the ContentType is exported and restored on a subsequent import.
                        </p>
                     </li>
                     <li>
                        <p>If a table contains a SecureFiles LOB that is currently archived and the data is cached, and the Export <code class="codeph">VERSION</code> parameter is set to a value earlier than <code class="codeph">11.2.0.0.0</code>, then the SecureFiles LOB data is exported and the archive metadata is dropped. In this scenario, if <code class="codeph">VERSION</code> is set to <code class="codeph">11.1</code> or later, then the SecureFiles LOB becomes a vanilla SecureFiles LOB. But if <code class="codeph">VERSION</code> is set to a value earlier than <code class="codeph">11.1</code>, then the SecureFiles LOB becomes a BasicFiles LOB.
                        </p>
                     </li>
                     <li>
                        <p>If a table contains a SecureFiles LOB that is currently archived but the data is not cached, and the Export <code class="codeph">VERSION</code> parameter is set to a value earlier than <code class="codeph">11.2.0.0.0</code>, then an ORA-45001 error is returned.
                        </p>
                     </li>
                     <li>
                        <p>If a table contains a SecureFiles LOB that is currently archived and the data is cached, and the Export <code class="codeph">VERSION</code> parameter is set to a value of <code class="codeph">11.2.0.0.0</code> or later, then both the cached data and the archive metadata is exported.
                        </p>
                     </li>
                  </ul>
               </div>
               <div>
                  <div class="infoboxnotealso" id="GUID-9030BC32-193B-4455-8DBB-4271DD44FA7A__GUID-327BEFAE-B5E2-437C-B9AF-01911E9AE56D">
                     <p class="notep1">See Also:</p>
                     <p><a href="../adlob/using-oracle-LOBs-storage.html#ADLOB4444" target="_blank"><span><cite>Oracle Database SecureFiles and Large Objects Developer's Guide</cite></span></a> for more information about SecureFiles
                     </p>
                  </div>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-17FAE261-0972-4220-A2E4-44D479F519D4" title="Oracle Data Pump technology enables very high-speed movement of data and metadata from one database to another.">Overview of Oracle Data Pump</a></p>
                     </div>
                  </div>
               </div>
               
            </div><a id="SUTIL3835"></a><a id="SUTIL3834"></a><div class="props_rev_3"><a id="GUID-34D0DEE7-3530-42DC-BE01-C2588CC73CE5" name="GUID-34D0DEE7-3530-42DC-BE01-C2588CC73CE5"></a><h3 id="SUTIL-GUID-34D0DEE7-3530-42DC-BE01-C2588CC73CE5" class="sect3"><span class="enumeration_section">1.11 </span>Oracle Data Pump Exit Codes
               </h3>
               <div>
                  <p>You can review Oracle Data Pump export and import operation results in a log file, and in a process exit code.</p>
                  <div class="section">
                     <p>Oracle Data Pump provides the results of export and import operations immediately upon completion. In addition to recording the results in a log file, Oracle Data Pump can also report the outcome in a process exit code. Use the Oracle Data Pump exit code to check the outcome of an Oracle Data Pump job from the command line or a script:</p>
                     <div class="tblformalwide" id="GUID-34D0DEE7-3530-42DC-BE01-C2588CC73CE5__BABICAEC">
                        <p class="titleintable">Table 1-1 Data Pump Exit Codes </p>
                        <table cellpadding="4" cellspacing="0" class="FormalWide" title="Data Pump Exit Codes " summary="Data Pump Exit Codes for Linux, Unix, and Windows" width="100%" frame="hsides" border="1" rules="rows">
                           <thead>
                              <tr align="left" valign="top">
                                 <th align="left" valign="bottom" width="29%" id="d10392e3670">Exit Code</th>
                                 <th align="left" valign="bottom" width="71%" id="d10392e3673">Meaning</th>
                              </tr>
                           </thead>
                           <tbody>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="29%" id="d10392e3678" headers="d10392e3670 ">
                                    <p><code class="codeph">EX_SUCC 0</code></p>
                                 </td>
                                 <td align="left" valign="top" width="71%" headers="d10392e3678 d10392e3673 ">
                                    <p>The export or import job completed successfully. No errors are displayed to the output device or recorded in the log file, if there is one.</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="29%" id="d10392e3686" headers="d10392e3670 ">
                                    <p><code class="codeph">EX_SUCC_ERR 5</code></p>
                                 </td>
                                 <td align="left" valign="top" width="71%" headers="d10392e3686 d10392e3673 ">
                                    <p>The export or import job completed successfully, but there were errors encountered during the job. The errors are displayed to the output device and recorded in the log file, if there is one.</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="29%" id="d10392e3694" headers="d10392e3670 ">
                                    <p><code class="codeph">EX_FAIL 1</code></p>
                                 </td>
                                 <td align="left" valign="top" width="71%" headers="d10392e3694 d10392e3673 ">
                                    <p>The export or import job encountered one or more fatal errors, including the following:</p>
                                    <ul style="list-style-type: disc;">
                                       <li>
                                          <p>Errors on the command line or in command syntax</p>
                                       </li>
                                       <li>
                                          <p>Oracle database errors from which export or import cannot recover</p>
                                       </li>
                                       <li>
                                          <p>Operating system errors (such as malloc)</p>
                                       </li>
                                       <li>
                                          <p>Invalid parameter values that prevent the job from starting (for example, an invalid directory object specified in the <code class="codeph">DIRECTORY</code> parameter)
                                          </p>
                                       </li>
                                    </ul>
                                    <p>A fatal error is displayed to the output device but may not be recorded in the log file. Whether it is recorded in the log file can depend on several factors, including:</p>
                                    <ul style="list-style-type: disc;">
                                       <li>
                                          <p>Was a log file specified at the start of the job?</p>
                                       </li>
                                       <li>
                                          <p>Did the processing of the job proceed far enough for a log file to be opened?</p>
                                       </li>
                                    </ul>
                                 </td>
                              </tr>
                           </tbody>
                        </table>
                     </div>
                     <!-- class="inftblhruleinformal" -->
                  </div>
                  <!-- class="section" -->
               </div>
               <div>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-17FAE261-0972-4220-A2E4-44D479F519D4" title="Oracle Data Pump technology enables very high-speed movement of data and metadata from one database to another.">Overview of Oracle Data Pump</a></p>
                     </div>
                  </div>
               </div>
               
            </div><a id="SUTIL4280"></a><div class="props_rev_3"><a id="GUID-4443B80B-0446-4010-B8CA-2524659516BC" name="GUID-4443B80B-0446-4010-B8CA-2524659516BC"></a><h3 id="SUTIL-GUID-4443B80B-0446-4010-B8CA-2524659516BC" class="sect3"><span class="enumeration_section">1.12 </span>Auditing Data Pump Jobs
               </h3>
               <div>
                  <p>To monitor and record specific user database actions, perform auditing on Data Pump jobs with unified auditing.</p>
                  <div class="section">
                     <p>You can perform auditing on Data Pump jobs to monitor and record specific user database actions. Data Pump uses unified auditing, in which all audit records are centralized in one place.</p>
                     <p>To set up unified auditing, you create a unified audit policy or alter an existing policy. An audit policy is a named group of audit settings that enable you to audit a particular aspect of user behavior in the database. To create the policy, use the SQL <code class="codeph">CREATE AUDIT POLICY</code> statement.
                     </p>
                     <p>After creating the audit policy, use the <code class="codeph">AUDIT</code> and <code class="codeph">NOAUDIT</code> SQL statements to, respectively, enable and disable the policy.
                     </p>
                  </div>
                  <!-- class="section" -->
               </div>
               <div>
                  <div class="infoboxnotealso" id="GUID-4443B80B-0446-4010-B8CA-2524659516BC__GUID-9E9A3DDD-CFA5-4F37-A0BA-B204B344120B">
                     <p class="notep1">See Also:</p>
                     <p></p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p><a href="../sqlrf/CREATE-AUDIT-POLICY-Unified-Auditing.html#SQLRF56055" target="_blank"><span><cite>Oracle Database SQL Language Reference</cite></span></a> for more information about the SQL <code class="codeph">CREATE AUDIT POLICY,ALTER AUDIT POLICY, AUDIT,</code> and <code class="codeph">NOAUDIT</code> statements
                           </p>
                        </li>
                        <li>
                           <p><a href="https://www.oracle.com/pls/topic/lookup?ctx=en/database/oracle/oracle-database/19/sutil&amp;id=DBSEG006" target="_blank"><span><cite>Oracle Database Security Guide</cite></span></a> for more information about using auditing in an Oracle database
                           </p>
                        </li>
                     </ul>
                  </div>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-17FAE261-0972-4220-A2E4-44D479F519D4" title="Oracle Data Pump technology enables very high-speed movement of data and metadata from one database to another.">Overview of Oracle Data Pump</a></p>
                     </div>
                  </div>
               </div>
               
            </div><a id="SUTIL4292"></a><div class="props_rev_3"><a id="GUID-7EE60BAB-0D3D-46EB-8E11-4FDDA68EF14E" name="GUID-7EE60BAB-0D3D-46EB-8E11-4FDDA68EF14E"></a><h3 id="SUTIL-GUID-7EE60BAB-0D3D-46EB-8E11-4FDDA68EF14E" class="sect3"><span class="enumeration_section">1.13 </span>How Does Data Pump Handle Timestamp Data?
               </h3>
               <div>
                  <p>This section describes factors that can affect successful completion of export and import jobs that involve the timestamp data types <code class="codeph">TIMESTAMP WITH TIMEZONE</code> and <code class="codeph">TIMESTAMP WITH LOCAL TIMEZONE</code>.
                  </p>
                  <div class="infoboxnote" id="GUID-7EE60BAB-0D3D-46EB-8E11-4FDDA68EF14E__GUID-65C5A862-FA8A-4237-9D33-07B06BEAD85D">
                     <p class="notep1">Note:</p>
                     <p>The information in this section applies only to Oracle Data Pump running on Oracle Database 12<span class="italic">c</span> and later.
                     </p>
                  </div>
               </div>
               <div>
                  <ul class="ullinks">
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-9B6C92EE-860E-43DD-9728-735B17B9DA89">TIMESTAMP WITH TIMEZONE Restrictions</a><br>Export and import jobs that have <code class="codeph">TIMESTAMP WITH TIME ZONE</code> data are restricted.
                     </li>
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-D8443A5E-BF6D-4329-AF11-8E5899356C64">TIMESTAMP WITH LOCAL TIME ZONE Restrictions</a><br>Moving tables using a transportable mode is restricted.
                     </li>
                  </ul>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-17FAE261-0972-4220-A2E4-44D479F519D4" title="Oracle Data Pump technology enables very high-speed movement of data and metadata from one database to another.">Overview of Oracle Data Pump</a></p>
                     </div>
                  </div>
               </div>
               
               <div class="sect3"><a id="GUID-9B6C92EE-860E-43DD-9728-735B17B9DA89" name="GUID-9B6C92EE-860E-43DD-9728-735B17B9DA89"></a><h4 id="SUTIL-GUID-9B6C92EE-860E-43DD-9728-735B17B9DA89" class="sect4"><span class="enumeration_section">1.13.1 </span>TIMESTAMP WITH TIMEZONE Restrictions
                  </h4>
                  <div>
                     <p>Export and import jobs that have <code class="codeph">TIMESTAMP WITH TIME ZONE</code> data are restricted.
                     </p>
                     <p></p>
                  </div>
                  <div>
                     <ul class="ullinks">
                        <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-02A6F03E-7754-41B5-A579-93A6E171A61C">Understanding TIMESTAMP WITH TIME ZONE Restrictions</a><br>Carrying out export and import jobs that have <code class="codeph">TIMESTAMP WITH TIME ZONE</code> data requires understanding information about your time zone file data and Oracle Database release.
                        </li>
                        <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-EF3AF1D8-716B-4C3E-931D-52937A5175F1">Data Pump Support for TIMESTAMP WITH TIME ZONE Data</a><br>Data Pump supports <code class="codeph">TIMESTAMP WITH TIME ZONE</code> data during different export and import modes like non-transportable mode, transportable tablespace and transportable table mode, and full transportable mode.
                        </li>
                        <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-4DABDB38-BEAA-471B-9026-F91CD22FD5C4">Time Zone File Versions on the Source and Target</a><br>Successful job completion can depend on whether the source and target time zone file versions match.
                        </li>
                     </ul>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-7EE60BAB-0D3D-46EB-8E11-4FDDA68EF14E" title="This section describes factors that can affect successful completion of export and import jobs that involve the timestamp data types TIMESTAMP WITH TIMEZONE and TIMESTAMP WITH LOCAL TIMEZONE.">How Does Data Pump Handle Timestamp Data?</a></p>
                        </div>
                     </div>
                  </div>
                  <a id="SUTIL4320"></a><div class="props_rev_3"><a id="GUID-02A6F03E-7754-41B5-A579-93A6E171A61C" name="GUID-02A6F03E-7754-41B5-A579-93A6E171A61C"></a><h5 id="SUTIL-GUID-02A6F03E-7754-41B5-A579-93A6E171A61C" class="sect5"><span class="enumeration_section">1.13.1.1 </span>Understanding TIMESTAMP WITH TIME ZONE Restrictions
                     </h5>
                     <div>
                        <p>Carrying out export and import jobs that have <code class="codeph">TIMESTAMP WITH TIME ZONE</code> data requires understanding information about your time zone file data and Oracle Database release.
                        </p>
                        <div class="section">
                           <p>Successful job completion can depend on the following factors:</p>
                           <ul style="list-style-type: disc;">
                              <li>
                                 <p>The version of the Oracle Database time zone files on the source and target databases.</p>
                              </li>
                              <li>
                                 <p>The export/import mode and whether the Data Pump version being used supports <code class="codeph">TIMESTAMP WITH TIME ZONE</code> data. (Data Pump 11.2.0.1 and later provide support for <code class="codeph">TIMESTAMP WITH TIME ZONE</code> data.)
                                 </p>
                              </li>
                           </ul>
                        </div>
                        <!-- class="section" -->
                        <div class="example" id="GUID-02A6F03E-7754-41B5-A579-93A6E171A61C__GUID-BFCD545C-EDE5-4280-9C2B-4B3A0638781F">
                           <p>To identify the time zone file version of a database, you can execute the following SQL statement:</p><pre class="pre codeblock"><code>SQL&gt; SELECT VERSION FROM V$TIMEZONE_FILE;</code></pre></div>
                        <!-- class="example" -->
                        <div class="section">See <cite>Oracle Database Globalization Support Guide</cite> for more information about time zone files. 
                        </div>
                        <!-- class="section" -->
                     </div>
                     <div>
                        <div class="relinfo">
                           <p><strong>Related Topics</strong></p>
                           <ul>
                              <li><a href="../nlspg/datetime-data-types-and-time-zone-support.html#NLSPG258" target="_blank"><span><cite>Oracle Database Globalization Support Guide</cite></span></a></li>
                           </ul>
                        </div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-9B6C92EE-860E-43DD-9728-735B17B9DA89" title="Export and import jobs that have TIMESTAMP WITH TIME ZONE data are restricted.">TIMESTAMP WITH TIMEZONE Restrictions</a></p>
                           </div>
                        </div>
                     </div>
                  </div><a id="SUTIL4323"></a><a id="SUTIL4324"></a><a id="SUTIL4325"></a><a id="SUTIL4322"></a><div class="props_rev_3"><a id="GUID-EF3AF1D8-716B-4C3E-931D-52937A5175F1" name="GUID-EF3AF1D8-716B-4C3E-931D-52937A5175F1"></a><h5 id="SUTIL-GUID-EF3AF1D8-716B-4C3E-931D-52937A5175F1" class="sect5"><span class="enumeration_section">1.13.1.2 </span>Data Pump Support for TIMESTAMP WITH TIME ZONE Data
                     </h5>
                     <div>
                        <p>Data Pump supports <code class="codeph">TIMESTAMP WITH TIME ZONE</code> data during different export and import modes like non-transportable mode, transportable tablespace and transportable table mode, and full transportable mode.
                        </p>
                        <p>This section describes Data Pump support for <code class="codeph">TIMESTAMP WITH TIME ZONE</code> data during different export and import modes when versions of the Oracle Database time zone file are different on the source and target databases.
                        </p>
                        <div class="section">
                           <p class="subhead3" id="GUID-EF3AF1D8-716B-4C3E-931D-52937A5175F1__GUID-B6D7D52C-5A63-4479-B732-8433BC8B155B">Non-transportable Modes</p>
                        </div>
                        <!-- class="section" -->
                        <div class="section">
                           <ul style="list-style-type: disc;">
                              <li>
                                 <p>If the dump file is created with a Data Pump version that supports <code class="codeph">TIMESTAMP WITH TIME ZONE</code> data (11.2.0.1 or later), then the time zone file version of the export system is recorded in the dump file. Data Pump uses that information to determine whether data conversion is necessary. If the target database knows about the source time zone version, but is actually using a later version, then the data is converted to the later version. <code class="codeph">TIMESTAMP WITH TIME ZONE</code> data cannot be downgraded, so if you attempt to import to a target that is using an earlier version of the time zone file than the source used, the import fails.
                                 </p>
                              </li>
                              <li>
                                 <p>If the dump file is created with a Data Pump version prior to Oracle Database 11<span class="italic">g</span> release 2 (11.2.0.1), then <code class="codeph">TIMESTAMP WITH TIME ZONE</code> data is not supported, so no conversion is done and corruption may occur.
                                 </p>
                              </li>
                           </ul>
                        </div>
                        <!-- class="section" -->
                        <div class="section">
                           <p class="subhead3" id="GUID-EF3AF1D8-716B-4C3E-931D-52937A5175F1__GUID-306AD66A-A9D1-4035-ABBD-336770ADE243">Transportable Tablespace and Transportable Table Modes</p>
                        </div>
                        <!-- class="section" -->
                        <div class="section">
                           <ul style="list-style-type: disc;">
                              <li>
                                 <p>In transportable tablespace and transportable table modes, if the source and target have different time zone file versions, then tables with <code class="codeph">TIMESTAMP WITH TIME ZONE</code> columns are not created. A warning is displayed at the beginning of the job showing the source and target database time zone file versions. A message is also displayed for each table not created. This is true even if the Data Pump version used to create the dump file supports <code class="codeph">TIMESTAMP WITH TIME ZONE</code> data. (Release 11.2.0.1 and later support <code class="codeph">TIMESTAMP WITH TIMEZONE</code> data.)
                                 </p>
                              </li>
                              <li>
                                 <p>If the source is earlier than Oracle Database 11<span class="italic">g</span> release 2 (11.2.0.1), then the time zone file version must be the same on the source and target database for all transportable jobs regardless of whether the transportable set uses <code class="codeph">TIMESTAMP WITH TIME ZONE</code> columns.
                                 </p>
                              </li>
                           </ul>
                        </div>
                        <!-- class="section" -->
                        <div class="section">
                           <p class="subhead3" id="GUID-EF3AF1D8-716B-4C3E-931D-52937A5175F1__GUID-4E60A499-6C75-4F94-9CA0-13B1FF70243A">Full Transportable Mode</p>
                        </div>
                        <!-- class="section" -->
                        <div class="section">
                           <p>Full transportable exports and imports are supported when the source database is at least Oracle Database 11<span class="italic">g</span> release 2 (11.2.0.3) and the target is Oracle Database 12c release 1 (12.1) or later.
                           </p>
                           <p>Data Pump 11.2.0.1 and later provide support for <code class="codeph">TIMESTAMP WITH TIME ZONE</code> data. Therefore, in full transportable operations, tables with <code class="codeph">TIMESTAMP WITH TIME ZONE</code> columns are created. If the source and target database have different time zone file versions, then <code class="codeph">TIMESTAMP WITH TIME ZONE</code> columns from the source are converted to the time zone file version of the target.
                           </p>
                        </div>
                        <!-- class="section" -->
                     </div>
                     <div>
                        <div class="infoboxnotealso" id="GUID-EF3AF1D8-716B-4C3E-931D-52937A5175F1__GUID-91544DBB-B246-4082-9F94-304D109C167D">
                           <p class="notep1">See Also:</p>
                           <p></p>
                           <ul style="list-style-type: disc;">
                              <li>
                                 <p><a href="../admin/transporting-data.html#ADMIN10140" target="_blank"><span class="italic">Oracle Database Administrator's Guide</span></a> for more information about transportable tablespaces
                                 </p>
                              </li>
                              <li>
                                 <p><a href="oracle-data-pump-export-utility.html#GUID-079769D8-40F4-432F-88AD-E7264D7A2E2D__BEHFFGJG">Using the Transportable Option During Full Mode Exports</a> for more information about full transportable exports
                                 </p>
                              </li>
                              <li>
                                 <p><a href="datapump-import-utility.html#GUID-E27D2DC9-A6D8-4F0B-AB72-6BF526B3AA18__BEHFEGFI">Using the Transportable Option During Full Mode Imports</a> for more information about full transportable imports
                                 </p>
                              </li>
                           </ul>
                        </div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-9B6C92EE-860E-43DD-9728-735B17B9DA89" title="Export and import jobs that have TIMESTAMP WITH TIME ZONE data are restricted.">TIMESTAMP WITH TIMEZONE Restrictions</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div><a id="SUTIL4321"></a><div class="props_rev_3"><a id="GUID-4DABDB38-BEAA-471B-9026-F91CD22FD5C4" name="GUID-4DABDB38-BEAA-471B-9026-F91CD22FD5C4"></a><h5 id="SUTIL-GUID-4DABDB38-BEAA-471B-9026-F91CD22FD5C4" class="sect5"><span class="enumeration_section">1.13.1.3 </span>Time Zone File Versions on the Source and Target
                     </h5>
                     <div>
                        <p>Successful job completion can depend on whether the source and target time zone file versions match.</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>If the Oracle Database time zone file version is the same on the source and target databases, then conversion of <code class="codeph">TIMESTAMP WITH TIME ZONE</code> data is not necessary. The export/import job should complete successfully.
                              </p>
                              <p>The exception to this is a transportable tablespace or transportable table export performed using a Data Pump release earlier than 11.2.0.1. In that case, tables in the dump file that have <code class="codeph">TIMESTAMP WITH TIME ZONE</code> columns are not created on import even though the time zone file version is the same on the source and target.
                              </p>
                           </li>
                           <li>
                              <p>If the source time zone file version is not available on the target database, then the job fails. The version of the time zone file on the source may not be available on the target because the source may have had its time zone file updated to a later version but the target has not. For example, if the export is done on Oracle Database 11<span class="italic">g</span> release 2 (11.2.0.2) with a time zone file version of 17, and the import is done on 11.2.0.2 with only a time zone file of 16 available, then the job fails.
                              </p>
                           </li>
                        </ul>
                     </div>
                     <div>
                        <div class="familylinks">
                           <div class="parentlink">
                              <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-9B6C92EE-860E-43DD-9728-735B17B9DA89" title="Export and import jobs that have TIMESTAMP WITH TIME ZONE data are restricted.">TIMESTAMP WITH TIMEZONE Restrictions</a></p>
                           </div>
                        </div>
                     </div>
                     
                  </div>
               </div><a id="SUTIL4326"></a><div class="props_rev_3"><a id="GUID-D8443A5E-BF6D-4329-AF11-8E5899356C64" name="GUID-D8443A5E-BF6D-4329-AF11-8E5899356C64"></a><h4 id="SUTIL-GUID-D8443A5E-BF6D-4329-AF11-8E5899356C64" class="sect4"><span class="enumeration_section">1.13.2 </span>TIMESTAMP WITH LOCAL TIME ZONE Restrictions
                  </h4>
                  <div>
                     <p>Moving tables using a transportable mode is restricted.</p>
                     <p>If a table is moved using a transportable mode (transportable table, transportable tablespace, or full transportable), and the following conditions exist, then a warning is issued and the table is not created:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>The source and target databases have different database time zones.</p>
                        </li>
                        <li>
                           <p>The table contains <code class="codeph">TIMESTAMP WITH LOCAL TIME ZONE</code> data types.
                           </p>
                        </li>
                     </ul>
                     <p>To successfully move a table that was not created because of these conditions, use a non-transportable export and import mode.</p>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-7EE60BAB-0D3D-46EB-8E11-4FDDA68EF14E" title="This section describes factors that can affect successful completion of export and import jobs that involve the timestamp data types TIMESTAMP WITH TIMEZONE and TIMESTAMP WITH LOCAL TIMEZONE.">How Does Data Pump Handle Timestamp Data?</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div>
            </div><a id="SUTIL4307"></a><div class="props_rev_3"><a id="GUID-72F01BF0-61F5-4775-8C7B-4E227F244866" name="GUID-72F01BF0-61F5-4775-8C7B-4E227F244866"></a><h3 id="SUTIL-GUID-72F01BF0-61F5-4775-8C7B-4E227F244866" class="sect3"><span class="enumeration_section">1.14 </span>Character Set and Globalization Support Considerations
               </h3>
               <div>
                  <p>Globalization support behavior of Data Pump Export and Import.</p>
                  <p>These sections describe the globalization support behavior of Data Pump Export and Import with respect to character set conversion of user data and data definition language (DDL).</p>
               </div>
               <div>
                  <ul class="ullinks">
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-7B94D834-313B-4BA7-80F2-A29C1870DF27">Data Definition Language (DDL)</a><br>The Export utility writes dump files using the database character set of the export system.
                     </li>
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-A786A4B1-A913-4765-81F9-C877A6566F9C">Single-Byte Character Sets and Export and Import</a><br>Ensure that the export database and the import database use the same character set.
                     </li>
                     <li class="ulchildlink"><a href="oracle-data-pump-overview.html#GUID-5F23F5CF-82F0-4254-B865-20ED68F4AE31">Multibyte Character Sets and Export and Import</a><br>During character set conversion, any characters in the export file that have no equivalent in the import database character set are replaced with a default character. The import database character set defines the default character.
                     </li>
                  </ul>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-17FAE261-0972-4220-A2E4-44D479F519D4" title="Oracle Data Pump technology enables very high-speed movement of data and metadata from one database to another.">Overview of Oracle Data Pump</a></p>
                     </div>
                  </div>
               </div>
               <a id="SUTIL4310"></a><div class="props_rev_3"><a id="GUID-7B94D834-313B-4BA7-80F2-A29C1870DF27" name="GUID-7B94D834-313B-4BA7-80F2-A29C1870DF27"></a><h4 id="SUTIL-GUID-7B94D834-313B-4BA7-80F2-A29C1870DF27" class="sect4"><span class="enumeration_section">1.14.1 </span>Data Definition Language (DDL)
                  </h4>
                  <div>
                     <p>The Export utility writes dump files using the database character set of the export system.</p>
                     <p>When the dump file is imported, a character set conversion is required for DDL only if the database character set of the  import system is different from the database character set of the export system.</p>
                     <p>To minimize data loss due to character set conversions, ensure that the import database character set is a superset of the export database character set.</p>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-72F01BF0-61F5-4775-8C7B-4E227F244866" title="Globalization support behavior of Data Pump Export and Import.">Character Set and Globalization Support Considerations</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="SUTIL4311"></a><div class="props_rev_3"><a id="GUID-A786A4B1-A913-4765-81F9-C877A6566F9C" name="GUID-A786A4B1-A913-4765-81F9-C877A6566F9C"></a><h4 id="SUTIL-GUID-A786A4B1-A913-4765-81F9-C877A6566F9C" class="sect4"><span class="enumeration_section">1.14.2 </span>Single-Byte Character Sets and Export and Import
                  </h4>
                  <div>
                     <p>Ensure that the export database and the import database use the same character set.</p>
                     <p>If the system on which the import occurs uses a 7-bit character set, and you import an 8-bit character set dump file, then some 8-bit characters may be converted to 7-bit equivalents. An indication that this has happened is when accented characters lose the accent mark.</p>
                     <p>To avoid this unwanted conversion, ensure that the export database and the import database use the same character set.</p>
                  </div>
                  <div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-72F01BF0-61F5-4775-8C7B-4E227F244866" title="Globalization support behavior of Data Pump Export and Import.">Character Set and Globalization Support Considerations</a></p>
                        </div>
                     </div>
                  </div>
                  
               </div><a id="SUTIL4312"></a><div class="props_rev_3"><a id="GUID-5F23F5CF-82F0-4254-B865-20ED68F4AE31" name="GUID-5F23F5CF-82F0-4254-B865-20ED68F4AE31"></a><h4 id="SUTIL-GUID-5F23F5CF-82F0-4254-B865-20ED68F4AE31" class="sect4"><span class="enumeration_section">1.14.3 </span>Multibyte Character Sets and Export and Import 
                  </h4>
                  <div>
                     <p>During character set conversion, any characters in the export file that have no equivalent in the import database character set are replaced with a default character. The import database character set defines the default character.</p>
                     <p>If the import system has to use replacement characters while converting DDL, then a warning message is displayed and the system attempts to load the converted DDL.</p>
                     <p>If the import system has to use replacement characters while converting user data, then the default behavior is to load the converted data. However, it is possible to instruct the import system to reject rows of user data that were converted using replacement characters. See the Import <code class="codeph">DATA OPTIONS</code> parameter  for details.
                     </p>
                     <p>To guarantee 100% conversion, the import database character set must be a superset (or equivalent) of the character set used to generate the export file.</p>
                     <div class="infoboxnote" id="GUID-5F23F5CF-82F0-4254-B865-20ED68F4AE31__GUID-47BCA3F7-50F1-444B-BEDE-CFABB6000811">
                        <p class="notep1">Caution:</p>
                        <p>When the database character set of the export system differs from that of the import system, the import system displays informational messages at the start of the job that show what the database character set is. </p>
                        <p>When the import database character set is not a superset of the character set used to generate the export file, the import system displays a warning that possible data loss may occur due to character set conversions.</p>
                     </div>
                  </div>
                  <div>
                     <div class="relinfo">
                        <p><strong>Related Topics</strong></p>
                        <ul>
                           <li><a href="datapump-import-utility.html#GUID-5FFA128D-B7F5-41D0-A72C-EB2CE384765D">DATA_OPTIONS</a></li>
                        </ul>
                     </div>
                     <div class="familylinks">
                        <div class="parentlink">
                           <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-72F01BF0-61F5-4775-8C7B-4E227F244866" title="Globalization support behavior of Data Pump Export and Import.">Character Set and Globalization Support Considerations</a></p>
                        </div>
                     </div>
                  </div>
               </div>
            </div>
            <div class="sect2"><a id="GUID-B1A6BBA2-0269-48CC-8A0E-8E3955A231C0" name="GUID-B1A6BBA2-0269-48CC-8A0E-8E3955A231C0"></a><h3 id="SUTIL-GUID-B1A6BBA2-0269-48CC-8A0E-8E3955A231C0" class="sect3"><span class="enumeration_section">1.15 </span>Oracle Data Pump Behavior with Data-Bound Collation
               </h3>
               <div>
                  <p>Oracle Data Pump supports data-bound collation (DBC).</p>
                  <div class="p">Data Pump Export always includes all available collation metadata into the created dump file. This includes:
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Current default collations of exported users' schemas</p>
                        </li>
                        <li>
                           <p>Current default collations of exported tables, views, materialized views and PL/SQL units (including user-defined types)</p>
                        </li>
                        <li>
                           <p>Declared collations of all table and cluster character data type columns</p>
                        </li>
                     </ul>
                  </div>
                  <p>When importing a dump file exported from an Oracle Database 12<span class="italic">c</span> Release 2 (12.2) database, Data Pump Import's behavior depends on the effective value of the Data Pump <code class="codeph">VERSION</code> parameter at the time of import and on whether the data-bound collation (DBC) feature is enabled in the target database. The effective value of the <code class="codeph">VERSION</code> parameter is determined by how it is specified. The parameter may be specified as follows:
                  </p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p><code class="codeph">VERSION=<span class="codeinlineitalic">n</span></code>, which means the effective value is the specific version number <code class="codeph"><span class="codeinlineitalic">n</span></code>, for example, <code class="codeph">VERSION=12.2</code></p>
                     </li>
                     <li>
                        <p><code class="codeph">VERSION=LATEST</code>, which means the effective value is the currently running database version
                        </p>
                     </li>
                     <li>
                        <p><code class="codeph">VERSION=COMPATIBLE</code>, which means the effective value is the same as the value of the database initialization parameter <code class="codeph">COMPATIBLE</code>. This is also true if no value is specified for <code class="codeph">VERSION</code>.
                        </p>
                     </li>
                  </ul>
                  <p> For the DBC feature to be enabled in a database, the initialization parameter <code class="codeph">COMPATIBLE</code> must be set to 12.2 or higher and the initialization parameter <code class="codeph">MAX_STRING_SIZE</code> must be set to <code class="codeph">EXTENDED</code>.
                  </p>
                  <p>If the effective value of the Data Pump Import <code class="codeph">VERSION</code> parameter is 12.2 and DBC is enabled in the target database, then Data Pump Import generates DDL statements with collation clauses referencing collation metadata from the dump file. Exported objects are created with the original collation metadata that they had in the source database.&nbsp;
                  </p>
                  <p>No collation syntax is generated if DBC is disabled or if the Data Pump Import <code class="codeph">VERSION</code> parameter is set to a value lower than 12.2.
                  </p>
               </div>
               <div>
                  <div class="familylinks">
                     <div class="parentlink">
                        <p><strong>Parent topic:</strong> <a href="oracle-data-pump-overview.html#GUID-17FAE261-0972-4220-A2E4-44D479F519D4" title="Oracle Data Pump technology enables very high-speed movement of data and metadata from one database to another.">Overview of Oracle Data Pump</a></p>
                     </div>
                  </div>
               </div>
               
            </div>
         </div>
      </article>
   </body>
</html>