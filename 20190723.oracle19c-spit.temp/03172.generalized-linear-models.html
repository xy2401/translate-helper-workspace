<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xml:lang="en-us" lang="en-us">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <meta name="abstract" content="Learn how to use Generalized Linear Models (GLM) statistical technique for Linear modeling.">
      <meta name="description" content="Learn how to use Generalized Linear Models (GLM) statistical technique for Linear modeling.">
      <title>Generalized Linear Models</title>
      <meta property="og:site_name" content="Oracle Help Center">
      <meta property="og:title" content="Concepts">
      <meta property="og:description" content="Learn how to use Generalized Linear Models (GLM) statistical technique for Linear modeling.">
      <link rel="stylesheet" href="/sp_common/book-template/ohc-book-template/css/book.css">
      <link rel="shortcut icon" href="/sp_common/book-template/ohc-common/img/favicon.ico">
      <meta name="application-name" content="Concepts">
      <meta name="generator" content="DITA Open Toolkit version 1.8.5 (Mode = doc)">
      <meta name="plugin" content="SP_docbuilder HTML plugin release 18.2.2">
      <link rel="alternate" href="data-mining-concepts.pdf" title="PDF File" type="application/pdf">
      <meta name="robots" content="all">
      <link rel="schema.dcterms" href="http://purl.org/dc/terms/">
      <meta name="dcterms.created" content="2019-01-10T04:37:09-08:00">
      
      <meta name="dcterms.dateCopyrighted" content="2005, 2019">
      <meta name="dcterms.category" content="database">
      <meta name="dcterms.identifier" content="E97867-01">
      
      <meta name="dcterms.product" content="en/database/oracle/oracle-database/19">
      
      <link rel="prev" href="expnential-smoothing.html" title="Previous" type="text/html">
      <link rel="next" href="k-means.html" title="Next" type="text/html">
      <script>
        document.write('<style type="text/css">');
        document.write('body > .noscript, body > .noscript ~ * { visibility: hidden; }');
        document.write('</style>');
     </script>
      <script data-main="/sp_common/book-template/ohc-book-template/js/book-config" src="/sp_common/book-template/requirejs/require.js"></script>
      <script>
            if (window.require === undefined) {
                document.write('<script data-main="sp_common/book-template/ohc-book-template/js/book-config" src="sp_common/book-template/requirejs/require.js"><\/script>');
                document.write('<link href="sp_common/book-template/ohc-book-template/css/book.css" rel="stylesheet"/>');
            }
        </script>
      <script type="application/json" id="ssot-metadata">{"primary":{"category":{"short_name":"database","element_name":"Database","display_in_url":true},"suite":{"short_name":"oracle","element_name":"Oracle","display_in_url":true},"product_group":{"short_name":"not-applicable","element_name":"Not applicable","display_in_url":false},"product":{"short_name":"oracle-database","element_name":"Oracle Database","display_in_url":true},"release":{"short_name":"19","element_name":"Release 19","display_in_url":true}}}</script>
      
    <meta name="dcterms.title" content="Data Mining Concepts">
    <meta name="dcterms.isVersionOf" content="DMCON">
    <meta name="dcterms.release" content="Release 19">
  </head>
   <body>
      <div class="noscript alert alert-danger text-center" role="alert">
         <a href="expnential-smoothing.html" class="pull-left"><span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span>Previous</a>
         <a href="k-means.html" class="pull-right">Next<span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span></a>
         <span class="fa fa-exclamation-triangle" aria-hidden="true"></span> JavaScript must be enabled to correctly display this content
        
      </div>
      <article>
         <header>
            <ol class="breadcrumb" vocab="http://schema.org/" typeof="BreadcrumbList">
               <li property="itemListElement" typeof="ListItem"><a href="index.html" property="item" typeof="WebPage"><span property="name">Concepts</span></a></li>
               <li property="itemListElement" typeof="ListItem"><a href="algorithms.html" property="item" typeof="WebPage"><span property="name"> Algorithms</span></a></li>
               <li class="active" property="itemListElement" typeof="ListItem"> Generalized Linear Models</li>
            </ol>
            <a id="GUID-5E59530F-EBD9-414E-8C8B-63F8079772CE" name="GUID-5E59530F-EBD9-414E-8C8B-63F8079772CE"></a>
            
            <h2 id="DMCON-GUID-5E59530F-EBD9-414E-8C8B-63F8079772CE" class="sect2"><span class="enumeration_chapter">17 </span> Generalized Linear Models
            </h2>
         </header>
         <div class="ind">
            <div>
               <p>Learn how to use Generalized Linear Models (GLM) statistical technique for Linear modeling.</p>
               <p><a id="d19285e8" class="indexterm-anchor"></a><a id="d19285e12" class="indexterm-anchor"></a><a id="d19285e16" class="indexterm-anchor"></a>Oracle Data Mining supports GLM for <a id="d19285e19" class="indexterm-anchor"></a>Regression and Binary <a id="d19285e24" class="indexterm-anchor"></a> Classification.
               </p>
               <ul style="list-style-type: disc;">
                  <li>
                     <p><a href="generalized-linear-models.html#GUID-2D4A68D3-06BC-45AA-BD0B-B15994CA94A0" title="Introduces Generalized Linear Models (GLM).">About Generalized Linear Models</a></p>
                  </li>
                  <li>
                     <p><a href="generalized-linear-models.html#GUID-B7098AAA-1303-4E16-ABB3-22660FE524FF" title="Learn how to interpret, and understand data transparency through model details and global details.Predict confidence bounds through Generalized Linear Models (GLM).Understand the use of Ridge regression for singularity (exact multicollinearity) in data. Configure Ridge Regression through build settings.Models built with Ridge Regression do not support confidence bounds.Learn about preparing data for Ridge Regression.">GLM in Oracle Data Mining</a></p>
                  </li>
                  <li>
                     <p><a href="generalized-linear-models.html#GUID-F29113DC-0D5A-4F64-A90A-9F5FC0E827DA" title="Learn about configuring Feature Generation.">Scalable Feature Selection</a></p>
                  </li>
                  <li>
                     <p><a href="generalized-linear-models.html#GUID-3ED057CA-B4A2-4602-A948-5FC704CE5494" title="Specify the build settings for Generalized Linear Model (GLM).Learn about coeffficient statistics for Linear and Logistic Regression.Learn about high-level statistics describing the model.Generate row-statistics by configuring Generalized Linear Models (GLM).">Tuning and Diagnostics for GLM</a></p>
                  </li>
                  <li>
                     <p><a href="generalized-linear-models.html#GUID-F36DDDDB-3A87-4C97-8000-EBF009E794C2" title="Learn about the different solvers for Generalized Liner Models (GLM).">GLM Solvers</a></p>
                  </li>
                  <li>
                     <p><a href="generalized-linear-models.html#GUID-19B8E133-0029-4892-88BB-3E1C9E83EB12" title="Learn about preparing data for Generalized Linear Models (GLM).">Data Preparation for GLM</a></p>
                  </li>
                  <li>
                     <p><a href="generalized-linear-models.html#GUID-72E679D5-B88E-4706-9A00-400080AB3E66">Linear Regression</a></p>
                  </li>
                  <li>
                     <p><a href="generalized-linear-models.html#GUID-6391E631-7E0F-4B9F-85BD-E49DA49E7B73">Logistic Regression</a></p>
                  </li>
               </ul>
            </div>
            <div>
               <div class="relinfo">
                  <p><strong>Related Topics</strong></p>
                  <ul>
                     <li><a href="regression.html#GUID-51A08CFC-1487-4887-AB47-794C50D67358" title="Learn how to predict a continuous numerical target through Regression - the supervised mining function.">Regression</a></li>
                     <li><a href="classification.html#GUID-3D51EC47-E686-4468-8F49-A27B5F8E8FE4" title="Learn how to predict a categorical target through Classification - the supervised mining function.">Classification</a></li>
                  </ul>
               </div>
            </div><a id="DMCON022"></a><a id="DMCON309"></a><div class="props_rev_3"><a id="GUID-2D4A68D3-06BC-45AA-BD0B-B15994CA94A0" name="GUID-2D4A68D3-06BC-45AA-BD0B-B15994CA94A0"></a><h3 id="DMCON-GUID-2D4A68D3-06BC-45AA-BD0B-B15994CA94A0" class="sect3"><span class="enumeration_section">17.1 </span>About Generalized Linear Models
               </h3>
               <div>
                  <p>Introduces Generalized Linear Models (GLM).</p>
                  <p>GLM include and extend the class of linear models. </p>
                  <p>Linear models make a set of restrictive assumptions, most importantly, that the target (dependent variable <span class="italic">y</span>) is normally distributed conditioned on the value of predictors with a constant variance regardless of the predicted response value. The advantage of linear models and their restrictions include computational simplicity, an interpretable model form, and the ability to compute certain diagnostic information about the quality of the fit.
                  </p>
                  <p>Generalized linear models relax these restrictions, which are often violated in practice. For example, binary (yes/no or 0/1) responses do not have same variance across classes. Furthermore, the sum of terms in a linear model typically can have very large ranges encompassing very negative and very positive values. For the binary response example, we would like the response to be a probability in the range [0,1]. </p>
                  <p>Generalized linear models accommodate responses that violate the linear model assumptions through two mechanisms: a link function and a variance function. The link function transforms the target range to potentially -infinity to +infinity so that the simple form of linear models can be maintained. The variance function expresses the variance as a function of the predicted response, thereby accommodating responses with non-constant variances (such as the binary responses).</p>
                  <p>Oracle Data Mining includes two of the most popular members of the GLM family of models with their most popular link and variance functions: </p>
                  <ul style="list-style-type: disc;">
                     <li>
                        <p><strong class="term">Linear regression</strong> with the identity link and variance function equal to the constant 1 (constant variance over the range of response values). 
                        </p>
                     </li>
                     <li>
                        <p><strong class="term">Logistic regression</strong> with the logit link and binomial variance functions. 
                        </p>
                     </li>
                  </ul>
               </div>
               <div>
                  <div class="relinfo">
                     <p><strong>Related Topics</strong></p>
                     <ul>
                        <li><a href="regression.html#GUID-C6EBF018-D4CA-469C-8804-0E1E2F4EDA74">Linear Regression</a></li>
                        <li><a href="generalized-linear-models.html#GUID-72E679D5-B88E-4706-9A00-400080AB3E66">Linear Regression</a></li>
                        <li><a href="generalized-linear-models.html#GUID-6391E631-7E0F-4B9F-85BD-E49DA49E7B73">Logistic Regression</a></li>
                     </ul>
                  </div>
               </div>
            </div><a id="DMCON310"></a><div class="props_rev_3"><a id="GUID-B7098AAA-1303-4E16-ABB3-22660FE524FF" name="GUID-B7098AAA-1303-4E16-ABB3-22660FE524FF"></a><h3 id="DMCON-GUID-B7098AAA-1303-4E16-ABB3-22660FE524FF" class="sect3"><span class="enumeration_section">17.2 </span>GLM in Oracle Data Mining
               </h3>
               <div>
                  <p>Generalized Linear Models (GLM) is a parametric modeling technique. Parametric models make assumptions about the distribution of the data. When the assumptions are met, parametric models can be more efficient than non-parametric models.</p>
                  <p>The challenge in developing models of this type involves assessing the extent to which the assumptions are met. For this reason, quality diagnostics are key to developing quality parametric models.</p>
               </div><a id="DMCON311"></a><div class="props_rev_3"><a id="GUID-B148EFA5-C0F3-4E1B-8892-0211C827496C" name="GUID-B148EFA5-C0F3-4E1B-8892-0211C827496C"></a><h4 id="DMCON-GUID-B148EFA5-C0F3-4E1B-8892-0211C827496C" class="sect4"><span class="enumeration_section">17.2.1 </span>Interpretability and Transparency
                  </h4>
                  <div>
                     <p>Learn how to interpret, and understand data transparency through model details and global details.</p>
                     <p>Oracle <a id="d19285e200" class="indexterm-anchor"></a>Data Mining Generalized Linear Models (GLM) are easy to interpret. Each model build generates many statistics and diagnostics. Transparency is also a key feature: model details describe key characteristics of the <a id="d19285e203" class="indexterm-anchor"></a>coefficients, and global details provide high-level statistics. 
                     </p>
                  </div>
                  <div>
                     <div class="relinfo">
                        <p><strong>Related Topics</strong></p>
                        <ul>
                           <li><a href="generalized-linear-models.html#GUID-3ED057CA-B4A2-4602-A948-5FC704CE5494" title="Specify the build settings for Generalized Linear Model (GLM).Learn about coeffficient statistics for Linear and Logistic Regression.Learn about high-level statistics describing the model.Generate row-statistics by configuring Generalized Linear Models (GLM).">Tuning and Diagnostics for GLM</a></li>
                        </ul>
                     </div>
                  </div>
               </div><a id="DMCON312"></a><div class="props_rev_3"><a id="GUID-585BC5D1-5C56-4D3F-8D32-1D62CDEDCDDA" name="GUID-585BC5D1-5C56-4D3F-8D32-1D62CDEDCDDA"></a><h4 id="DMCON-GUID-585BC5D1-5C56-4D3F-8D32-1D62CDEDCDDA" class="sect4"><span class="enumeration_section">17.2.2 </span>Wide Data
                  </h4>
                  <div>
                     <p>Oracle Data Mining Generalized Linear Model (GLM) is uniquely suited for handling <a id="d19285e236" class="indexterm-anchor"></a>wide data. The algorithm can build and score quality models that use a virtually limitless number of predictors (attributes). The only constraints are those imposed by system resources. 
                     </p>
                  </div>
               </div><a id="DMCON313"></a><div class="props_rev_3"><a id="GUID-44B771B5-BE64-46F2-B1CD-5478BE2E00C7" name="GUID-44B771B5-BE64-46F2-B1CD-5478BE2E00C7"></a><h4 id="DMCON-GUID-44B771B5-BE64-46F2-B1CD-5478BE2E00C7" class="sect4"><span class="enumeration_section">17.2.3 </span>Confidence Bounds
                  </h4>
                  <div>
                     <p>Predict confidence bounds through Generalized Linear Models (GLM).</p>
                     <p>GLM have the ability to predict confidence bounds. In addition to predicting a best estimate and a probability (Classification only) for each row, GLM identifies an interval wherein the prediction (Regression) or probability (Classification) lies. The width of the interval depends upon the precision of the model and a user-specified confidence level. </p>
                     <p>The confidence level is a measure of how sure the model is that the true value lies within a confidence interval computed by the model. A popular choice for confidence level is 95%. For example, a model might predict that an employee's income is $125K, and that you can be 95% sure that it lies between $90K and $160K. Oracle Data Mining supports 95% confidence by default, but that value can be configured.</p>
                     <div class="infoboxnote" id="GUID-44B771B5-BE64-46F2-B1CD-5478BE2E00C7__GUID-658C1596-3FFB-43E3-87B4-BEA3E0E507E5">
                        <p class="notep1">Note:</p>
                        <p>Confidence bounds are returned with the coefficient statistics. You can also use the <code class="codeph">PREDICTION_BOUNDS</code> SQL function to obtain the confidence bounds of a model prediction. 
                        </p>
                     </div>
                  </div>
                  <div>
                     <div class="relinfo">
                        <p><strong>Related Topics</strong></p>
                        <ul>
                           <li><a href="../sqlrf/PREDICTION_BOUNDS.html#SQLRF-GUID-C9478C25-8D31-4A39-99B8-AB66A6614795" target="_blank"><span><cite>Oracle Database SQL Language Reference</cite></span></a></li>
                        </ul>
                     </div>
                  </div>
               </div><a id="DMCON314"></a><div class="props_rev_3"><a id="GUID-453EF78D-522F-4616-BE54-E36C73280B49" name="GUID-453EF78D-522F-4616-BE54-E36C73280B49"></a><h4 id="DMCON-GUID-453EF78D-522F-4616-BE54-E36C73280B49" class="sect4"><span class="enumeration_section">17.2.4 </span>Ridge Regression
                  </h4>
                  <div>
                     <p>Understand the use of Ridge regression for singularity (exact multicollinearity) in data. </p>
                     <p>The <a id="d19285e311" class="indexterm-anchor"></a>best regression models are those in which the predictors correlate highly with the target, but there is very little correlation between the predictors themselves. <strong class="term">Multicollinearity</strong> is the term used to describe multivariate regression with correlated predictors.
                     </p>
                     <p><strong class="term">Ridge regression</strong> is a technique that compensates for multicollinearity. Oracle Data Mining supports ridge regression for both Regression and Classification mining functions. The algorithm automatically uses ridge if it detects <a id="d19285e321" class="indexterm-anchor"></a>singularity (exact multicollinearity) in the data. 
                     </p>
                     <p>Information about singularity is returned in the global model details. </p>
                  </div>
                  <div>
                     <div class="relinfo">
                        <p><strong>Related Topics</strong></p>
                        <ul>
                           <li><a href="generalized-linear-models.html#GUID-CF1F2B68-6BC9-4C91-919A-E14B56DE3042">Global Model Statistics for Linear Regression</a></li>
                           <li><a href="generalized-linear-models.html#GUID-7E12A0FF-AF3C-4424-9349-BADAB8B10010">Global Model Statistics for Logistic Regression</a></li>
                        </ul>
                     </div>
                  </div><a id="DMCON315"></a><div class="props_rev_3"><a id="GUID-BD09032B-043D-49C0-8919-DCF12842FBFE" name="GUID-BD09032B-043D-49C0-8919-DCF12842FBFE"></a><h5 id="DMCON-GUID-BD09032B-043D-49C0-8919-DCF12842FBFE" class="sect5"><span class="enumeration_section">17.2.4.1 </span>Configuring Ridge Regression
                     </h5>
                     <div>
                        <p>Configure Ridge Regression through build settings.</p>
                        <p>You can choose to explicitly enable ridge regression by specifying a build setting for the model. If you explicitly enable ridge, you can use the system-generated ridge parameter or you can supply your own. If ridge is used automatically, the ridge parameter is also calculated automatically.</p>
                        <p>The configuration choices are summarized as follows:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Whether or not to override the automatic choice made by the algorithm regarding ridge regression</p>
                           </li>
                           <li>
                              <p>The value of the ridge parameter, used only if you specifically enable ridge regression.</p>
                           </li>
                        </ul>
                     </div>
                     <div>
                        <div class="relinfo">
                           <p><strong>Related Topics</strong></p>
                           <ul>
                              <li><a href="../arpls/DBMS_DATA_MINING.html#ARPLS-GUID-4E3665B9-B1C2-4F6B-AB69-A7F353C70F5C" target="_blank"><span><cite>Oracle Database SQL Language Reference</cite></span></a></li>
                           </ul>
                        </div>
                     </div>
                  </div><a id="DMCON316"></a><div class="props_rev_3"><a id="GUID-6D5F41F0-442C-44FC-A021-5FD4151855E6" name="GUID-6D5F41F0-442C-44FC-A021-5FD4151855E6"></a><h5 id="DMCON-GUID-6D5F41F0-442C-44FC-A021-5FD4151855E6" class="sect5"><span class="enumeration_section">17.2.4.2 </span>Ridge and Confidence Bounds
                     </h5>
                     <p>Models built with Ridge Regression do not support confidence bounds.</p>
                     <div>
                        <div class="relinfo">
                           <p><strong>Related Topics</strong></p>
                           <ul>
                              <li><a href="generalized-linear-models.html#GUID-44B771B5-BE64-46F2-B1CD-5478BE2E00C7" title="Predict confidence bounds through Generalized Linear Models (GLM).">Confidence Bounds</a></li>
                           </ul>
                        </div>
                     </div>
                  </div><a id="DMCON318"></a><div class="props_rev_3"><a id="GUID-5714E7CD-A4E1-4F09-B612-C49C99EEFF49" name="GUID-5714E7CD-A4E1-4F09-B612-C49C99EEFF49"></a><h5 id="DMCON-GUID-5714E7CD-A4E1-4F09-B612-C49C99EEFF49" class="sect5"><span class="enumeration_section">17.2.4.3 </span>Ridge and Data Preparation
                     </h5>
                     <div>
                        <p>Learn about preparing data for Ridge Regression.</p>
                        <p>When Ridge Regression is enabled, different data preparation is likely to produce different results in terms of model coefficients and diagnostics. Oracle recommends that you enable Automatic Data Preparation for Generalized Linear Models, especially when Ridge Regression is used. </p>
                     </div>
                     <div>
                        <div class="relinfo">
                           <p><strong>Related Topics</strong></p>
                           <ul>
                              <li><a href="generalized-linear-models.html#GUID-19B8E133-0029-4892-88BB-3E1C9E83EB12" title="Learn about preparing data for Generalized Linear Models (GLM).">Data Preparation for GLM</a></li>
                           </ul>
                        </div>
                     </div>
                  </div>
               </div>
            </div><a id="DMCON598"></a><div class="props_rev_3"><a id="GUID-F29113DC-0D5A-4F64-A90A-9F5FC0E827DA" name="GUID-F29113DC-0D5A-4F64-A90A-9F5FC0E827DA"></a><h3 id="DMCON-GUID-F29113DC-0D5A-4F64-A90A-9F5FC0E827DA" class="sect3"><span class="enumeration_section">17.3 </span>Scalable Feature Selection
               </h3>
               <div>
                  <p>Oracle <a id="d19285e451" class="indexterm-anchor"></a>Data Mining supports a highly scalable and automated version of <a id="d19285e456" class="indexterm-anchor"></a>feature selection and <a id="d19285e459" class="indexterm-anchor"></a>generation for Generalized Linear Models. This capability can enhance the performance of the algorithm and improve accuracy and interpretability. Feature selection and generation are available for both Linear Regression and binary Logistic Regression. 
                  </p>
               </div><a id="DMCON652"></a><div class="props_rev_3"><a id="GUID-2FD0DC9B-37CB-471C-B935-93CC11AD443E" name="GUID-2FD0DC9B-37CB-471C-B935-93CC11AD443E"></a><h4 id="DMCON-GUID-2FD0DC9B-37CB-471C-B935-93CC11AD443E" class="sect4"><span class="enumeration_section">17.3.1 </span>Feature Selection
                  </h4>
                  <div>
                     <p><a id="d19285e481" class="indexterm-anchor"></a>Feature selection is the process of choosing the terms to be included in the model. The fewer terms in the model, the easier it is for human beings to interpret its meaning. In addition, some columns may not be relevant to the value that the model is trying to predict. Removing such columns can enhance model accuracy.
                     </p>
                  </div><a id="DMCON660"></a><div class="props_rev_3"><a id="GUID-F53B62F0-5595-4954-9568-1D8DF117DED8" name="GUID-F53B62F0-5595-4954-9568-1D8DF117DED8"></a><h5 id="DMCON-GUID-F53B62F0-5595-4954-9568-1D8DF117DED8" class="sect5"><span class="enumeration_section">17.3.1.1 </span>Configuring Feature Selection
                     </h5>
                     <div>
                        <p>Feature selection is a build setting for Generalized Linear Models. It is not enabled by default. When configured for feature selection, the algorithm automatically determines appropriate default behavior, but the following configuration options are available: </p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>The feature selection criteria can be AIC, SBIC, RIC, or α-investing. When the feature selection criteria is α-investing, feature acceptance can be either strict or relaxed.</p>
                           </li>
                           <li>
                              <p>The maximum number of features can be specified.</p>
                           </li>
                           <li>
                              <p>Features can be pruned in the final model. Pruning is based on t-statistics for linear regression or wald statistics for logistic regression.</p>
                           </li>
                        </ul>
                     </div>
                  </div><a id="DMCON655"></a><div class="props_rev_3"><a id="GUID-418D1AD0-42B4-49A8-B661-EF5D0D805677" name="GUID-418D1AD0-42B4-49A8-B661-EF5D0D805677"></a><h5 id="DMCON-GUID-418D1AD0-42B4-49A8-B661-EF5D0D805677" class="sect5"><span class="enumeration_section">17.3.1.2 </span>Feature Selection and Ridge Regression
                     </h5>
                     <div>
                        <p>Feature selection and ridge regression are mutually exclusive. When feature selection is enabled, the algorithm can not use ridge. </p>
                        <div class="p">
                           <div class="infoboxnote" id="GUID-418D1AD0-42B4-49A8-B661-EF5D0D805677__GUID-75371E02-14F5-4030-8B74-FFE5172E8163">
                              <p class="notep1">Note:</p>
                              <p>If you configure the model to use both feature selection and ridge regression, then you get an error.</p>
                           </div>
                        </div>
                     </div>
                  </div>
               </div><a id="DMCON653"></a><div class="props_rev_3"><a id="GUID-C5765E61-C1B6-4330-B87E-BF300C03FDF8" name="GUID-C5765E61-C1B6-4330-B87E-BF300C03FDF8"></a><h4 id="DMCON-GUID-C5765E61-C1B6-4330-B87E-BF300C03FDF8" class="sect4"><span class="enumeration_section">17.3.2 </span>Feature Generation
                  </h4>
                  <div>
                     <p><a id="d19285e557" class="indexterm-anchor"></a>Feature generation is the process of adding transformations of terms into the model. Feature generation enhances the power of models to fit more complex relationships between target and predictors.
                     </p>
                  </div><a id="DMCON661"></a><div class="props_rev_3"><a id="GUID-23DFC88C-95C3-4924-B0EC-D4C4D76E20E6" name="GUID-23DFC88C-95C3-4924-B0EC-D4C4D76E20E6"></a><h5 id="DMCON-GUID-23DFC88C-95C3-4924-B0EC-D4C4D76E20E6" class="sect5"><span class="enumeration_section">17.3.2.1 </span>Configuring Feature Generation
                     </h5>
                     <div>
                        <p>Learn about configuring Feature Generation.</p>
                        <p>Feature generation is only possible when feature selection is enabled. Feature generation is a build setting. By default, feature generation is not enabled. </p>
                        <p>The feature generation method can be either quadratic or cubic. By default, the algorithm chooses the appropriate method. You can also explicitly specify the feature generation method. </p>
                        <p>The following options for feature selection also affect feature generation:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Maximum number of features</p>
                           </li>
                           <li>
                              <p>Model pruning</p>
                           </li>
                        </ul>
                     </div>
                     <div>
                        <div class="relinfo">
                           <p><strong>Related Topics</strong></p>
                           <ul>
                              <li><a href="../arpls/DBMS_DATA_MINING.html#ARPLS-GUID-4E3665B9-B1C2-4F6B-AB69-A7F353C70F5C" target="_blank"><span><cite>Oracle Database PL/SQL Packages and Types Reference</cite></span></a></li>
                           </ul>
                        </div>
                     </div>
                  </div>
               </div>
            </div><a id="DMCON319"></a><div class="props_rev_3"><a id="GUID-3ED057CA-B4A2-4602-A948-5FC704CE5494" name="GUID-3ED057CA-B4A2-4602-A948-5FC704CE5494"></a><h3 id="DMCON-GUID-3ED057CA-B4A2-4602-A948-5FC704CE5494" class="sect3"><span class="enumeration_section">17.4 </span>Tuning and Diagnostics for GLM
               </h3>
               <div>
                  <p>The process of developing a Generalized Linear Model typically involves a number of model builds. Each build generates many statistics that you can evaluate to determine the quality of your model. Depending on these diagnostics, you may want to try changing the model settings or making other modifications.</p>
               </div><a id="DMCON320"></a><div class="props_rev_3"><a id="GUID-6A36E8AE-9357-4BFF-8133-9B0507F34C28" name="GUID-6A36E8AE-9357-4BFF-8133-9B0507F34C28"></a><h4 id="DMCON-GUID-6A36E8AE-9357-4BFF-8133-9B0507F34C28" class="sect4"><span class="enumeration_section">17.4.1 </span>Build Settings
                  </h4>
                  <div>
                     <p>Specify the build settings for Generalized Linear Model (GLM).</p>
                     <p>You can use specify build settings.</p>
                     <p>Additional build settings are available to:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Control the use of ridge regression.</p>
                        </li>
                        <li>
                           <p>Specify the handling of missing values in the training data.</p>
                        </li>
                        <li>
                           <p>Specify the target value to be used as a reference in a logistic regression model.</p>
                        </li>
                     </ul>
                  </div>
                  <div>
                     <div class="relinfo">
                        <p><strong>Related Topics</strong></p>
                        <ul>
                           <li><a href="generalized-linear-models.html#GUID-453EF78D-522F-4616-BE54-E36C73280B49" title="Understand the use of Ridge regression for singularity (exact multicollinearity) in data.">Ridge Regression</a></li>
                           <li><a href="generalized-linear-models.html#GUID-19B8E133-0029-4892-88BB-3E1C9E83EB12" title="Learn about preparing data for Generalized Linear Models (GLM).">Data Preparation for GLM</a></li>
                           <li><a href="generalized-linear-models.html#GUID-6391E631-7E0F-4B9F-85BD-E49DA49E7B73">Logistic Regression</a></li>
                           <li><a href="../arpls/DBMS_DATA_MINING.html#ARPLS-GUID-4E3665B9-B1C2-4F6B-AB69-A7F353C70F5C" target="_blank"><span><cite>Oracle Database PL/SQL Packages and Types Reference</cite></span></a></li>
                        </ul>
                     </div>
                  </div>
               </div><a id="DMCON321"></a><div class="props_rev_3"><a id="GUID-1A82DCDD-C6E3-4F0F-AFFC-D37D5CA57FE1" name="GUID-1A82DCDD-C6E3-4F0F-AFFC-D37D5CA57FE1"></a><h4 id="DMCON-GUID-1A82DCDD-C6E3-4F0F-AFFC-D37D5CA57FE1" class="sect4"><span class="enumeration_section">17.4.2 </span>Diagnostics
                  </h4>
                  <div>
                     <p>Generalized Linear Models generate many metrics to help you evaluate the quality of the model. </p>
                  </div><a id="DMCON322"></a><div class="props_rev_3"><a id="GUID-B60A24C9-D7EF-48AA-9D08-1A5ECD66AA61" name="GUID-B60A24C9-D7EF-48AA-9D08-1A5ECD66AA61"></a><h5 id="DMCON-GUID-B60A24C9-D7EF-48AA-9D08-1A5ECD66AA61" class="sect5"><span class="enumeration_section">17.4.2.1 </span>Coefficient Statistics
                     </h5>
                     <div>
                        <p>Learn about coeffficient statistics for Linear and Logistic Regression.</p>
                        <p>The same set of statistics is returned for both linear and logistic regression, but statistics that do not apply to the mining function are returned as NULL. </p>
                        <p>Coefficient statistics are returned by the Model Detail Views for Generalized Linear Model.</p>
                     </div>
                     <div>
                        <div class="relinfo">
                           <p><strong>Related Topics</strong></p>
                           <ul>
                              <li><a href="generalized-linear-models.html#GUID-B078259C-29BC-4B53-9457-B21F4740CCA6">Coefficient Statistics for Linear Regression</a></li>
                              <li><a href="generalized-linear-models.html#GUID-A29A6577-A14F-4AA9-BF22-06A511A739B4">Coefficient Statistics for Logistic Regression</a></li>
                              <li><a href="../dmprg/model-detail-views.html#DMPRG-GUID-5451C38E-CDEF-4DA3-9741-3C811D3D66EA" target="_blank"><span><cite>Oracle Data Mining User’s Guide</cite></span></a></li>
                           </ul>
                        </div>
                     </div>
                  </div><a id="DMCON323"></a><div class="props_rev_3"><a id="GUID-75840126-8794-49CB-ADAA-1011939A61B8" name="GUID-75840126-8794-49CB-ADAA-1011939A61B8"></a><h5 id="DMCON-GUID-75840126-8794-49CB-ADAA-1011939A61B8" class="sect5"><span class="enumeration_section">17.4.2.2 </span>Global Model Statistics
                     </h5>
                     <div>
                        <p>Learn about high-level statistics describing the model.</p>
                        <p>Separate high-level statistics describing the model as a whole, are returned for linear and logistic regression. When ridge regression is enabled, fewer global details are returned.</p>
                        <p>Global statistics are returned by the Model Detail Views for Generalized Linear Model.</p>
                     </div>
                     <div>
                        <div class="relinfo">
                           <p><strong>Related Topics</strong></p>
                           <ul>
                              <li><a href="generalized-linear-models.html#GUID-CF1F2B68-6BC9-4C91-919A-E14B56DE3042">Global Model Statistics for Linear Regression</a></li>
                              <li><a href="generalized-linear-models.html#GUID-7E12A0FF-AF3C-4424-9349-BADAB8B10010">Global Model Statistics for Logistic Regression</a></li>
                              <li><a href="generalized-linear-models.html#GUID-453EF78D-522F-4616-BE54-E36C73280B49" title="Understand the use of Ridge regression for singularity (exact multicollinearity) in data.">Ridge Regression</a></li>
                              <li><a href="../dmprg/model-detail-views.html#DMPRG-GUID-5451C38E-CDEF-4DA3-9741-3C811D3D66EA" target="_blank"><span><cite>Oracle Data Mining User’s Guide</cite></span></a></li>
                           </ul>
                        </div>
                     </div>
                  </div><a id="DMCON324"></a><div class="props_rev_3"><a id="GUID-EF776E08-B26C-45D2-A637-D55771E3035D" name="GUID-EF776E08-B26C-45D2-A637-D55771E3035D"></a><h5 id="DMCON-GUID-EF776E08-B26C-45D2-A637-D55771E3035D" class="sect5"><span class="enumeration_section">17.4.2.3 </span>Row Diagnostics
                     </h5>
                     <div>
                        <p>Generate row-statistics by configuring Generalized Linear Models (GLM).</p>
                        <p>GLM to generate per-row statistics by specifying the name of a diagnostics table in the build setting <code class="codeph">GLMS_DIAGNOSTICS_TABLE_NAME</code>.
                        </p>
                        <p>GLM requires a case ID to generate row diagnostics. If you provide the name of a diagnostic table but the data does not include a case ID column, an exception is raised.</p>
                     </div>
                     <div>
                        <div class="relinfo">
                           <p><strong>Related Topics</strong></p>
                           <ul>
                              <li><a href="generalized-linear-models.html#GUID-497F3137-3F4F-4B05-8897-13F66F42CD2C">Row Diagnostics for Linear Regression</a></li>
                              <li><a href="generalized-linear-models.html#GUID-FD9FB031-4D4B-4C8E-8F27-DCB0090DF9A4">Row Diagnostics for Logistic Regression</a></li>
                           </ul>
                        </div>
                     </div>
                  </div>
               </div>
            </div>
            <div class="props_rev_3"><a id="GUID-F36DDDDB-3A87-4C97-8000-EBF009E794C2" name="GUID-F36DDDDB-3A87-4C97-8000-EBF009E794C2"></a><h3 id="DMCON-GUID-F36DDDDB-3A87-4C97-8000-EBF009E794C2" class="sect3"><span class="enumeration_section">17.5 </span>GLM Solvers
               </h3>
               <div>
                  <p>Learn about the different solvers for Generalized Liner Models (GLM).</p>
                  <p>The GLM algorithm supports four different solvers: Cholesky, QR, Stochastic Gradient Descent (SGD), L-BFGS, and Alternating Direction Method of Multipliers (ADMM). The Cholesky and QR solvers employ classical decomposition approaches. The Cholesky solver is faster compared to the QR solver but less stable numerically. The QR solver handles better rank deficient problems without the help of regularization.</p>
                  <p>The SGD and L-BFGS ADMM solvers are best suited for high dimensional data. SGD solver employs stochastic gradient descent optimization algorithm while L-BFGS ADMM uses the Broyden-Fletcher-Goldfarb-Shanno optimization algorithm within an Alternating Direction Method of Multipliers framework. SGD is fast but is sensitive to parameters and requires appropriately scaled data to achieve good convergence. The L-BFGS algorithm solves unconstrained optimization problems and is more stable and robust than SGD. In addition, L-BFGS is used in conjunction with ADMM which results in a highly efficient distributed optimization approach with low communication cost.</p>
               </div>
               <div>
                  <div class="relinfo">
                     <p><strong>Related Topics</strong></p>
                     <ul>
                        <li><a href="../arpls/DBMS_DATA_MINING.html#ARPLS-GUID-7793F608-2719-45EA-87F9-6F246BA800D4" target="_blank">DBMS_DATA_MINING - Algorithm Settings: Neural Network</a></li>
                        <li><a href="../arpls/DBMS_DATA_MINING.html#ARPLS-GUID-4E3665B9-B1C2-4F6B-AB69-A7F353C70F5C" target="_blank">DBMS_DATA_MINING — Algorithm Settings: Generalized Linear Models</a></li>
                        <li><a href="../arpls/DBMS_DATA_MINING.html#ARPLS-GUID-0200DE7C-E754-4663-A66C-EC25BA2AF224" target="_blank">DBMS_DATA_MINING — Algorithm Settings: ADMM</a></li>
                        <li><a href="../arpls/DBMS_DATA_MINING.html#ARPLS-GUID-918E3D96-84F4-4171-84C7-E0774B86EA7D" target="_blank">DBMS_DATA_MINING — Algorithm Settings: LBFGS</a></li>
                     </ul>
                  </div>
               </div>
            </div><a id="DMCON325"></a><div class="props_rev_3"><a id="GUID-19B8E133-0029-4892-88BB-3E1C9E83EB12" name="GUID-19B8E133-0029-4892-88BB-3E1C9E83EB12"></a><h3 id="DMCON-GUID-19B8E133-0029-4892-88BB-3E1C9E83EB12" class="sect3"><span class="enumeration_section">17.6 </span>Data Preparation for GLM
               </h3>
               <div>
                  <p>Learn about preparing data for Generalized Linear Models (GLM).</p>
                  <p><a id="d19285e889" class="indexterm-anchor"></a>Automatic Data Preparation (ADP) implements suitable data transformations for both linear and logistic regression.
                  </p>
                  <div class="infoboxnote" id="GUID-19B8E133-0029-4892-88BB-3E1C9E83EB12__GUID-E8927119-85F8-4786-BC59-19A6BCC4CBFD">
                     <p class="notep1">Note:</p>
                     <p>Oracle recommends that you use Automatic Data Preparation with GLM.</p>
                  </div>
               </div>
               <div>
                  <div class="relinfo">
                     <p><strong>Related Topics</strong></p>
                     <ul>
                        <li><a href="../dmapi/automatic-data-preparation.html#DMPRG014" target="_blank"><span><cite>Oracle Data Mining User’s Guide</cite></span></a></li>
                     </ul>
                  </div>
               </div><a id="DMCON326"></a><div class="props_rev_3"><a id="GUID-72F14528-1077-4EAB-992B-E39607CC49A1" name="GUID-72F14528-1077-4EAB-992B-E39607CC49A1"></a><h4 id="DMCON-GUID-72F14528-1077-4EAB-992B-E39607CC49A1" class="sect4"><span class="enumeration_section">17.6.1 </span>Data Preparation for Linear Regression
                  </h4>
                  <div>
                     <p>Learn about Automatic Data Preparation (ADP) for Generalized Linear Model (GLM).</p>
                     <p>When Automatic Data Preparation (ADP) is enabled, the algorithm chooses a transformation based on input data properties and other settings. The transformation can include one or more of the following for numerical data: subtracting the mean, scaling by the standard deviation, or performing a correlation transformation (Neter, et. al, 1990). If the correlation transformation is applied to numeric data, it is also applied to categorical attributes.</p>
                     <p>Prior to standardization, categorical attributes are exploded into N-1 columns where N is the attribute cardinality. The most frequent value (mode) is omitted during the explosion transformation. In the case of highest frequency ties, the attribute values are sorted alpha-numerically in ascending order, and the first value on the list is omitted during the explosion. This explosion transformation occurs whether or not ADP is enabled.</p>
                     <p>In the case of high cardinality categorical attributes, the described transformations (explosion followed by standardization) can increase the build data size because the resulting data representation is dense. To reduce memory, disk space, and processing requirements, use an alternative approach. Under these circumstances, the VIF statistic must be used with caution. </p>
                  </div>
                  <div>
                     <div class="relinfo">
                        <p><strong>Related Topics</strong></p>
                        <ul>
                           <li><a href="generalized-linear-models.html#GUID-5714E7CD-A4E1-4F09-B612-C49C99EEFF49" title="Learn about preparing data for Ridge Regression.">Ridge and Data Preparation</a></li>
                           <li><a href="../dmprg/transforming-data.html#DMPRG-GUID-C3FDDEC7-8CC9-4AC1-A6C3-75D91E26B703" target="_blank"><span><cite>Oracle Data Mining User’s Guide</cite></span></a></li>
                        </ul>
                     </div>
                     <div class="infoboxnotealso" id="GUID-72F14528-1077-4EAB-992B-E39607CC49A1__GUID-3C103C92-8837-4FAB-9019-F53B1941BD39">
                        <p class="notep1">See Also:</p>
                        <div class="p">
                           <ul style="list-style-type: disc;">
                              <li>
                                 <p>Neter, J., Wasserman, W., and Kutner, M.H., "Applied Statistical Models", Richard D. Irwin, Inc., Burr Ridge, IL, 1990.</p>
                              </li>
                           </ul>
                        </div>
                     </div>
                  </div>
               </div><a id="DMCON327"></a><div class="props_rev_3"><a id="GUID-0BD579B6-264F-40A5-BD3F-3E35BB03C43F" name="GUID-0BD579B6-264F-40A5-BD3F-3E35BB03C43F"></a><h4 id="DMCON-GUID-0BD579B6-264F-40A5-BD3F-3E35BB03C43F" class="sect4"><span class="enumeration_section">17.6.2 </span>Data Preparation for Logistic Regression
                  </h4>
                  <div>
                     <p>Categorical attributes are exploded into <span class="italic">N</span>-1 columns where <span class="italic">N</span> is the attribute cardinality. The most frequent value (mode) is omitted during the explosion transformation. In the case of highest frequency ties, the attribute values are sorted alpha-numerically in ascending order and the first value on the list is omitted during the explosion. This explosion transformation occurs whether or not Automatic Data Preparation (ADP) is enabled.
                     </p>
                     <p>When ADP is enabled, numerical attributes are scaled by the standard deviation. This measure of variability is computed as the standard deviation per attribute with respect to the origin (not the mean) (Marquardt, 1980).</p>
                     <div class="infoboxnotealso" id="GUID-0BD579B6-264F-40A5-BD3F-3E35BB03C43F__GUID-5DC13BE9-A0AD-4F1C-9223-4C27BE07A4C5">
                        <p class="notep1">See Also:</p>
                        <p>Marquardt, D.W., "A Critique of Some Ridge Regression Methods: Comment", Journal of the American Statistical Association, Vol. 75, No. 369 , 1980, pp. 87-91. </p>
                     </div>
                  </div>
               </div><a id="DMCON062"></a><div class="props_rev_3"><a id="GUID-EEE344FD-8FA8-4603-8896-B8B67956E442" name="GUID-EEE344FD-8FA8-4603-8896-B8B67956E442"></a><h4 id="DMCON-GUID-EEE344FD-8FA8-4603-8896-B8B67956E442" class="sect4"><span class="enumeration_section">17.6.3 </span>Missing Values
                  </h4>
                  <div>
                     <p>When building or applying a model, Oracle Data Mining automatically replaces missing values of numerical attributes with the mean and missing values of categorical attributes with the mode. </p>
                     <p>You can configure a Generalized Linear Models to override the default treatment of missing values. With the <code class="codeph">ODMS_MISSING_VALUE_TREATMENT</code> setting, you can cause the algorithm to delete rows in the training data that have missing values instead of replacing them with the mean or the mode. However, when the model is applied, Oracle Data Mining performs the usual mean/mode missing value replacement. As a result, it is possible that the statistics generated from scoring does not match the statistics generated from building the model.
                     </p>
                     <p>If you want to delete rows with missing values in the scoring the model, you must perform the transformation explicitly. To make build and apply statistics match, you must remove the rows with NULLs from the scoring data before performing the apply operation. You can do this by creating a view.</p><pre class="oac_no_warn" dir="ltr">CREATE VIEW <span class="italic"><code class="codeph">viewname</code></span> AS SELECT * from <span class="italic"><code class="codeph">tablename</code></span> 
     WHERE <span class="italic"><code class="codeph">column_name1</code></span> is NOT NULL 
     AND   <span class="italic"><code class="codeph">column_name2</code></span> is NOT NULL 
     AND   <span class="italic"><code class="codeph">column_name3</code></span> is NOT NULL ..... </pre><div class="infoboxnote" id="GUID-EEE344FD-8FA8-4603-8896-B8B67956E442__GUID-7272BE74-F138-48F6-8C8B-67AAA069F01E">
                        <p class="notep1">Note:</p>
                        <p>In Oracle Data Mining, missing values in nested data indicate sparsity, not values missing at random. </p>
                        <p>The value <code class="codeph">ODMS_MISSING_VALUE_DELETE_ROW</code> is only valid for tables without nested columns. If this value is used with nested data, an exception is raised.
                        </p>
                     </div>
                  </div>
               </div>
            </div><a id="DMCON024"></a><div class="props_rev_3"><a id="GUID-72E679D5-B88E-4706-9A00-400080AB3E66" name="GUID-72E679D5-B88E-4706-9A00-400080AB3E66"></a><h3 id="DMCON-GUID-72E679D5-B88E-4706-9A00-400080AB3E66" class="sect3"><span class="enumeration_section">17.7 </span>Linear Regression
               </h3>
               <div>
                  <p><a id="d19285e1058" class="indexterm-anchor"></a><a id="d19285e1062" class="indexterm-anchor"></a><a id="d19285e1066" class="indexterm-anchor"></a>Linear regression is the Generalized Linear Models’ Regression algorithm supported by Oracle Data Mining. The algorithm assumes no target transformation and constant variance over the range of target values. 
                  </p>
               </div><a id="DMCON328"></a><div class="props_rev_3"><a id="GUID-B078259C-29BC-4B53-9457-B21F4740CCA6" name="GUID-B078259C-29BC-4B53-9457-B21F4740CCA6"></a><h4 id="DMCON-GUID-B078259C-29BC-4B53-9457-B21F4740CCA6" class="sect4"><span class="enumeration_section">17.7.1 </span>Coefficient Statistics for Linear Regression
                  </h4>
                  <div>
                     <p>Generalized Linear Model Regression models generate the following coefficient statistics:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Linear coefficient estimate</p>
                        </li>
                        <li>
                           <p>Standard error of the coefficient estimate</p>
                        </li>
                        <li>
                           <p>t-value of the coefficient estimate</p>
                        </li>
                        <li>
                           <p>Probability of the t-value</p>
                        </li>
                        <li>
                           <p>Variance Inflation Factor (VIF)</p>
                        </li>
                        <li>
                           <p>Standardized estimate of the coefficient</p>
                        </li>
                        <li>
                           <p>Lower and upper confidence bounds of the coefficient</p>
                        </li>
                     </ul>
                  </div>
               </div><a id="DMCON329"></a><div class="props_rev_3"><a id="GUID-CF1F2B68-6BC9-4C91-919A-E14B56DE3042" name="GUID-CF1F2B68-6BC9-4C91-919A-E14B56DE3042"></a><h4 id="DMCON-GUID-CF1F2B68-6BC9-4C91-919A-E14B56DE3042" class="sect4"><span class="enumeration_section">17.7.2 </span>Global Model Statistics for Linear Regression
                  </h4>
                  <div>
                     <p>Generalized Linear Model Regression models generate the following statistics that describe the model as a whole:</p>
                     <ul style="list-style-type: disc;">
                        <li>
                           <p>Model degrees of freedom</p>
                        </li>
                        <li>
                           <p>Model sum of squares</p>
                        </li>
                        <li>
                           <p>Model mean square</p>
                        </li>
                        <li>
                           <p>Model <span class="italic">F</span> statistic
                           </p>
                        </li>
                        <li>
                           <p>Model <span class="italic">F</span> value probability
                           </p>
                        </li>
                        <li>
                           <p>Error degrees of freedom</p>
                        </li>
                        <li>
                           <p>Error sum of squares</p>
                        </li>
                        <li>
                           <p>Error mean square</p>
                        </li>
                        <li>
                           <p>Corrected total degrees of freedom</p>
                        </li>
                        <li>
                           <p>Corrected total sum of squares</p>
                        </li>
                        <li>
                           <p>Root mean square error</p>
                        </li>
                        <li>
                           <p>Dependent mean</p>
                        </li>
                        <li>
                           <p>Coefficient of variation</p>
                        </li>
                        <li>
                           <p>R-Square</p>
                        </li>
                        <li>
                           <p>Adjusted R-Square</p>
                        </li>
                        <li>
                           <p>Akaike's information criterion</p>
                        </li>
                        <li>
                           <p>Schwarz's Baysian information criterion</p>
                        </li>
                        <li>
                           <p>Estimated mean square error of the prediction</p>
                        </li>
                        <li>
                           <p>Hocking Sp statistic</p>
                        </li>
                        <li>
                           <p>JP statistic (the final prediction error)</p>
                        </li>
                        <li>
                           <p>Number of parameters (the number of coefficients, including the intercept)</p>
                        </li>
                        <li>
                           <p>Number of rows</p>
                        </li>
                        <li>
                           <p>Whether or not the model converged</p>
                        </li>
                        <li>
                           <p>Whether or not a covariance matrix was computed</p>
                        </li>
                     </ul>
                  </div>
               </div><a id="DMCON331"></a><a id="DMCON330"></a><div class="props_rev_3"><a id="GUID-497F3137-3F4F-4B05-8897-13F66F42CD2C" name="GUID-497F3137-3F4F-4B05-8897-13F66F42CD2C"></a><h4 id="DMCON-GUID-497F3137-3F4F-4B05-8897-13F66F42CD2C" class="sect4"><span class="enumeration_section">17.7.3 </span>Row Diagnostics for Linear Regression
                  </h4>
                  <div>
                     <div class="section">
                        <p>For Linear Regression, the diagnostics table has the columns described in the following table. All the columns are <code class="codeph">NUMBER</code>, except the <code class="codeph">CASE_ID</code> column, which preserves the type from the training data.
                        </p>
                     </div>
                     <!-- class="section" -->
                     <div class="tblformal" id="GUID-497F3137-3F4F-4B05-8897-13F66F42CD2C__BEIHEIAH">
                        <p class="titleintable">Table 17-1 Diagnostics Table for GLM Regression Models</p>
                        <table cellpadding="4" cellspacing="0" class="Formal" title="Diagnostics Table for GLM Regression Models" summary="Diagnostics for GLM regression models" width="100%" frame="hsides" border="1" rules="rows">
                           <thead>
                              <tr align="left" valign="top">
                                 <th align="left" valign="bottom" width="31%" id="d19285e1251">Column</th>
                                 <th align="left" valign="bottom" width="69%" id="d19285e1254">Description</th>
                              </tr>
                           </thead>
                           <tbody>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d19285e1259" headers="d19285e1251 ">
                                    <p><code class="codeph">CASE_ID</code></p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d19285e1259 d19285e1254 ">
                                    <p>Value of the case ID column</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d19285e1267" headers="d19285e1251 ">
                                    <p><code class="codeph">TARGET_VALUE</code></p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d19285e1267 d19285e1254 ">
                                    <p>Value of the target column</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d19285e1275" headers="d19285e1251 ">
                                    <p><code class="codeph">PREDICTED_VALUE</code></p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d19285e1275 d19285e1254 ">
                                    <p>Value predicted by the model for the target</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d19285e1283" headers="d19285e1251 ">
                                    <p><code class="codeph">HAT</code></p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d19285e1283 d19285e1254 ">
                                    <p>Value of the diagonal element of the hat matrix</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d19285e1291" headers="d19285e1251 ">
                                    <p><code class="codeph">RESIDUAL</code></p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d19285e1291 d19285e1254 ">
                                    <p>Measure of error</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d19285e1299" headers="d19285e1251 ">
                                    <p><code class="codeph">STD_ERR_RESIDUAL</code></p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d19285e1299 d19285e1254 ">
                                    <p>Standard error of the residual</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d19285e1307" headers="d19285e1251 ">
                                    <p><code class="codeph">STUDENTIZED_RESIDUAL</code></p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d19285e1307 d19285e1254 ">
                                    <p>Studentized residual</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d19285e1315" headers="d19285e1251 ">
                                    <p><code class="codeph">PRED_RES</code></p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d19285e1315 d19285e1254 ">
                                    <p>Predicted residual</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="31%" id="d19285e1323" headers="d19285e1251 ">
                                    <p><code class="codeph">COOKS_D</code></p>
                                 </td>
                                 <td align="left" valign="top" width="69%" headers="d19285e1323 d19285e1254 ">
                                    <p>Cook's D influence statistic</p>
                                 </td>
                              </tr>
                           </tbody>
                        </table>
                     </div>
                     <!-- class="inftblhruleinformal" -->
                  </div>
               </div>
            </div><a id="DMCON020"></a><div class="props_rev_3"><a id="GUID-6391E631-7E0F-4B9F-85BD-E49DA49E7B73" name="GUID-6391E631-7E0F-4B9F-85BD-E49DA49E7B73"></a><h3 id="DMCON-GUID-6391E631-7E0F-4B9F-85BD-E49DA49E7B73" class="sect3"><span class="enumeration_section">17.8 </span>Logistic Regression
               </h3>
               <div>
                  <p><a id="d19285e1350" class="indexterm-anchor"></a><a id="d19285e1354" class="indexterm-anchor"></a>Binary <a id="d19285e1359" class="indexterm-anchor"></a>Logistic Regression is the Generalized Linear Model Classification algorithm supported by Oracle Data Mining. The algorithm uses the logit link function and the binomial variance function. 
                  </p>
               </div><a id="DMCON332"></a><div class="props_rev_3"><a id="GUID-0E193EE8-7A9A-4F3E-96D7-A27FF4EDB999" name="GUID-0E193EE8-7A9A-4F3E-96D7-A27FF4EDB999"></a><h4 id="DMCON-GUID-0E193EE8-7A9A-4F3E-96D7-A27FF4EDB999" class="sect4"><span class="enumeration_section">17.8.1 </span>Reference Class
                  </h4>
                  <div>
                     <p>You can <a id="d19285e1382" class="indexterm-anchor"></a>use the build setting <code class="codeph">GLMS_REFERENCE_CLASS_NAME</code> to specify the target value to be used as a reference in a binary logistic regression model. Probabilities are produced for the other (non-reference) class. By default, the algorithm chooses the value with the highest prevalence. If there are ties, the attributes are sorted alpha-numerically in an ascending order. 
                     </p>
                  </div>
               </div><a id="DMCON333"></a><div class="props_rev_3"><a id="GUID-FAC2AA6F-85CE-4824-826B-9FFAA200DBBD" name="GUID-FAC2AA6F-85CE-4824-826B-9FFAA200DBBD"></a><h4 id="DMCON-GUID-FAC2AA6F-85CE-4824-826B-9FFAA200DBBD" class="sect4"><span class="enumeration_section">17.8.2 </span>Class Weights
                  </h4>
                  <div>
                     <p>You can use the build setting <code class="codeph">CLAS_WEIGHTS_TABLE_NAME</code> to specify the name of a class weights table. Class weights influence the weighting of target classes during the model build.
                     </p>
                  </div>
               </div><a id="DMCON334"></a><div class="props_rev_3"><a id="GUID-A29A6577-A14F-4AA9-BF22-06A511A739B4" name="GUID-A29A6577-A14F-4AA9-BF22-06A511A739B4"></a><h4 id="DMCON-GUID-A29A6577-A14F-4AA9-BF22-06A511A739B4" class="sect4"><span class="enumeration_section">17.8.3 </span>Coefficient Statistics for Logistic Regression
                  </h4>
                  <div>
                     <div class="section">
                        <p>Generalized Linear Model Classification models generate the following coefficient statistics:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Name of the predictor</p>
                           </li>
                           <li>
                              <p>Coefficient estimate</p>
                           </li>
                           <li>
                              <p>Standard error of the coefficient estimate</p>
                           </li>
                           <li>
                              <p>Wald chi-square value of the coefficient estimate</p>
                           </li>
                           <li>
                              <p>Probability of the Wald chi-square value</p>
                           </li>
                           <li>
                              <p>Standardized estimate of the coefficient</p>
                           </li>
                           <li>
                              <p>Lower and upper confidence bounds of the coefficient</p>
                           </li>
                           <li>
                              <p>Exponentiated coefficient</p>
                           </li>
                           <li>
                              <p>Exponentiated coefficient for the upper and lower confidence bounds of the coefficient</p>
                           </li>
                        </ul>
                     </div>
                     <!-- class="section" -->
                  </div>
               </div><a id="DMCON335"></a><div class="props_rev_3"><a id="GUID-7E12A0FF-AF3C-4424-9349-BADAB8B10010" name="GUID-7E12A0FF-AF3C-4424-9349-BADAB8B10010"></a><h4 id="DMCON-GUID-7E12A0FF-AF3C-4424-9349-BADAB8B10010" class="sect4"><span class="enumeration_section">17.8.4 </span>Global Model Statistics for Logistic Regression
                  </h4>
                  <div>
                     <div class="section">
                        <p>Generalized Linear Model Classification models generate the following statistics that describe the model as a whole:</p>
                        <ul style="list-style-type: disc;">
                           <li>
                              <p>Akaike's criterion for the fit of the intercept only model</p>
                           </li>
                           <li>
                              <p>Akaike's criterion for the fit of the intercept and the covariates (predictors) model</p>
                           </li>
                           <li>
                              <p>Schwarz's criterion for the fit of the intercept only model</p>
                           </li>
                           <li>
                              <p>Schwarz's criterion for the fit of the intercept and the covariates (predictors) model</p>
                           </li>
                           <li>
                              <p>-2 log likelihood of the intercept only model</p>
                           </li>
                           <li>
                              <p>-2 log likelihood of the model</p>
                           </li>
                           <li>
                              <p>Likelihood ratio degrees of freedom</p>
                           </li>
                           <li>
                              <p>Likelihood ratio chi-square probability value</p>
                           </li>
                           <li>
                              <p>Pseudo R-square Cox an Snell</p>
                           </li>
                           <li>
                              <p>Pseudo R-square Nagelkerke</p>
                           </li>
                           <li>
                              <p>Dependent mean</p>
                           </li>
                           <li>
                              <p>Percent of correct predictions</p>
                           </li>
                           <li>
                              <p>Percent of incorrect predictions</p>
                           </li>
                           <li>
                              <p>Percent of ties (probability for two cases is the same)</p>
                           </li>
                           <li>
                              <p>Number of parameters (the number of coefficients, including the intercept)</p>
                           </li>
                           <li>
                              <p>Number of rows</p>
                           </li>
                           <li>
                              <p>Whether or not the model converged</p>
                           </li>
                           <li>
                              <p>Whether or not a covariance matrix was computed.</p>
                           </li>
                        </ul>
                     </div>
                     <!-- class="section" -->
                  </div>
               </div><a id="DMCON337"></a><a id="DMCON336"></a><div class="props_rev_3"><a id="GUID-FD9FB031-4D4B-4C8E-8F27-DCB0090DF9A4" name="GUID-FD9FB031-4D4B-4C8E-8F27-DCB0090DF9A4"></a><h4 id="DMCON-GUID-FD9FB031-4D4B-4C8E-8F27-DCB0090DF9A4" class="sect4"><span class="enumeration_section">17.8.5 </span>Row Diagnostics for Logistic Regression
                  </h4>
                  <div>
                     <div class="section">
                        <p>For Logistic Regression, the diagnostics table has the columns described in the following table. All the columns are <code class="codeph">NUMBER</code>, except the <code class="codeph">CASE_ID</code> and <code class="codeph">TARGET_VALUE</code> columns, which preserve the type from the training data.
                        </p>
                     </div>
                     <!-- class="section" -->
                     <div class="tblformal" id="GUID-FD9FB031-4D4B-4C8E-8F27-DCB0090DF9A4__BEIBGIIG">
                        <p class="titleintable">Table 17-2 Row Diagnostics Table for Logistic Regression</p>
                        <table cellpadding="4" cellspacing="0" class="Formal" title="Row Diagnostics Table for Logistic Regression" summary="GLM diagnostics for classification models" width="100%" frame="hsides" border="1" rules="rows">
                           <thead>
                              <tr align="left" valign="top">
                                 <th align="left" valign="bottom" width="28%" id="d19285e1581">Column </th>
                                 <th align="left" valign="bottom" width="72%" id="d19285e1584">Description</th>
                              </tr>
                           </thead>
                           <tbody>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="28%" id="d19285e1589" headers="d19285e1581 ">
                                    <p><code class="codeph">CASE_ID</code></p>
                                 </td>
                                 <td align="left" valign="top" width="72%" headers="d19285e1589 d19285e1584 ">
                                    <p>Value of the case ID column </p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="28%" id="d19285e1597" headers="d19285e1581 ">
                                    <p><code class="codeph">TARGET_VALUE</code></p>
                                 </td>
                                 <td align="left" valign="top" width="72%" headers="d19285e1597 d19285e1584 ">
                                    <p>Value of the target value</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="28%" id="d19285e1605" headers="d19285e1581 ">
                                    <p><code class="codeph">TARGET_VALUE_PROB</code></p>
                                 </td>
                                 <td align="left" valign="top" width="72%" headers="d19285e1605 d19285e1584 ">
                                    <p>Probability associated with the target value </p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="28%" id="d19285e1613" headers="d19285e1581 ">
                                    <p><code class="codeph">HAT</code></p>
                                 </td>
                                 <td align="left" valign="top" width="72%" headers="d19285e1613 d19285e1584 ">
                                    <p>Value of the diagonal element of the hat matrix</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="28%" id="d19285e1621" headers="d19285e1581 ">
                                    <p><code class="codeph">WORKING_RESIDUAL</code></p>
                                 </td>
                                 <td align="left" valign="top" width="72%" headers="d19285e1621 d19285e1584 ">
                                    <p>Residual with respect to the adjusted dependent variable</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="28%" id="d19285e1629" headers="d19285e1581 ">
                                    <p><code class="codeph">PEARSON_RESIDUAL</code></p>
                                 </td>
                                 <td align="left" valign="top" width="72%" headers="d19285e1629 d19285e1584 ">
                                    <p>The raw residual scaled by the estimated standard deviation of the target</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="28%" id="d19285e1637" headers="d19285e1581 ">
                                    <p><code class="codeph">DEVIANCE_RESIDUAL</code></p>
                                 </td>
                                 <td align="left" valign="top" width="72%" headers="d19285e1637 d19285e1584 ">
                                    <p>Contribution to the overall goodness of fit of the model</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="28%" id="d19285e1645" headers="d19285e1581 ">
                                    <p><code class="codeph">C</code></p>
                                 </td>
                                 <td align="left" valign="top" width="72%" headers="d19285e1645 d19285e1584 ">
                                    <p>Confidence interval displacement diagnostic</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="28%" id="d19285e1653" headers="d19285e1581 ">
                                    <p><code class="codeph">CBAR</code></p>
                                 </td>
                                 <td align="left" valign="top" width="72%" headers="d19285e1653 d19285e1584 ">
                                    <p>Confidence interval displacement diagnostic</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="28%" id="d19285e1661" headers="d19285e1581 ">
                                    <p><code class="codeph">DIFDEV</code></p>
                                 </td>
                                 <td align="left" valign="top" width="72%" headers="d19285e1661 d19285e1584 ">
                                    <p>Change in the deviance due to deleting an individual observation</p>
                                 </td>
                              </tr>
                              <tr align="left" valign="top">
                                 <td align="left" valign="top" width="28%" id="d19285e1669" headers="d19285e1581 ">
                                    <p><code class="codeph">DIFCHISQ</code></p>
                                 </td>
                                 <td align="left" valign="top" width="72%" headers="d19285e1669 d19285e1584 ">
                                    <p>Change in the Pearson chi-square</p>
                                 </td>
                              </tr>
                           </tbody>
                        </table>
                     </div>
                     <!-- class="inftblhruleinformal" -->
                  </div>
               </div>
            </div>
         </div>
      </article>
   </body>
</html>